{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Deploy IBM Cloud Pak for Watson AIOps using GitOps</li> <li>Use Cases</li> <li>Install Cloud Pak for Watson AIOps using GitOps</li> </ul>"},{"location":"#deploy-ibm-cloud-pak-for-watson-aiops-using-gitops","title":"Deploy IBM Cloud Pak for Watson AIOps using GitOps","text":"<p>This repository facilitates the use of Red Hat OpenShift GitOps to deploy Cloud Pak for Watson AIOps on a Red Hat OpenShift cluster.</p>"},{"location":"#use-cases","title":"Use Cases","text":"<ul> <li>As a cluster admin, I want to install Cloud Pak for Watson AIOps using GitOps, and track the cluster update with the Git commit log. (Day 1 Operation)</li> </ul>"},{"location":"#installing-cloud-pak-for-watson-aiops-using-gitops","title":"Installing Cloud Pak for Watson AIOps using GitOps","text":"<ul> <li>:tada::tada::tada: Cloud Pak for Watson AIOps 3.6 online installation :tada::tada::tada:</li> </ul>"},{"location":"aws-efs-config-example/","title":"Aws efs config example","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>AWS EFS Storage Configuration Example</li> <li>Prerequisite</li> <li>Update default security group to enable EFS access</li> <li>Creating EFS Storage</li> <li>Deploying EFS provisioner in the AWS cluster</li> </ul>"},{"location":"aws-efs-config-example/#aws-efs-storage-configuration-example","title":"AWS EFS Storage Configuration Example","text":""},{"location":"aws-efs-config-example/#prerequisite","title":"Prerequisite","text":"<ul> <li>Refer to the AWS EFS guide for details.</li> <li>EFS storage configuration requires the following cluster configuration data:</li> <li>cluster node VPC ID   </li> <li>VPC security group IDs for the master node and worker nodes as well as the default security group   </li> </ul>"},{"location":"aws-efs-config-example/#update-default-security-group-to-enable-efs-access","title":"Update default security group to enable EFS access","text":"<ul> <li>Edit the cluster default security group inbound rules</li> <li>Add NFS rule for master node security group</li> <li>Add NFS rule for worker node security group   </li> </ul>"},{"location":"aws-efs-config-example/#creating-efs-storage","title":"Creating EFS Storage","text":"<ul> <li>From the AWS UI console, go to Services-&gt;EFS</li> <li>Create file system</li> <li>Select Customize   </li> <li>From the Virtual Private Cloud (VPC) panel, select the VPC associated with the cluster master node.   </li> <li>Use default settings for the other options</li> </ul>"},{"location":"aws-efs-config-example/#deploying-efs-provisioner-in-the-aws-cluster","title":"Deploying EFS provisioner in the AWS cluster","text":"<ul> <li>Log in to the AWS cluster</li> <li>Create a script called efs-helm.sh with the following code: <pre><code>FSID=&lt;EFS File system ID&gt;  # Get from Amazon EFS File systems list\nREGION=&lt;EFS Region&gt;        # for example, use `us-east-2` for region us-east-2a/b/c\n\nhelm install efs-provisioner \\\n--namespace default \\\n--set  efsProvisioner.efsFileSystemId=${FSID} \\\n--set efsProvisioner.awsRegion=${REGION} \\\nefs-provisioner-0.13.2.tgz\n</code></pre></li> <li>Run efs-helm.sh script to deploy the efs provisioner</li> <li>Update the efs storage class as default storage</li> <li>remove the current default storage class from gp2</li> <li>edit sc <code>aws-efs</code> and add the following settings in the YAML to set it as the default storage class. <pre><code>  annotations:\nstorageclass.kubernetes.io/is-default-class: \"true\"\n</code></pre></li> </ul>"},{"location":"cp4waiops-custom-install/","title":"Cp4waiops custom install","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Customize Cloud Pak for Watson AIOps installation</li> <li>Background</li> <li>Host your own Git repository</li> <li>Advanced installation</li> </ul>"},{"location":"cp4waiops-custom-install/#customize-cloud-pak-for-watson-aiops-installation","title":"Customize Cloud Pak for Watson AIOps installation","text":""},{"location":"cp4waiops-custom-install/#background","title":"Background","text":"<p>GitOps is a declarative way to implement continuous deployment for cloud native applications. You can use GitOps to create repeatable processes for managing applications across multiple clusters. GitOps handles and automates complex deployments at a fast pace, saving time during deployment and release cycles.</p> <p>GitOps is a set of practices that use Git pull requests to manage infrastructure and application configurations. In GitOps, the Git repository is the only source of truth for system and application configuration. This Git repository contains declarative description for the applications that you need in your specific environment and contains an automated process to make your environment match the described state. Also, it contains the entire state of the system so that the trail of changes to the system state is visible and auditable. With GitOps you can solve the problem of application configuration sprawl.</p> <p>This document provides guidance for users who want to host the GitOps repositories in their own Git systems and customize an IBM Cloud Pak for Watson AIOps installation from their own repositories.</p>"},{"location":"cp4waiops-custom-install/#host-your-own-git-repository","title":"Host your own Git repository","text":"<p>To customize a Cloud Pak for Watson AIOps installation using your own Git repository, use the following steps.</p> <ul> <li> <p>Fork this repository to your own GitHub account.</p> </li> <li> <p>Modify the parameters in <code>config/&lt;version&gt;/**/values.yaml</code> based on your specific installation requirements. The official Cloud Pak for Watson AIOps GitOps repository uses a set of helm charts to wrap all Cloud Pak for Watson AIOps configuration YAML manifests in multiple helm templates. With a helm chart, you can customize the Cloud Pak for Watson AIOps installation parameters that are defined in a set of <code>values.yaml</code> files. For example, the <code>values.yaml</code> for the all-in-one configuration provides a set of parameters with default values that allow the customization of the Cloud Pak for Watson AIOps installation using all-in-one configuration.</p> </li> <li> <p>You can also define more <code>values.yaml</code> files if needed. These <code>values.yaml</code> files along with the original <code>values.yaml</code> file can all be applied when you create an Argo CD App to start the Cloud Pak for Watson AIOps installation, either from the UI or command line.</p> </li> <li> <p>Follow the installation guide for a specific Cloud Pak for Watson AIOps release that is provided in the official Cloud Pak for Watson AIOps GitOps repository to install Cloud Pak for Watson AIOps using GitOps. If you install Cloud Pak for Watson AIOps from the UI, then when you create the Argo CD App, in the Argo CD App form, change the <code>Repository URL</code> field to match the URL of your own repository, and set the <code>Revision</code> field to match the branch that you are working on. You can also apply the additional <code>values.yaml</code> files defined in previous step by adding them in <code>HELM</code> &gt; <code>VALUES FILES</code> field in the form.</p> </li> <li> <p>If you install Cloud Pak for Watson AIOps from the command line using the Argo CD CLI, you can set the repository and revision using argument <code>--repo</code> and <code>--revision</code>. For example, if you forked the official Cloud Pak for Watson AIOps GitOps repository into repository <code>https://github.com/foo/cp4waiops-gitops</code>, and work on branch <code>production</code>, you would run the following command to create an Argo CD App and start the installation of Cloud Pak for Watson AIOps AI Manager:</p> </li> </ul> <pre><code>argocd app create cp4waiops-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/foo/cp4waiops-gitops \\\n--path config/3.3/ai-manager \\\n--revision production \\\n--dest-namespace cp4waiops \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.cp4waiops_namespace=cp4waiops \\\n--helm-set spec.imageCatalog=icr.io/cpopen/ibm-operator-catalog:latest \\\n--helm-set spec.channel=v3.3 \\\n--helm-set spec.dockerUsername=cp \\\n--helm-set spec.dockerPassword= &lt;entitlement-key&gt; \\\n--helm-set spec.storageClass=rook-cephfs \\\n--helm-set spec.storageClassLargeBlock=rook-cephfs \\\n--helm-set spec.size=small\n</code></pre>"},{"location":"cp4waiops-custom-install/#advanced-installation","title":"Advanced installation","text":"<ul> <li>Deploy Cloud Pak for Watson AIOps demo environment to multiple clusters</li> <li>Deploy Cloud Pak for Watson AIOps demo environment in one click</li> </ul>"},{"location":"deploy-cloudpak-to-multiple-clusters/","title":"Deploy cloudpak to multiple clusters","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Deploy Cloud Pak for Watson AIOps demo environment to multiple clusters</li> <li>Prepare environments</li> <li>Install the Argo CD CLI</li> <li>Install Cloud Pak for Watson AIOps demo environment</li> <li>Add cluster into Argo CD</li> <li>Add more clusters</li> </ul>"},{"location":"deploy-cloudpak-to-multiple-clusters/#deploy-cloud-pak-for-watson-aiops-demo-environment-to-multiple-clusters","title":"Deploy Cloud Pak for Watson AIOps demo environment to multiple clusters","text":"<p>Learn how to deploy the same IBM Cloud Pak for Watson AIOps demo environment to multiple clusters with GitOps.</p>"},{"location":"deploy-cloudpak-to-multiple-clusters/#prepare-environments","title":"Prepare environments","text":"<p>You need at least one cluster to host Argo CD, and one or more clusters to deploy the Cloud Pak for Watson AIOps demonstration environment, which is illustrated in following diagram:</p> <p></p> <p>NOTE:</p> <ul> <li><code>cluster 0</code> is used to host the Argo CD instance. It can be a Red Hat OpenShift cluster or a vanilla Kubernetes cluster that does not require too much resource, since Argo CD is lightweight and supports both Red Hat OpenShift and vanilla Kubernetes.</li> <li><code>cluster 1</code> - <code>cluster x</code> are used to deploy Cloud Pak for Watson AIOps demonstration environments. If you are looking for an extremely small Cloud Pak for Watson AIOps deployment with all of the default components, sample applications, and other dependencies on the same cluster for a demonstration or proof-of-concept, then a cluster with three worker nodes where each node has 16 cores CPU and 32 GB memory is recommended. If you require a production deployment, see System Requirements.</li> </ul>"},{"location":"deploy-cloudpak-to-multiple-clusters/#install-the-argo-cd-cli","title":"Install the Argo CD CLI","text":"<p>The Argo CD CLI (the <code>argocd</code> command) is needed to add clusters to Argo CD so that Argo CD can deploy the Cloud Pak for Watson AIOps demo environment to those clusters.</p> <p>To install Argo CD CLI, see the Argo CD online document. You can install and run Argo CD CLI on any machine such as your notebook, since it is just a client tool that is used to connect to the Argo CD server.</p>"},{"location":"deploy-cloudpak-to-multiple-clusters/#install-cloud-pak-for-watson-aiops-demo-environment","title":"Install Cloud Pak for Watson AIOps demo environment","text":"<p>After Argo CD and Argo CD CLI are installed, you can deploy a Cloud Pak for Watson AIOps demonstration environment from the Argo CD UI. To install a Cloud Pak for Watson AIOps demonstration environment, refer to Install Cloud Pak for Watson AIOps Demo Environment.</p> <p>The only difference when you set the installation parameters is that:</p> <ul> <li><code>argocd.allowLocalDeploy</code> must be set to <code>false</code>. This is to avoid the Cloud Pak for Watson AIOps demonstration environment from being deployed on the same cluster where Argo CD runs, since in this case that cluster is dedicated to running Argo CD.</li> </ul> <p>After you create the Argo CD App, you can see something similar to the following on the Argo CD UI:</p> <p></p> <p>You can only see the root level Argo CD App as no other child level Apps are created for now. This is because no other cluster has been added into Argo CD to deploy the actual Cloud Pak for Watson AIOps demonstration environment yet. If you click the root level App and go into it, then you can see all of the child level App definitions that are listed as follows:</p> <p></p> <p>Depending on the installation parameters that you specified when you created the root level Argo CD App, you can enable or disable some of the Apps according to your specific needs. In this case, all available Apps are enabled including Cloud Pak for Watson AIOps, Robot Shop, Humio, Istio, and so on. They are deployed to the target cluster that is going to be added into Argo CD later.</p>"},{"location":"deploy-cloudpak-to-multiple-clusters/#add-cluster-into-argo-cd","title":"Add cluster into Argo CD","text":"<p>If you use the Red Hat OpenShift cluster to host Argo CD, then to add the cluster into Argo CD, you need to log in to the cluster that runs Argo CD with the <code>oc login</code> command, and then run the following commands to log in to Argo CD with the Argo CD CLI:</p> <pre><code>ARGO_HOST=$(oc get route openshift-gitops-server -n openshift-gitops -o jsonpath='{.spec.host}')\nARGO_PASSWORD=$(oc get secret openshift-gitops-cluster -n openshift-gitops -o \"jsonpath={.data['admin\\.password']}\" | base64 -d)\nargocd login --username admin --password $ARGO_PASSWORD $ARGO_HOST --insecure\n</code></pre> <p>Next, log in to the target cluster that will be used to deploy the Cloud Pak for Watson AIOps demonstration environment, again with the <code>oc login</code> command. Then, run the following commands to add that cluster into Argo CD with the Argo CD CLI:</p> <pre><code>CLUSTER_NAME=stocky\nCURRENT_CONTEXT=$(oc config current-context)\nargocd cluster add $CURRENT_CONTEXT --name $CLUSTER_NAME\n</code></pre> <p>Here, a short name for the cluster is given using <code>CLUSTER_NAME</code> and is passed into the Argo CD CLI by the argument <code>--name</code>.</p> <p>Next, go to <code>Settings</code> &gt; <code>Clusters</code> from the Argo CD UI. The newly added cluster is listed as follows.</p> <p></p> <p>Go to <code>Applications</code> to see all the child level Apps being created automatically, without any additional manual intervention.</p> <p></p> <p>Click the root level App and go into it to see that for each child level App definition there is a corresponding App instance that is linked to it. This is the actual application being deployed to the target cluster that was just added into Argo CD.</p> <p></p> <p>Depending on the installation parameters that you specified when creating the root level App, it usually takes 1 hour to finish the installation of Cloud Pak for Watson AIOps, and 10 minutes to finish all of the other applications deployments including Ceph, Robot Shop, Humio, Istio, and so on. When you see all of the Apps turning green, (<code>Synced</code> and <code>Healthy</code>), then the installation of the Cloud Pak for Watson AIOps demonstration environment is complete on the target cluster.</p> <p></p>"},{"location":"deploy-cloudpak-to-multiple-clusters/#add-more-clusters","title":"Add more clusters","text":"<p>To add more clusters to deploy more Cloud Pak for Watson AIOps demonstration environments, repeat these steps to add clusters into Argo CD. Argo CD detects these clusters and deploys applications to these clusters automatically. For example, after you add the second cluster, you can see that the newly added cluster is added to the <code>Clusters</code> view from Argo CD UI:</p> <p></p> <p>You can also see that each child level App definition now maps to two App instances, and that each instance represents the actual application that is getting deployed to a separate cluster.</p> <p></p>"},{"location":"deploy-cloudpak-with-sample-apps/","title":"Deploy cloudpak with sample apps","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Deploy Cloud Pak for Watson AIOps demo environment in one click</li> <li>About x-small profile</li> <li>Prepare environment</li> <li>Install Cloud Pak for Watson AIOps Demo Environment</li> <li>Access Environment<ul> <li>Cloud Pak for Watson AIOps</li> <li>Robot Shop</li> <li>Humio</li> </ul> </li> </ul>"},{"location":"deploy-cloudpak-with-sample-apps/#deploy-cloud-pak-for-watson-aiops-demo-environment-in-one-click","title":"Deploy Cloud Pak for Watson AIOps demo environment in one click","text":"<p>Learn how to deploy an IBM Cloud Pak for Watson AIOps demo environment using GitOps in one click.</p> <ul> <li>Deploy Cloud Pak for Watson AIOps using custom profile <code>x-small</code> in a sandbox with restricted resources.</li> <li>Set up an integration with Humio, Kafka, Kubernetes, and more as postinstallation steps automatically.</li> <li>Deploy Robot Shop as a sample application, and other dependencies on the same cluster where Cloud Pak for Watson AIOps runs.</li> </ul> <p>This installation scenario is tested and verified against Cloud Pak for Watson AIOps 3.2 and 3.3.</p> <p></p>"},{"location":"deploy-cloudpak-with-sample-apps/#about-x-small-profile","title":"About x-small profile","text":"<p>The <code>x-small</code> profile is not an official profile that is supported by Cloud Pak for Watson AIOps at the momentm as it only covers AI Manager and does not include Event Manager. As an experimental feature, you can use it to set up demonstrations, proof-of-concept deployments, or development environments.</p> <p>Although in this installation scenario the <code>x-small</code> profile is used, this approach also supports a Cloud Pak for Watson AIOps installation in a production environment using official profiles such as <code>small</code> or <code>large</code>.</p>"},{"location":"deploy-cloudpak-with-sample-apps/#prepare-environment","title":"Prepare environment","text":"<p>Prepare a Red Hat Red Hat OpenShift cluster as your demonstration environment. If you use the <code>x-small</code> profile, it is recommended to set up a cluster with three worker nodes where each node has 16 cores CPU and 32 GB memory.</p> <p>Before you start to install the demonstration environment, make sure that you have installed Red Hat Red Hat OpenShift GitOps (Argo CD) on the cluster. To install Red Hat OpenShift GitOps, refer to Installing OpenShift GitOps.</p> <p>These instructions use Argo CD to install the following applications in one go:</p> Application Required Description Ceph No The storage that is used by Cloud Pak for Watson AIOps and other applications. It can be skipped if you already have storage solution available on your target cluster. Cloud Pak for Watson AIOps Yes IBM Cloud Pak for Watson AIOps. Robot Shop No The sample application used to demonstrate Cloud Pak for Watson AIOps features. Humio &amp; Fluent Bit No The log collector that is used by Cloud Pak for Watson AIOps for log anomaly detecting. Istio No The service mesh used by sample application for fault injection. <p>NOTE: This example uses Ceph storage for demonstration purpose. You must use a supported storage. For more information about supported storage, see Storage Considerations.</p>"},{"location":"deploy-cloudpak-with-sample-apps/#install-cloud-pak-for-watson-aiops-demo-environment","title":"Install Cloud Pak for Watson AIOps Demo Environment","text":"<p>Log in to Argo CD, then start the installation by clicking the <code>NEW APP</code> button on upper left to create an Argo CD App.</p> <p>Complete the form using the suggested field values listed in following table:</p> Field Value Application Name cp4waiops-demo Project default Sync Policy Automatic Repository URL https://github.com/IBM/cp4waiops-gitops Revision HEAD Path config/all-in-one Cluster URL https://kubernetes.default.svc Namespace openshift-gitops <p>NOTE:</p> <p>NOTE: If you use a repository that is forked from the official Cloud Pak for Watson AIOps GitOps repository or a different branch, then you must update the values of the <code>Repository URL</code> and <code>Revision</code> parameters to match your repository and branch. For example, if you use <code>https://github.com/&lt;myaccount&gt;/cp4waiops-gitops</code> and <code>dev</code> branch, then these two parameters must be changed.</p> <p>You can also update the following parameters to customize the installation.</p> Parameter Type Default Value Description argocd.cluster string openshift The type of the cluster that Argo CD runs on, valid values include: openshift, kubernetes. argocd.allowLocalDeploy bool true Allow apps to be deployed on the same cluster where Argo CD runs. rookceph.enabled bool true Specify whether or not to install Ceph as storage used by Cloud Pak for Watson AIOps. cp4waiops.version string v3.3 Specify the version of Cloud Pak for Watson AIOps, e.g.: v3.2, v3.3. cp4waiops.profile string small The Cloud Pak for Watson AIOps deployment profile, for example: x-small, small, large. cp4waiops.dockerUsername string cp The username of image registry used to pull images. cp4waiops.dockerPassword string REPLACE_IT The password of image registry used to pull images. cp4waiops.aiManager.enabled bool true Specify whether to install AI Manager. cp4waiops.aiManager.namespace string cp4waiops The namespace where AI Manager is installed. cp4waiops.aiManager.instanceName string aiops-installation The instance name of AI Manager. cp4waiops.eventManager.enabled bool true Specify whether to install Event Manager. cp4waiops.eventManager.namespace string noi The namespace where Event Manager is installed. cp4waiops.eventManager.clusterDomain string REPLACE_IT The domain name of the cluster where Event Manager is installed. <p>NOTE:</p> <ul> <li><code>cp4waiops.dockerPassword</code> This is the entitlement key that you can copy from My IBM Container Software Library.</li> <li><code>cp4waiops.profile</code> The profile <code>x-small</code> is only suitable for demonstrations and proof-of-concept deployments. Production environments must use a <code>small</code> or <code>large</code> profile.</li> <li><code>cp4waiops.eventManager.enabled</code> This must be false if you have a value of <code>x-small</code> for <code>cp4waiops.profile</code>, as this profile size is only suitable for deployments of AI Manager, and not for deployments of AI Manager and Event Manager.</li> <li><code>cp4waiops.eventManager.clusterDomain</code> This is the domain name of the cluster where Event Manager is installed. Use a fully qualified domain name (FQDN). For example, <code>apps.clustername.abc.xyz.com</code>.</li> </ul> <p>The following installation parameters are not commonly used, so they are invisible when you create the Argo CD App from UI. But you can add them when completing the form in <code>HELM</code> &gt; <code>VALUES</code> field.</p> Parameter Type Default Value Description cp4waiops.setup.enabled bool false Set up Cloud Pak for Watson AIOps after it is installed. cp4waiops.setup.humio.enabled bool true Setup Humio integration. cp4waiops.setup.kafka.enabled bool true Setup Kafka integration. cp4waiops.setup.kubernetes.enabled bool true Setup Kubernetes integration. robotshop.enabled bool false Specify whether to install Robot Shop. humio.enabled bool false Specify whether to install Humio. istio.enabled bool false Specify whether to install Istio. <p>For example, adding the following YAML snippet to <code>HELM</code> &gt; <code>VALUES</code> field enables Robot Shop, Humio, and Istio: </p> <pre><code>robotshop:\nenabled: true\nhumio:\nenabled: true\nistio:\nenabled: true\n</code></pre> <p>When the form is completed, click <code>CREATE</code> to start the installation. Whilst waiting for the install to complete, you will see more Apps being rolled out gradually from the Argo CD UI. Each App represents a specific application to be deployed and is managed by the root level App.</p> <p></p> <p>Depending on the installation parameters that you specified, it usually takes one hour to finish the installation of Cloud Pak for Watson AIOps, and ten minutes to finish all other application deployments, including Ceph, Robot Shop, Humio, Istio, and more. When the Argo CD Apps turn green, (<code>Synced</code> and <code>Healthy</code>) then the installation of the Cloud Pak for Watson AIOps demonstration environment is finished.</p> <p></p>"},{"location":"deploy-cloudpak-with-sample-apps/#access-environment","title":"Access Environment","text":""},{"location":"deploy-cloudpak-with-sample-apps/#cloud-pak-for-watson-aiops","title":"Cloud Pak for Watson AIOps","text":"<p>To access Cloud Pak for Watson AIOps, you can run following command to get the URL. Here <code>aiops-installation</code> is the Cloud Pak for Watson AIOps instance name that you specified using the installation parameter <code>cp4waiops.instanceName</code> when creating the Argo CD App.</p> <pre><code>kubectl -n cp4waiops get installation aiops-installation -o jsonpath='{.status.locations.cloudPakUiUrl}{\"\\n\"}'\n</code></pre> <p>To get the password for user <code>admin</code>, run following command:</p> <pre><code>kubectl -n ibm-common-services get secret platform-auth-idp-credentials -o jsonpath='{.data.admin_password}' | base64 -d\n</code></pre> <p>Use this information to log in to the Cloud Pak for Watson AIOps UI.</p> <p></p> <p>If you set the installation parameter <code>cp4waiops.setup</code> to <code>true</code>, then you have pre-configured an integration with Humio, Kafka, and Kubernetes in. To verify this, go to <code>Define</code> &gt; <code>Data and tool connections</code> to see these integrations displayed as follows:</p> <p></p>"},{"location":"deploy-cloudpak-with-sample-apps/#robot-shop","title":"Robot Shop","text":"<p>To access Robot Shop, run the following command to get the URL:</p> <pre><code>kubectl -n istio-system get route istio-ingressgateway -o jsonpath='{\"http://\"}{.spec.host}{\"\\n\"}'\n</code></pre> <p></p>"},{"location":"deploy-cloudpak-with-sample-apps/#humio","title":"Humio","text":"<p>To access Humio, run the following command to get the URL:</p> <pre><code>kubectl -n humio-logging get route humio-humio-core -o jsonpath='{\"http://\"}{.spec.host}{\"\\n\"}'\n</code></pre> <p>To get the password for user <code>developer</code>, run following command:</p> <pre><code>kubectl -n humio-logging get secret developer-user-password -o jsonpath=\"{.data.password}\" | base64 -d\n</code></pre> <p>Use this information to log in to the Humio UI. After logging in, you can see a pre-defined repository named <code>robot-shop</code> for Robot Shop:</p> <p></p> <p>Click the repository to see the live logs captured by Humio from Robot Shop:</p> <p></p>"},{"location":"deploy-ocp-cloudpak-with-gitops/","title":"Deploy ocp cloudpak with gitops","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Deploy Cloud Pak for Watson AIOPs demo environment including cluster provisioning</li> <li>Install Cloud Pak for Watson AIOPs demo environment</li> </ul>"},{"location":"deploy-ocp-cloudpak-with-gitops/#deploy-cloud-pak-for-watson-aiops-demo-environment-including-cluster-provisioning","title":"Deploy Cloud Pak for Watson AIOPs demo environment including cluster provisioning","text":"<p>Learn how to provision a Red Hat OpenShift cluster, and use this cluster to deploy an IBM Cloud Pak for Watson AIOPs demonstration environment using GitOps. With this approach you will get a fully automated experience of launching a Cloud Pak for Watson AIOPs demo environment, from cluster provisioning to the deployment and configuration of the demonstration environment, all driven by GitOps automatically.</p> <p>IMPORTANT: Internal use only. <code>Fyre</code>, an IBM IaaS platform for internal use, is currently the only supported provider.</p> <p></p>"},{"location":"deploy-ocp-cloudpak-with-gitops/#install-cloud-pak-for-watson-aiops-demo-environment","title":"Install Cloud Pak for Watson AIOPs demo environment","text":"<p>After installing Argo CD, you can deploy a Cloud Pak for Watson AIOPs demonstration environment via Argo CD UI. To install a Cloud Pak for Watson AIOPs demonstration environment, please refer to Install Cloud Pak for Watson AIOPs demo environment.</p> <p>The only difference when you set the install parameters is that:</p> <ul> <li><code>argocd.allowLocalDeploy</code> must be set to <code>false</code>. This is to avoid the Cloud Pak for Watson AIOps demonstration environment from being deployed on the same cluster where Argo CD runs, since in this case, that cluster is dedicated to running Argo CD.</li> <li>You will be able to configure the Red Hat OpenShift cluster provisioning with the following installation parameters.</li> </ul> Parameter Type Default Value Description cluster.enabled bool false Specify whether or not to provision a cluster before install Cloud Pak for Watson AIOPs. cluster.provider.type string fyre The supported provider to provision cluster, valid values include: fyre. cluster.provider.quotaType string quick-burn The supported quota type to provision cluster, valid values include: quick-burn, ocp-plus. cluster.provider.credentials.productGroupId string REPLACE_IT Fyre product group id required when calling Fyre API. cluster.provider.credentials.token string REPLACE_IT Fyre user token required when calling Fyre API. cluster.provider.credentials.user string REPLACE_IT Fyre user id required when calling Fyre API. cluster.provider.site string svl Fyre site required when calling Fyre API, ocp-plus only. cluster.provider.ocpVersion string 4.8.27 OCP Version required when calling Fyre API. cluster.provider.workerFlavor string extra-large The supported size to provision cluster, valid values include: extra-large, large. extra-large requests 6 worker nodes, large requests 3 worker nodes. <p>NOTE: <code>cluster.provider.type</code>, <code>fyre</code> is currently the only supported provider. It is an IBM IaaS platform only for internal use.</p> <p>These parameters are invisible when you create the Argo CD App from the UI. You can add them when completing the form in <code>HELM</code> &gt; <code>VALUES</code> field as follows:</p> <pre><code>cluster:\nenabled: true\nprovider:\ntype: fyre\nquotaType: quick-burn\ncredentials:\nuser: &lt;my_user_id&gt;\ntoken: &lt;my_user_token&gt;\nproductGroupId: &lt;my_product_group_id&gt;\n</code></pre> <p>After you create the Argo CD App, you will see something similar as follows from Argo CD UI:</p> <p></p> <p>Apart from the root level App, the App <code>cluster-operator-fyre</code> represents the operator that drives the cluster provisioning on Fyre. The App <code>clusters-fyre</code> maps the cluster provisioning request created and stored in git repository. Click the App <code>clusters-fyre</code> to check its details:</p> <p></p> <p>There is a custom resource in type of <code>OpenShiftFyre</code> that \"documents\" the desired status for the OpenShift cluster to be requested. Also, there is a secret that includes the Fyre credentials that you input earlier when creating the Argo CD App using install parameters. The operator will use this information to communicate with Fyre API. You may also notice that the <code>OpenShiftFyre</code> resource is in <code>Processing</code> status. This means the operator has issued the request to Fyre successfully and Fyre has started to provision the cluster for you.</p> <p>If you go to the root level App, you will see that two new child level Apps are added:</p> <p></p> <p>Because the cluster is still being provisioned and not available to deploy the Cloud Pak for Watson AIOPs demo environment yet, there is no actual App instance spawned for the demo environment. Usually, it takes time to complete the cluster provisioning. Once it's completed, the new cluster will be added to Argo CD automatically by the operator. You can check it by going to <code>Settings</code> &gt; <code>Clusters</code> from Argo CD UI:</p> <p></p> <p>When the new cluster is displayed in the list as above, Argo CD will then kick off the demo environment deployment on that cluster immediately without any manual intervention. You will see all child level Apps are now getting created from the <code>Applications</code> view as follows:</p> <p></p> <p>Specify the target cluster in the clusters filter box, then wait for all Apps turning into green.</p> <p></p> <p>Now you should be able to use your fresh new Cloud Pak for Watson AIOPs demo environment!</p>"},{"location":"how-to-create-local-registry/","title":"How to create local registry","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Creating a Multi-arch Docker Registry</li> <li>Prerequisites</li> <li>Procedure<ul> <li>Install Httpd Tools</li> <li>Create Folders for Docker Registry</li> <li>Provide Certificate for Docker Registry</li> <li>Generate User Name and Password for Docker Registry</li> <li>Create docker-registry Container to Host Your Registry</li> <li>Open Required Ports for Docker Registry</li> <li>Add Self-signed Certificate to Your List of Trusted Certificates</li> <li>Confirm Docker Registry is Available</li> </ul> </li> <li>Access Docker Registry<ul> <li>Generate base64-encoded User Name and Password or Token for Your Mirror Registry</li> <li>Prepare Pullsecret Content</li> <li>Create Imagepullsecret</li> <li>Handle Cert for Accessing Docker Registry</li> </ul> </li> </ul>"},{"location":"how-to-create-local-registry/#creating-a-multi-arch-docker-registry","title":"Creating a Multi-arch Docker Registry","text":""},{"location":"how-to-create-local-registry/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>You have a Red Hat Enterprise Linux (RHEL) server on your network to use as the registry host.</p> </li> <li> <p>The registry host can access the internet.</p> </li> </ul>"},{"location":"how-to-create-local-registry/#procedure","title":"Procedure","text":""},{"location":"how-to-create-local-registry/#install-httpd-tools","title":"Install Httpd Tools","text":"<pre><code>yum -y install docker httpd-tools\n</code></pre>"},{"location":"how-to-create-local-registry/#create-folders-for-docker-registry","title":"Create Folders for Docker Registry","text":"<pre><code>mkdir -p /opt/registry/{auth,certs,data}\n</code></pre>"},{"location":"how-to-create-local-registry/#provide-certificate-for-docker-registry","title":"Provide Certificate for Docker Registry","text":"<p>If you do not have an existing, trusted certificate authority, you can generate a self-signed certificate:</p> <pre><code>cd /opt/registry/certs\nopenssl req -newkey rsa:4096 -nodes -sha256 -keyout domain.key -x509 -days 365 -out domain.crt\n</code></pre> <p>At the prompts, provide the required values for the certificate:</p> <pre><code>Country Name (2 letter code)    \nSpecify the two-letter ISO country code for your location. See the ISO 3166 country codes standard.\n\nState or Province Name (full name)  \nEnter the full name of your state or province.\n\nLocality Name (eg, city)    \nEnter the name of your city.\n\nOrganization Name (eg, company) \nEnter your company name.\n\nOrganizational Unit Name (eg, section)  \nEnter your department name.\n\nCommon Name (eg, your name or your server\u2019s hostname)   \nEnter the host name for the registry host. Ensure that your hostname is in DNS and that it resolves to the expected IP address.\n\nEmail Address   \nEnter your email address. For more information, see the req description in the OpenSSL documentation.\n</code></pre> <p>Note: make sure enter the <code>hostname</code> for the common name , that could be resolved to the expect IP address when login docker reigstry</p>"},{"location":"how-to-create-local-registry/#generate-user-name-and-password-for-docker-registry","title":"Generate User Name and Password for Docker Registry","text":"<p><pre><code>htpasswd -bBc /opt/registry/auth/htpasswd &lt;user_name&gt; &lt;password&gt; \n</code></pre> Note: you will use this <code>user_name</code> <code>password</code> to login the docker registry</p>"},{"location":"how-to-create-local-registry/#create-docker-registry-container-to-host-your-registry","title":"Create docker-registry Container to Host Your Registry","text":"<p><pre><code>docker run --name mirror-registry -p &lt;local_registry_host_port&gt;:5000 \\\n     -v /opt/registry/data:/var/lib/registry:z \\\n     -v /opt/registry/auth:/auth:z \\\n     -e \"REGISTRY_AUTH=htpasswd\" \\\n     -e \"REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm\" \\\n     -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \\\n     -v /opt/registry/certs:/certs:z \\\n     -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \\\n     -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \\\n     -e REGISTRY_COMPATIBILITY_SCHEMA1_ENABLED=true \\\n     -d docker.io/library/registry:2\n</code></pre> Note: For <code>local_registry_host_port</code>, specify the port that your docker registry uses to serve content</p>"},{"location":"how-to-create-local-registry/#open-required-ports-for-docker-registry","title":"Open Required Ports for Docker Registry","text":"<pre><code># firewall-cmd --add-port=&lt;local_registry_host_port&gt;/tcp --zone=internal --permanent \n# firewall-cmd --add-port=&lt;local_registry_host_port&gt;/tcp --zone=public   --permanent \n# firewall-cmd --reload\n</code></pre>"},{"location":"how-to-create-local-registry/#add-self-signed-certificate-to-your-list-of-trusted-certificates","title":"Add Self-signed Certificate to Your List of Trusted Certificates","text":"<pre><code>cp /opt/registry/certs/domain.crt /etc/pki/ca-trust/source/anchors/\n# update-ca-trust\n</code></pre>"},{"location":"how-to-create-local-registry/#confirm-docker-registry-is-available","title":"Confirm Docker Registry is Available","text":"<pre><code>curl -u &lt;user_name&gt;:&lt;password&gt; -k https://&lt;local_registry_host_name&gt;:&lt;local_registry_host_port&gt;/v2/_catalog \n\n{\"repositories\":[]}\n</code></pre> <p>Note: - For <code>user_name</code> and <code>password</code> , specify the user name and password for your registry. - For <code>local_registry_host_name</code>, specify the registry domain name that you specified in your certificate, such as <code>registry.example.com</code> - For <code>local_registry_host_port</code>, specify the port that your docker registry uses to serve content</p>"},{"location":"how-to-create-local-registry/#access-docker-registry","title":"Access Docker Registry","text":""},{"location":"how-to-create-local-registry/#generate-base64-encoded-user-name-and-password-or-token-for-your-mirror-registry","title":"Generate base64-encoded User Name and Password or Token for Your Mirror Registry","text":"<pre><code># echo -n '&lt;user_name&gt;:&lt;password&gt;' | base64 -w0\n\nYWRtaW46YWRtaW4=\n</code></pre> <p>Note: For <code>user_name</code> and <code>password</code>, specify the user name and password that you configured for your registry</p>"},{"location":"how-to-create-local-registry/#prepare-pullsecret-content","title":"Prepare Pullsecret Content","text":"<pre><code># cat config.json\n{\n  \"auths\": {\n    \"&lt;local_registry_host_name&gt;:&lt;local_registry_host_port&gt;\": {\n      \"auth\": \"YWRtaW46YWRtaW4=\"\n    }\n  }\n}\n</code></pre> <p>Note: - For <code>local_registry_host_name</code>, specify the registry domain name that you specified in your certificate. - For <code>local_registry_host_port</code>, specify the port that your docker registry uses to serve content. - For <code>credentials</code>, specify the base64-encoded user name and password for the docker registry that you generated.</p>"},{"location":"how-to-create-local-registry/#create-imagepullsecret","title":"Create Imagepullsecret","text":"<pre><code>kubectl create secret generic cp4mcm-pull-secret \\\n  --from-file=.dockerconfigjson=&lt;path&gt;/config.json \\\n  --type=kubernetes.io/dockerconfigjson \n</code></pre> <p>Note: You need fill in the <code>config.json</code> path here</p>"},{"location":"how-to-create-local-registry/#handle-cert-for-accessing-docker-registry","title":"Handle Cert for Accessing Docker Registry","text":"<ul> <li>Pure kuberentes</li> <li>Copy the domain.crt file to <code>/etc/docker/certs.d/&lt;local_registry_host_name&gt;:&lt;local_registry_host_port&gt;/ca.crt</code> on every kubernetes node . You do not need to restart Docker</li> <li>OCP 4</li> <li>Copy the <code>domain.crt</code> to cluster and rename it to <code>ca.crt</code></li> <li>Create configmap and patch to use the cert</li> </ul> <pre><code># oc create configmap registry-config --from-file=${MIRROR_ADDR_HOSTNAME}..${local_registry_host_port}=$path/ca.crt -n openshift-config\n\n# oc patch image.config.openshift.io/cluster --patch '{\"spec\":{\"additionalTrustedCA\":{\"name\":\"registry-config\"}}}' --type=merge\n</code></pre>"},{"location":"how-to-deploy-airgap-32/","title":"How to deploy airgap 32","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Deploy CP4WAIOPS (Cloud Pak for Watson AIOps) 3.2 with GitOps In Airgap Cluster</li> <li>Prerequisite</li> <li>Install CP4WAIOPS Using OpenShift Web Console<ul> <li>Grant ArgoCD Cluster Admin Permission</li> <li>Login to ArgoCD</li> <li>Mirror Image to Local Registry with GitOps</li> <li>Bastion host</li> <li>Storage Consideration</li> <li>Verify Ceph Cluster Installation</li> <li>Install CP4WAIOPS using GitOps</li> <li>Verify CP4WAIOPS Installation</li> <li>Access Cloud Pak for Watson AIOps</li> </ul> </li> <li>Using CLI to Install CP4WAIOPS<ul> <li>Grant ArgoCD Cluster Admin Permission</li> <li>Login to the ArgoCD server</li> <li>Mirror Image to Local Registry with GitOps</li> <li>Storage Consideration</li> <li>Install CP4WAIOPS using GitOps</li> <li>Verify CP4WAIOPS Installation</li> <li>Access CP4WAIOps UI</li> </ul> </li> </ul>"},{"location":"how-to-deploy-airgap-32/#deploy-cp4waiops-cloud-pak-for-watson-aiops-32-with-gitops-in-airgap-cluster","title":"Deploy CP4WAIOPS (Cloud Pak for Watson AIOps) 3.2 with GitOps In Airgap Cluster","text":"<p>NOTE: THIS IS NOT A RELEASED FEATURE FOR CP4WAIOPS!</p> <p>Refer to here go get some detail for CP4WAIOPS 3.2 airgap install detail.</p> <p>There are three airgap models are supported as follows: - Bastion host - Portable compute device - Portable storage device</p> <p>In this tutorial, we will share some detail for airgap with a Bastion host.</p>"},{"location":"how-to-deploy-airgap-32/#prerequisite","title":"Prerequisite","text":"<ul> <li>NOTE: Only OpenShift 4.8 with CP4WAIOPS 3.2 are fully tested, NOT A RELEASED FEATURE FOR CP4WAIOPS.</li> <li>You must prepare a bastion host that can connect to the internet and to the air-gapped network with access to the Red Hat\u00ae OpenShift\u00ae Container Platform cluster and the local, intranet Docker registry.</li> <li>Your bastion host must have 120GB storage to hold all of the software that is to be transferred to the local, intranet Docker registry.</li> <li>Refer to System requirements for Cloud Pak for Watson AIOps 3.2</li> <li>GitOps, refer to Installing GitOps Operator in web console</li> <li>Local image registry and access, refer to how to create a local registry</li> <li>You need to have GitHub Enterprise Edition or Gitlab running in your local network. In this tutorial, we are using <code>github.com</code> to simulate.</li> </ul>"},{"location":"how-to-deploy-airgap-32/#install-cp4waiops-using-openshift-web-console","title":"Install CP4WAIOPS Using OpenShift Web Console","text":""},{"location":"how-to-deploy-airgap-32/#grant-argocd-cluster-admin-permission","title":"Grant ArgoCD Cluster Admin Permission","text":"<ul> <li> <p>From the Red Hat OpenShift Console, go to User Management &gt; RoleBindings &gt; Create binding.</p> </li> <li> <p>Use the Form view to configure the properties for the ClusterRoleBinding, and select the Create button.</p> </li> <li>Binding type<ul> <li>Cluster-wide role binding (ClusterRoleBinding)</li> </ul> </li> <li>RoleBinding<ul> <li>Name: argocd-admin</li> </ul> </li> <li>Role<ul> <li>Role Name: cluster-admin</li> </ul> </li> <li>Subject<ul> <li>ServiceAccount: check it</li> <li>Subject namespace: openshift-gitops</li> <li>Subject name: openshift-gitops-argocd-application-controller</li> </ul> </li> </ul>"},{"location":"how-to-deploy-airgap-32/#login-to-argocd","title":"Login to ArgoCD","text":"<ul> <li>You can now login to gitops UI as follows by clicking the menu on OpenShift top right.</li> </ul> <ul> <li>GitOps UI will be poped up and you can login with <code>LOG IN VIA OPENSHIFT</code>.</li> </ul>"},{"location":"how-to-deploy-airgap-32/#mirror-image-to-local-registry-with-gitops","title":"Mirror Image to Local Registry with GitOps","text":""},{"location":"how-to-deploy-airgap-32/#bastion-host","title":"Bastion host","text":"<p>Mirror Image to local Registry on Bastion host with GitOps</p> <pre><code>- GENERAL\n  - Application Name: anyname(like \"imagemirror\")\n  - Project: default\n  - SYNC POLICY: Automatic\n- SOURCE\n  - REPO URL : https://github.com/IBM/cp4waiops-gitops\n  - Target version: HEAD\n  - path: config/3.2/airgap/imageMirror\n- DESTINATION\n  - Cluster URL: &lt;cluster-url-in-basion-host&gt;\n  - Namespace: image\n- HELM\n  - spec.imageMirror_namespace: image\n  - spec.localDockerRegistryHost: &lt;localDockerRegistryHost&gt;\n  - spec.localDockerRegistryPort: &lt;localDockerRegistryPort&gt;\n  - spec.localDockerRegistryUser: &lt;localDockerRegistryUser&gt;\n  - spec.localDockerRegistryPassword: &lt;localDockerRegistryPassword&gt;\n  - spec.cpRegistryPassword: &lt;entitlement-key&gt;\n  - spec.aiManager.enabled: false  ## set to true if you want to install AIManager\n  - spec.aiManager.caseName: ibm-cp-waiops\n  - spec.aiManager.caseVersion: 1.1.0\n  - spec.aiManager.redhatRegistryUser: &lt;redhatRegistryUser&gt;\n  - spec.aiManager.redhatRegistryPassword: &lt;redhatRegistryPassword&gt;\n  - spec.eventManager.enabled: ## set to true if you want to install EvetManger\n  - spec.eventManager.caseName: ibm-netcool-prod\n</code></pre> <p>NOTE:</p> <ul> <li><code>entitlement-key</code> is the entitlement key that you copied in MyIBM Container Software Library</li> </ul> <p>Connect your host to your air-gapped environment and connet your OCP to the gitops.</p>"},{"location":"how-to-deploy-airgap-32/#storage-consideration","title":"Storage Consideration","text":"<p>Please refer to Storage considerations for CP4WAIOSP 3.2.</p> <p>In this tutorial, we are using Ceph, you can select different storage based on your system requirement.</p> <p>From ArgoCD UI, click <code>NEW APP</code> and input parameters as follows for Ceph and then <code>Create</code>.</p> <p>The parameters for Ceph are as follows:</p> <pre><code>- GENERAL\n  - Application Name: ceph\n  - Project: default\n  - SYNC POLICY: Automatic\n- SOURCE\n  - REPO URL : https://github.com/IBM/cp4waiops-gitops\n  - Target version: HEAD\n  - path: ceph\n- DESTINATION\n  - Cluster URL: &lt;ocp-cluster-url&gt;\n  - Namespace: rook-ceph\n- DIRECTORY\n  - DIRECTORY RECURSE: check it\n</code></pre> <p></p>"},{"location":"how-to-deploy-airgap-32/#verify-ceph-cluster-installation","title":"Verify Ceph Cluster Installation","text":"<p>After Ceph ArgoCD App was created, you can click the App from ArgoCD UI, and you will see the toplogy of all Ceph resources as follows:</p> <p></p> <p>You can also use the filters on the left to filter out the resources that has been failed, and click the resource to check logs and events.</p> <p></p> <p>You can also check all Ceph Pods using CLI as follows, make sure there is no pod in error state.</p> <p>If there are some pod got error, you can either check logs from ArgoCD UI or use CLI <code>oc logs</code> to check.</p> <pre><code>[root@api.body.cp.fyre.ibm.com ~]# oc get po -n rook-ceph\nNAME                                                              READY   STATUS      RESTARTS   AGE\ncsi-cephfsplugin-7b6jk                                            3/3     Running     0          2d\ncsi-cephfsplugin-l7mvz                                            3/3     Running     0          2d\ncsi-cephfsplugin-provisioner-695b574445-gfcwz                     6/6     Running     6          2d\ncsi-cephfsplugin-provisioner-695b574445-lb64p                     6/6     Running     7          2d\ncsi-cephfsplugin-qcsqz                                            3/3     Running     0          2d\ncsi-cephfsplugin-qdrtl                                            3/3     Running     0          2d\ncsi-cephfsplugin-wj7qq                                            3/3     Running     0          2d\ncsi-cephfsplugin-xlsnb                                            3/3     Running     0          2d\ncsi-rbdplugin-8xwdb                                               3/3     Running     0          2d\ncsi-rbdplugin-b6t9l                                               3/3     Running     0          2d\ncsi-rbdplugin-h965f                                               3/3     Running     0          2d\ncsi-rbdplugin-lv2hp                                               3/3     Running     0          2d\ncsi-rbdplugin-pqvrc                                               3/3     Running     0          2d\ncsi-rbdplugin-provisioner-7f9847cd48-48gqk                        6/6     Running     0          2d\ncsi-rbdplugin-provisioner-7f9847cd48-wxh2z                        6/6     Running     12         2d\ncsi-rbdplugin-x8cw9                                               3/3     Running     0          2d\nrook-ceph-crashcollector-worker0.body.cp.fyre.ibm.com-88f5bnbdc   1/1     Running     0          2d\nrook-ceph-crashcollector-worker1.body.cp.fyre.ibm.com-d4c7gdcts   1/1     Running     0          2d\nrook-ceph-crashcollector-worker2.body.cp.fyre.ibm.com-7767p8fxm   1/1     Running     0          2d\nrook-ceph-crashcollector-worker3.body.cp.fyre.ibm.com-6c5cqs4lk   1/1     Running     0          2d\nrook-ceph-crashcollector-worker4.body.cp.fyre.ibm.com-787f99czf   1/1     Running     0          2d\nrook-ceph-crashcollector-worker5.body.cp.fyre.ibm.com-94d4b654q   1/1     Running     0          2d\nrook-ceph-mds-myfs-a-7d48d48497-sbhld                             1/1     Running     0          2d\nrook-ceph-mds-myfs-b-66f4b746c7-2fnl2                             1/1     Running     0          2d\nrook-ceph-mgr-a-5c84cd7b7b-574lf                                  1/1     Running     0          2d\nrook-ceph-mon-a-7b947ddf45-74p49                                  1/1     Running     0          2d\nrook-ceph-mon-b-7cf885c589-5j6r9                                  1/1     Running     0          2d\nrook-ceph-mon-c-bcb6575d8-g9l5w                                   1/1     Running     0          2d\nrook-ceph-operator-54649856c4-cdx24                               1/1     Running     0          2d\nrook-ceph-osd-0-c44985597-gwkqk                                   1/1     Running     0          2d\nrook-ceph-osd-1-6f7d5cc955-v4862                                  1/1     Running     0          2d\nrook-ceph-osd-2-58df99c46f-5kl8z                                  1/1     Running     0          2d\nrook-ceph-osd-3-5c8579456c-bpcqz                                  1/1     Running     0          2d\nrook-ceph-osd-4-5668c69fbf-kvdf6                                  1/1     Running     0          2d\nrook-ceph-osd-5-cbbdb95-cqvjd                                     1/1     Running     0          2d\nrook-ceph-osd-prepare-worker0.body.cp.fyre.ibm.com-bxr7t          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker1.body.cp.fyre.ibm.com-fftd8          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker2.body.cp.fyre.ibm.com-scg84          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker3.body.cp.fyre.ibm.com-m488b          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker4.body.cp.fyre.ibm.com-dxcm5          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker5.body.cp.fyre.ibm.com-jclnq          0/1     Completed   0          4h16m\n</code></pre>"},{"location":"how-to-deploy-airgap-32/#install-cp4waiops-using-gitops","title":"Install CP4WAIOPS using GitOps","text":"<p>Same as Ceph, you can follow same steps to install Cloud Pak for Watson AIOps using GitOps.</p> <p>The parameters for Cloud Pak for Watson AIOps are as follows:</p> <pre><code>- GENERAL\n  - Application Name: anyname(like \"cp4waiops\")\n  - Project: default\n  - SYNC POLICY: Automatic\n- SOURCE\n  - REPO URL : https://github.com/IBM/cp4waiops-gitops\n  - Target version: HEAD\n  - path: config/3.2/cp4waiops\n- DESTINATION\n  - Cluster URL: &lt;ocp-cluster-url&gt;\n  - Namespace: cp4waiops\n- HELM\n  - spec.localDockerRegistryHost: &lt;localDockerRegistryHost&gt;\n  - spec.localDockerRegistryPort: &lt;localDockerRegistryPort&gt;\n  - spec.localDockerRegistryUser: &lt;localDockerRegistryUser&gt;\n  - spec.localDockerRegistryPassword: &lt;localDockerRegistryPassword&gt;\n  - spec.storageClass: rook-cephfs\n  - spec.storageClassLargeBlock: rook-cephfs\n  - spec.aiManager.enabled: true  ## set to true if you want to install AIManager\n  - spec.aiManager.namespace: ibm-cp-waiops\n  - spec.aiManager.caseName: ibm-cp-waiops\n  - spec.aiManager.caseVersion: 1.1.0\n  - spec.aiManager.channel: v3.2\n  - spec.aiManager.size: small\n  - spec.eventManager.enabled: false ## set to true if you want to install EvetManger\n  - spec.eventManager.namespace: ibm-cp-waiops\n  - spec.eventManager.version: 1.6.3.2\n  - spec.eventManager.caseName: ibm-netcool-prod\n  - spec.eventManager.clusterDomain: apps.clustername.*.*.com\n  - spec.eventManager.channel: v1.5\n  - spec.eventManager.deploymentType: trial\n</code></pre> <p>NOTE: <code>spec.dockerPassword</code> is the entitlement key that you copied in My IBM Container Software Library.</p> <p></p>"},{"location":"how-to-deploy-airgap-32/#verify-cp4waiops-installation","title":"Verify CP4WAIOPS Installation","text":"<p>After both Ceph and Cloud Pak for Watson AIOps are ready, you will be able to see those two Apps from Argo CD UI as follows with status as <code>Healthy and Synced</code>.</p> <p></p> <p>Same as Ceph, you can also check the topology of Cloud Pak for Watson AIOps using ArgoCD UI as follows:</p> <p></p> <p>You can also check via termial as follows, and make sure there is no error pods.</p> <p>If there are some pod got error, you can either check logs from ArgoCD UI or use CLI <code>oc logs</code> to check.</p> <pre><code>[root@api.body.cp.fyre.ibm.com ~]# oc get po -n cp4waiops\nNAME                                                              READY   STATUS      RESTARTS   AGE\naimanager-aio-ai-platform-api-server-7c877989d6-7jh55             1/1     Running     0          47h\naimanager-aio-change-risk-654884bd8c-6xpxw                        1/1     Running     0          47h\naimanager-aio-chatops-orchestrator-7c54fc5664-rtmrp               1/1     Running     0          47h\naimanager-aio-chatops-slack-integrator-77fc9499c4-wtclt           1/1     Running     0          47h\naimanager-aio-chatops-teams-integrator-577f6b85bf-j2995           1/1     Running     0          47h\naimanager-aio-controller-86875d4b7-jfwwp                          1/1     Running     0          47h\naimanager-aio-create-secrets-ccjdg                                0/1     Completed   0          47h\naimanager-aio-create-truststore-5hxps                             0/1     Completed   0          47h\naimanager-aio-curator-job-27362220-k59t8                          0/1     Completed   0          142m\naimanager-aio-curator-job-27362280-n2w88                          0/1     Completed   0          82m\naimanager-aio-curator-job-27362340-qkwln                          0/1     Completed   0          22m\naimanager-aio-log-anomaly-detector-fdfcbb96b-rpb9q                1/1     Running     0          47h\naimanager-aio-log-anomaly-detector-fdfcbb96b-v426m                1/1     Running     0          47h\naimanager-aio-similar-incidents-service-77cc9d699f-qlxgg          1/1     Running     0          47h\naimanager-ibm-minio-0                                             1/1     Running     0          47h\naimanager-operator-585d799f9f-w22vz                               1/1     Running     0          47h\naiops-ai-model-ui-674b4f77f9-qv56n                                1/1     Running     0          47h\naiops-akora-ui-7bc6d5dd6b-6n9rs                                   1/1     Running     0          47h\naiops-application-details-ui-66779f957b-fqfhk                     1/1     Running     0          47h\naiops-base-ui-5b9f885888-pvm7z                                    1/1     Running     0          47h\naiops-connections-ui-7996699c55-m79fl                             1/1     Running     0          47h\naiops-ir-analytics-classifier-75869fd78b-p2s9v                    1/1     Running     0          47h\naiops-ir-analytics-probablecause-6dd5ffd867-rrg6b                 1/1     Running     2          47h\naiops-ir-analytics-spark-master-5cd57946d4-99bqt                  1/1     Running     0          47h\naiops-ir-analytics-spark-pipeline-composer-795f965b6d-vkjqw       1/1     Running     0          47h\naiops-ir-analytics-spark-worker-65d57f7f9c-4nsb8                  1/1     Running     0          47h\naiops-ir-core-archiving-754dcb5fcb-jm82z                          1/1     Running     0          47h\naiops-ir-core-archiving-setup-rrlkh                               0/1     Completed   0          47h\naiops-ir-core-cem-users-65b9b699b9-hzh9b                          1/1     Running     0          47h\naiops-ir-core-esarchiving-67dbb7c5d7-wg7dx                        1/1     Running     0          47h\naiops-ir-core-logstash-6c89d66f79-tlfcl                           1/1     Running     0          47h\naiops-ir-core-ncobackup-0                                         2/2     Running     0          47h\naiops-ir-core-ncodl-api-59f977b475-lx7n4                          1/1     Running     0          47h\naiops-ir-core-ncodl-if-66cf44c565-lkkgx                           1/1     Running     0          47h\naiops-ir-core-ncodl-ir-7469fd4866-wjfvf                           1/1     Running     0          47h\naiops-ir-core-ncodl-jobmgr-76d74b5567-t77wc                       1/1     Running     0          47h\naiops-ir-core-ncodl-setup-8hx6c                                   0/1     Completed   0          47h\naiops-ir-core-ncodl-std-7677546c8d-dbqm9                          1/1     Running     0          47h\naiops-ir-core-ncodl-std-7677546c8d-wf82d                          1/1     Running     0          47h\naiops-ir-core-ncoprimary-0                                        1/1     Running     0          47h\naiops-ir-lifecycle-create-policies-job-dljxp                      0/1     Completed   0          47h\naiops-ir-lifecycle-eventprocessor-ep-jobmanager-0                 2/2     Running     0          47h\naiops-ir-lifecycle-eventprocessor-ep-taskmanager-0                1/1     Running     0          47h\naiops-ir-lifecycle-logstash-77579f5d7f-9rhsx                      1/1     Running     0          47h\naiops-ir-lifecycle-policy-grpc-svc-6b59698569-cvhvq               1/1     Running     0          47h\naiops-ir-lifecycle-policy-registry-svc-68647d4cdc-t27mw           1/1     Running     0          47h\naiops-ir-lifecycle-policy-registry-svc-job-8gk89                  0/1     Completed   3          47h\naiops-ir-ui-api-graphql-68488c7675-87mbp                          1/1     Running     0          47h\naiops-topology-cassandra-0                                        1/1     Running     0          47h\naiops-topology-cassandra-auth-secret-generator-7mm84              0/1     Completed   0          47h\naiops-topology-file-observer-5757769dd5-xxc8j                     1/1     Running     0          47h\naiops-topology-kubernetes-observer-d4c8bcb55-ddbcg                1/1     Running     0          47h\naiops-topology-layout-6b957b5bbb-m28rd                            1/1     Running     0          47h\naiops-topology-merge-76c494795f-5b65g                             1/1     Running     0          47h\naiops-topology-observer-service-6f5d6fb44b-jswwp                  1/1     Running     0          47h\naiops-topology-rest-observer-799bfdf4c8-5nt6n                     1/1     Running     0          47h\naiops-topology-search-6cd7cc9d8-64bdk                             1/1     Running     0          47h\naiops-topology-secret-manager-2b84s                               0/1     Completed   0          47h\naiops-topology-servicenow-observer-84c588df5b-gm6p2               1/1     Running     0          47h\naiops-topology-status-58ddcdc845-mqpzg                            1/1     Running     0          47h\naiops-topology-topology-577b988f78-kc2m6                          1/1     Running     2          47h\naiops-topology-ui-api-bbd74965d-gzlfd                             1/1     Running     0          47h\naiops-topology-vmvcenter-observer-86b6c8dc44-krvtj                1/1     Running     0          47h\naiopsedge-github-topology-integrator-7b9db59cd8-nbdgz             1/1     Running     0          47h\naiopsedge-operator-controller-manager-9b68ddd75-5rqqz             1/1     Running     1          47h\naiopsedge-operator-controller-manager-9b68ddd75-xj7tq             1/1     Running     1          47h\nasm-operator-548c8894fd-r2dgv                                     1/1     Running     0          47h\nc-example-couchdbcluster-m-0                                      3/3     Running     0          47h\nc-example-redis-m-0                                               4/4     Running     0          47h\nc-example-redis-m-1                                               4/4     Running     0          47h\nc-example-redis-m-2                                               4/4     Running     0          47h\nc-example-redis-s-0                                               4/4     Running     0          47h\nc-example-redis-s-1                                               4/4     Running     0          47h\nc-example-redis-s-2                                               4/4     Running     0          47h\ncamel-k-kit-c7c60rolvegv49tvh8fg-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60sglvegv49tvh8g0-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60tglvegv49tvh8gg-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60tolvegv49tvh8h0-1-build                          0/1     Completed   0          47h\ncamel-k-operator-684f46fc4d-s6hf2                                 1/1     Running     0          47h\nconfigure-aiops-network-policy-967ll                              0/1     Completed   0          47h\nconnector-controller-bc7fc6668-f8nn5                              1/1     Running     0          47h\nconnector-synchronizer-7d4546ddd4-5kbrl                           1/1     Running     0          47h\ncouchdb-operator-d5cb7ff8c-rjnhx                                  1/1     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-jobmanager-0                 2/2     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-jobmanager-1                 2/2     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-taskmanager-0                1/1     Running     1          47h\ncp4waiops-eventprocessor-eve-29ee-ep-taskmanager-1                1/1     Running     0          47h\ncp4waiops-image-pull-secret-6fprf                                 0/1     Completed   0          2d\ncp4waiops-patch-j4qrm                                             0/1     Completed   0          2d\ncp4waiops-postgres-keeper-0                                       1/1     Running     0          47h\ncp4waiops-postgres-postgresql-create-cluster-7xb6t                0/1     Completed   0          47h\ncp4waiops-postgres-proxy-648bc64fd-x4mvv                          1/1     Running     0          47h\ncp4waiops-postgres-sentinel-5878f67f46-gvv7l                      1/1     Running     0          47h\ncp4waiops-postgresdb-postgresql-create-database-9j6kq             0/1     Completed   0          47h\ncreate-secrets-job-nx6dg                                          0/1     Completed   0          47h\ngateway-kong-5d45b77fb4-tgjcv                                     2/2     Running     2          47h\ngateway-kong-config-svc-27362360-9dmzc                            0/1     Completed   0          2m51s\niaf-core-operator-controller-manager-58dfd97f5c-bdd9t             1/1     Running     0          2d\niaf-eventprocessing-operator-controller-manager-5bc597797f6fxm4   1/1     Running     1          2d\niaf-flink-operator-controller-manager-7dc56c9b68-6rgtk            1/1     Running     0          2d\niaf-operator-controller-manager-6bc8f44ff7-rrrnx                  1/1     Running     0          2d\niaf-system-elasticsearch-es-aiops-0                               2/2     Running     0          47h\niaf-system-entity-operator-6b5444f575-7tdfw                       3/3     Running     0          47h\niaf-system-kafka-0                                                1/1     Running     0          47h\niaf-system-zookeeper-0                                            1/1     Running     0          47h\niaf-zen-tour-job-fhdfr                                            0/1     Completed   0          47h\niam-config-job-tfsst                                              0/1     Completed   0          47h\nibm-aiops-orchestrator-6c7cfc85b7-wqdnr                           1/1     Running     0          2d\nibm-cloud-databases-redis-operator-854cf65c4f-4rrvn               1/1     Running     0          47h\nibm-common-service-operator-5cd6947dc8-z8plb                      1/1     Running     0          2d\nibm-elastic-operator-controller-manager-5d6c467b55-wtrvg          1/1     Running     0          2d\nibm-ir-ai-operator-controller-manager-59b88c6bf6-ncnbt            1/1     Running     7          47h\nibm-kong-operator-6ff97bcdb9-rl7cp                                1/1     Running     0          47h\nibm-nginx-cd84b4d8-7ttn2                                          1/1     Running     0          47h\nibm-nginx-cd84b4d8-zp4t2                                          1/1     Running     0          47h\nibm-postgreservice-operator-controller-manager-8b7bdf589-hbg2g    1/1     Running     2          47h\nibm-secure-tunnel-operator-657dd7b78f-tsgws                       1/1     Running     0          47h\nibm-vault-deploy-consul-0                                         1/1     Running     0          47h\nibm-vault-deploy-vault-0                                          1/1     Running     0          47h\nibm-vault-deploy-vault-cron-job-27361440-qxpjl                    0/1     Completed   0          15h\nibm-vault-deploy-vault-injector-596567d459-wzkws                  1/1     Running     0          47h\nibm-vault-operator-controller-manager-5957bb5ff9-4zdrb            1/1     Running     0          47h\nibm-watson-aiops-ui-operator-controller-manager-b8cf6fff7-msspt   1/1     Running     0          47h\nir-core-operator-controller-manager-76dbdb699d-g97ng              1/1     Running     7          47h\nir-lifecycle-operator-controller-manager-64bdd8f7b6-pn46g         1/1     Running     9          47h\nmodel-train-classic-operator-56d487585c-4dv5b                     1/1     Running     2          47h\nmodeltrain-ibm-modeltrain-lcm-865b7f85cc-jfq4z                    1/1     Running     0          47h\nmodeltrain-ibm-modeltrain-ratelimiter-595f4f478-r9dwp             1/1     Running     0          47h\nmodeltrain-ibm-modeltrain-trainer-5b7f7888b5-c8cz5                1/1     Running     0          47h\npost-aiops-resources-t4ww9                                        0/1     Completed   0          47h\npost-aiops-translations-t58bb                                     0/1     Completed   0          47h\npost-aiops-update-user-role-kcr8k                                 0/1     Completed   0          47h\nscm-handlers-d655679fc-lvls2                                      2/2     Running     0          47h\nsetup-nginx-job-tn8sc                                             0/1     Completed   0          47h\nsnow-handlers-d8488f6f8-8lhxh                                     2/2     Running     0          47h\nsre-tunnel-controller-84565ff4f8-4qtwl                            1/1     Running     0          47h\nsre-tunnel-tunnel-network-api-589fd6646d-7znnh                    1/1     Running     0          47h\nsre-tunnel-tunnel-ui-mcmtunnelui-fff9b859b-g7dlk                  1/1     Running     0          47h\nusermgmt-5fb7986c7b-dwmk2                                         1/1     Running     0          47h\nusermgmt-5fb7986c7b-ssk86                                         1/1     Running     0          47h\nzen-audit-678b54b548-n7q7f                                        1/1     Running     0          47h\nzen-core-64c6d56db-d25zm                                          1/1     Running     0          47h\nzen-core-64c6d56db-glv65                                          1/1     Running     1          47h\nzen-core-api-85489478d6-95pck                                     1/1     Running     0          47h\nzen-core-api-85489478d6-n9x5s                                     1/1     Running     0          47h\nzen-metastoredb-0                                                 1/1     Running     0          47h\nzen-metastoredb-1                                                 1/1     Running     0          47h\nzen-metastoredb-2                                                 1/1     Running     0          47h\nzen-metastoredb-certs-lblhv                                       0/1     Completed   0          47h\nzen-metastoredb-init-hvlv2                                        0/1     Completed   0          47h\nzen-post-requisite-job-lpkfw                                      0/1     Completed   0          47h\nzen-pre-requisite-job-2klrt                                       0/1     Completed   0          47h\nzen-watcher-d8b795b46-2q6zx                                       1/1     Running     0          47h\n</code></pre>"},{"location":"how-to-deploy-airgap-32/#access-cloud-pak-for-watson-aiops","title":"Access Cloud Pak for Watson AIOps","text":"<p>If all pods are running for Cloud Pak for Watson AIOps, you can login to Cloud Pak for Watson AIOps UI as follows:</p> <ul> <li>Login to OCP UI, click the <code>Red Hat Applications icon</code> on top right.</li> </ul> <p></p> <ul> <li>Click the link for the <code>Cloud Pak for Administration</code>. Log in via <code>OpenShift authentication</code>.</li> </ul> <p></p> <ul> <li>Login to <code>Cloud Pak for Administration</code> and click the top right, select <code>IBM Automation (cp4waiops)</code>.</li> </ul> <p></p> <ul> <li>Log in via <code>OpenShift authentication</code> to Cloud Pak for Watson AIOps UI.</li> </ul> <p></p> <ul> <li>You will be navigated to Cloud Pak for Watson AIOps UI!</li> </ul> <p></p> <ul> <li>Congratulations! You are ready to play with Cloud Pak for Watson AIOps!</li> </ul>"},{"location":"how-to-deploy-airgap-32/#using-cli-to-install-cp4waiops","title":"Using CLI to Install CP4WAIOPS","text":""},{"location":"how-to-deploy-airgap-32/#grant-argocd-cluster-admin-permission_1","title":"Grant ArgoCD Cluster Admin Permission","text":"<pre><code>kind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\nname: argocd-admin\nsubjects:\n- kind: ServiceAccount\nname: openshift-gitops-argocd-application-controller\nnamespace: openshift-gitops\nroleRef:\napiGroup: rbac.authorization.k8s.io\nkind: ClusterRole\nname: cluster-admin\n</code></pre>"},{"location":"how-to-deploy-airgap-32/#login-to-the-argocd-server","title":"Login to the ArgoCD server","text":"<pre><code># OCP 4.8\nargo_route=openshift-gitops-server\nargo_secret=openshift-gitops-cluster\nsa_account=openshift-gitops-argocd-application-controller\n\nargo_pwd=$(oc get secret ${argo_secret} \\\n-n openshift-gitops \\\n-o jsonpath='{.data.admin\\.password}' | base64 -d ; echo ) \\\n&amp;&amp; argo_url=$(oc get route ${argo_route} \\\n-n openshift-gitops \\\n-o jsonpath='{.spec.host}') \\\n&amp;&amp; argocd login \"${argo_url}\" \\\n--username admin \\\n--password \"${argo_pwd}\" \\\n--insecure\n</code></pre>"},{"location":"how-to-deploy-airgap-32/#mirror-image-to-local-registry-with-gitops_1","title":"Mirror Image to Local Registry with GitOps","text":"<pre><code>argocd app create cp4waiops \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/3.2/airgap/imageMirror \\\n--revision HEAD \\\n--dest-namespace image \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.imageMirror_namespace=image \\\n--helm-set spec.localDockerRegistryHost=&lt;localDockerRegistryHost&gt; \\\n--helm-set spec.localDockerRegistryPort=&lt;localDockerRegistryPort&gt; \\\n--helm-set spec.localDockerRegistryUser=&lt;localDockerRegistryUser&gt; \\\n--helm-set spec.localDockerRegistryPassword=&lt;localDockerRegistryPassword&gt; \\\n--helm-set spec.cpRegistryPassword=&lt;entitlement-key&gt; \\\n--helm-set spec.aiManager.enabled=false \\\n--helm-set spec.aiManager.caseName=ibm-cp-waiops \\\n--helm-set spec.aiManager.caseVersion=1.1.0 \\\n--helm-set spec.aiManager.redhatRegistryUser=&lt;redhatRegistryUser&gt; \\\n--helm-set spec.aiManager.redhatRegistryPassword=&lt;redhatRegistryPassword&gt; \\\n--helm-set spec.eventManager.enabled=false \\\n--helm-set spec.eventManager.caseName=ibm-netcool-prod\n</code></pre> <p>NOTE:</p> <ul> <li><code>entitlement-key</code> is the entitlement key that you copied in MyIBM Container Software Library</li> </ul> <p>Connect your host to your air-gapped environment and connet your OCP to the gitops.</p>"},{"location":"how-to-deploy-airgap-32/#storage-consideration_1","title":"Storage Consideration","text":"<p>Please refer to Storage considerations for CP4WAIOSP 3.2.</p> <p>In this tutorial, we are using Ceph, you can select different storage based on your system requirement.</p> <pre><code>argocd app create ceph \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path ceph \\\n--revision HEAD \\\n--dest-namespace rook-ceph \\\n--dest-server https://kubernetes.default.svc \\\n--directory-recurse\n</code></pre>"},{"location":"how-to-deploy-airgap-32/#install-cp4waiops-using-gitops_1","title":"Install CP4WAIOPS using GitOps","text":"<pre><code>argocd app create cp4waiops \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/3.2/cp4waiops \\\n--revision HEAD \\\n--dest-namespace cp4waiops \\\n--dest-server &lt;your airgap OCP cluster&gt; \\\n--helm-set spec.localDockerRegistryHost=&lt;localDockerRegistryHost&gt; \\\n--helm-set spec.localDockerRegistryPort=&lt;localDockerRegistryPort&gt; \\\n--helm-set spec.localDockerRegistryUser=&lt;localDockerRegistryUser&gt; \\\n--helm-set spec.localDockerRegistryPassword=&lt;localDockerRegistryPassword&gt; \\\n--helm-set spec.storageClass=rook-cephfs \\\n--helm-set spec.storageClassLargeBlock=rook-cephfs \\\n--helm-set spec.aiManager.enabled=true \\\n--helm-set spec.aiManager.namespace=cp4waiops \\\n--helm-set spec.aiManager.caseName=ibm-cp-waiops \\\n--helm-set spec.aiManager.caseVersion=1.1.0 \\\n--helm-set spec.aiManager.channel=&lt;redhatRegistryUser&gt; \\\n--helm-set spec.aiManager.size=&lt;redhatRegistryPassword&gt; \\\n--helm-set spec.eventManager.enabled=false \\\n--helm-set spec.eventManager.namespace=eventmanager \\\n--helm-set spec.eventManager.caseName=ibm-netcool-prod \\\n--helm-set spec.eventManager.version=1.6.3.2 \\\n--helm-set spec.eventManager.clusterDomain=apps.clustername.*.*.com \\\n--helm-set spec.eventManager.channel=v1.5 \\\n--helm-set spec.eventManager.deploymentType=trial\n</code></pre> <p>NOTE:</p> <ul> <li> <p><code>entitlement-key</code> is the entitlement key that you copied in MyIBM Container Software Library</p> </li> <li> <p><code>apps.clustername.*.*.com</code> is the domain name of your OCP cluster</p> </li> </ul>"},{"location":"how-to-deploy-airgap-32/#verify-cp4waiops-installation_1","title":"Verify CP4WAIOPS Installation","text":"<p>You can run the command as follows to check:</p> <pre><code>kubectl get application -A\n</code></pre> <p>In this tutorial, the output of the above command is as follows:</p> <pre><code># kubectl get application -A\nNAMESPACE          NAME           SYNC STATUS   HEALTH STATUS\nopenshift-gitops   ceph           Synced        Healthy\nopenshift-gitops   cp4waiops      Synced        Healthy\nopenshift-gitops   mirror-image   Synced        Healthy\n</code></pre> <p>Wait a while and check if all pods under namespace <code>cp4waiops</code> and are running well without any crash.</p> <pre><code>kubectl get pod -n cp4waiops\n</code></pre>"},{"location":"how-to-deploy-airgap-32/#access-cp4waiops-ui","title":"Access CP4WAIOps UI","text":"<p>Refer to Access Cloud Pak for Watson AIOps and play with Cloud Pak for Watson AIOps.</p>"},{"location":"how-to-deploy-cp4waiops-31/","title":"How to deploy cp4waiops 31","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Deploy Cloud Pak for Watson AIOps with OpenShift GitOps</li> <li>Prerequisite</li> <li>Install Infra (Crossplane CP4WAIOPS Provider)<ul> <li>Grant Argo CD Enough Permissions</li> <li>Login to Argo CD</li> <li>Install CP4WAIOPS Provider</li> <li>Verify Crossplane Provider</li> <li>CLI Verify</li> <li>UI Verify</li> </ul> </li> <li>Storage Consideration</li> <li>Deploy Cloud Paks<ul> <li>Create a secret storing your entitlement key:</li> <li>Create a secret storing target ocp cluster kubeconfig :</li> <li>Create a ArgoCD application for installing cp4waiops in-cluster</li> <li>Verify Cloud Paks Installation</li> <li>CLI Verify</li> <li>UI Verify</li> <li>Access CP4WAIOps UI</li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-31/#deploy-cloud-pak-for-watson-aiops-with-openshift-gitops","title":"Deploy Cloud Pak for Watson AIOps with OpenShift GitOps","text":""},{"location":"how-to-deploy-cp4waiops-31/#prerequisite","title":"Prerequisite","text":"<ul> <li>NOTE: Only OpenShift 4.6 with CP4WAIOPS 3.1 are fully tested, NOT A RELEASED FEATURE FOR CP4WAIOPS.</li> <li>Install gitops operator(Red Hat OpenShift GitOps) in ocp operator-hub</li> <li>Install crossplane operator(Upbound Universal Crossplane (UXP)) in ocp operator-hub</li> </ul>"},{"location":"how-to-deploy-cp4waiops-31/#install-infra-crossplane-cp4waiops-provider","title":"Install Infra (Crossplane CP4WAIOPS Provider)","text":""},{"location":"how-to-deploy-cp4waiops-31/#grant-argo-cd-enough-permissions","title":"Grant Argo CD Enough Permissions","text":"<pre><code>kind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\nname: argocd-admin\nsubjects:\n- kind: ServiceAccount\nname: openshift-gitops-argocd-application-controller\nnamespace: openshift-gitops\nroleRef:\napiGroup: rbac.authorization.k8s.io\nkind: ClusterRole\nname: cluster-admin\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-31/#login-to-argo-cd","title":"Login to Argo CD","text":"<p>Login ArgoCD entrance</p> <p> </p> <p>Login Username/Password <pre><code>Username: admin  \nPassword: Please copy the Data value of secret \"openshift-gitops-cluster\" in namespace \"openshift-gitops\"\n</code></pre></p> <p> </p>"},{"location":"how-to-deploy-cp4waiops-31/#install-cp4waiops-provider","title":"Install CP4WAIOPS Provider","text":"<p>Create application. Choose \"New App\" in \"Applications\". Fill in like below, then choose \"create\". </p> <pre><code>GENERAL\nApplication Name: anyname(like \"crossplane-provider\")\nProject: default\nSYNC POLICY: Automatic\n\nSOURCE\nREPO URL : https://github.com/IBM/cp4waiops-gitops\nTarget version: HEAD\npath: config/3.1/argocd-apps/infra\n\nDESTINATION\nCluster URL: https://kubernetes.default.svc\nNamespace: upbound-system\n\nHELM\nmetadata.argocd_app_namespace: openshift-gitops\nmetadata.cp4waiops_provider_namespace: upbound-system\nmetadata.crossplane_namespace: upbound-system\nrepoURL: https://github.com/IBM/cp4waiops-gitops\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-31/#verify-crossplane-provider","title":"Verify Crossplane Provider","text":""},{"location":"how-to-deploy-cp4waiops-31/#cli-verify","title":"CLI Verify","text":"<p>After cp4waiops provider was deployed, you can run the command as follows to check:</p> <pre><code>kubectl get po -n upbound-system\nkubectl get application -A\n</code></pre> <p>In this tutorial, the output of the above command is as follows:</p> <p><pre><code># kubectl get po -n upbound-system\nNAME                                            READY   STATUS      RESTARTS   AGE\nadd-scc-policy-2wgw7                            0/1     Completed   0          98m\ncrossplane-5d88f96479-jdnf2                     1/1     Running     2          4h14m\ncrossplane-provider-cloudpak-57cf9bb7c8-5l852   1/1     Running     0          98m\ncrossplane-rbac-manager-58c6656768-4cgr5        1/1     Running     2          4h14m\nupbound-bootstrapper-67d458bf85-kkgq9           1/1     Running     0          4h14m\nxgql-7b65998b88-p6shn                           1/1     Running     2          4h14m\n</code></pre> <pre><code># kubectl get application -A\nNAMESPACE          NAME                      SYNC STATUS   HEALTH STATUS\nopenshift-gitops   ceph                      Synced        Healthy\nopenshift-gitops   crossplane-provider       Synced        Healthy\nopenshift-gitops   crossplane-provider-app   Synced        Healthy\n</code></pre></p>"},{"location":"how-to-deploy-cp4waiops-31/#ui-verify","title":"UI Verify","text":"<p>From Argo CD UI, you will be able to see there are two applications as follows:</p> <ul> <li>There are two applications, one is <code>crossplane-provider</code> and another is <code>crossplane-provider-app</code>. The <code>crossplane-provider</code> bring up the <code>crossplane-provider-app</code> via the app-of-apps pattern.</li> </ul> <p></p> <ul> <li>This is the deatail of app <code>crossplane-provider</code>, and the following picture describes the app-of-apps pattern.</li> </ul> <p></p> <ul> <li>The following picture is the detail of the <code>crossplane-provider-app</code>, you can see all of the resources for this app. </li> </ul>"},{"location":"how-to-deploy-cp4waiops-31/#storage-consideration","title":"Storage Consideration","text":"<p>It depends where the OCP comes from , if you're using fyre , then could create gitops application</p> <pre><code>GENERAL\nApplication Name: ceph\nProject: default\nSYNC POLICY: Automatic\n\nSOURCE\nREPO URL : https://github.com/IBM/cp4waiops-gitops\nTarget version: HEAD\npath: ceph\n\nDESTINATION\nCluster URL: https://kubernetes.default.svc\nNamespace: rook-ceph\nDIRECTORY\nDIRECTORY RECURSE: tick it\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-31/#deploy-cloud-paks","title":"Deploy Cloud Paks","text":""},{"location":"how-to-deploy-cp4waiops-31/#create-a-secret-storing-your-entitlement-key","title":"Create a secret storing your entitlement key:","text":"<pre><code>kubectl create secret generic image-pull-secret --from-literal=cp.icr.io=cp:&lt;entitlement-key&gt; -n crossplane-system\n</code></pre> <p>Note: refer to CP4WAIOPS-KC to replace the <code>entitlement-key</code> </p>"},{"location":"how-to-deploy-cp4waiops-31/#create-a-secret-storing-target-ocp-cluster-kubeconfig","title":"Create a secret storing target ocp cluster kubeconfig :","text":"<pre><code>kubectl create secret generic openshift-cluster-kubeconfig --from-file=credentials=&lt;kubeconfig&gt; -n crossplane-system\n</code></pre> <p>Note: please replace the kubeconfig to your real file , default value : /root/.kube/config</p>"},{"location":"how-to-deploy-cp4waiops-31/#create-a-argocd-application-for-installing-cp4waiops-in-cluster","title":"Create a ArgoCD application for installing cp4waiops in-cluster","text":"<pre><code>GENERAL\nApplication Name: anyname(like \"cp4waiops\")\nProject: default\nSYNC POLICY: Automatic\n\nSOURCE\nREPO URL : https://github.com/IBM/cp4waiops-gitops\nTarget version: HEAD\npath: config/3.1/cp4waiops\n\nDESTINATION\nCluster URL: https://kubernetes.default.svc\nNamespace: upbound-system\n\nHELM\nspec.cp4waiops_namespace: cp4waiops\nspec.channel: v3.1\nspec.imageCatalog: icr.io/cpopen/aiops-orchestrator-catalog:3.1-latest\nspec.imagePullSecret: ibm-entitlement-key\nspec.kubeConfigSecretName: openshift-cluster-kubeconfig\nspec.kubeConfigSecretNS: crossplane-system\nspec.providerConfigRef: openshift-cluster-provider-config \nspec.storageClass: rook-cephfs\nspec.storageClassLargeBlock: rook-cephfs\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-31/#verify-cloud-paks-installation","title":"Verify Cloud Paks Installation","text":""},{"location":"how-to-deploy-cp4waiops-31/#cli-verify_1","title":"CLI Verify","text":"<p>After instana instance was deployed, you can run the command as follows to check:</p> <pre><code>kubectl get application -A\n</code></pre> <p>In this tutorial, the output of the above command is as follows:</p> <pre><code># kubectl get application -A\nNAMESPACE          NAME                      SYNC STATUS   HEALTH STATUS\nopenshift-gitops   ceph                      Synced        Healthy\nopenshift-gitops   cp4waiops                 Synced        Healthy\nopenshift-gitops   crossplane-provider       Synced        Healthy\nopenshift-gitops   crossplane-provider-app   Synced        Healthy\n</code></pre> <p>Wait a while and check if all pods under namespace <code>cp4waiops</code> and are running well without any crash.</p> <pre><code>kubectl get pod -n cp4waiops\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-31/#ui-verify_1","title":"UI Verify","text":"<p>From Argo CD UI, you will be able to see there are another application added as follows:</p> <p></p> <ul> <li>The following picture is the detail of the <code>cp4waiops</code>, you can see all of the resources for this app. </li> </ul>"},{"location":"how-to-deploy-cp4waiops-31/#access-cp4waiops-ui","title":"Access CP4WAIOps UI","text":"<p>After you successfully install IBM Cloud Pak for Watson AIOps, check CP4WAIOPS-KC to get the URL for accessing the IBM Cloud Pak for Watson AIOps console, username and password.</p> <p></p> <p>After click <code>Log In</code>, you will be navigated to the CP4WAIOps UI as follows.</p> <p></p>"},{"location":"how-to-deploy-cp4waiops-32/","title":"How to deploy cp4waiops 32","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Deploy CP4WAIOPS (Cloud Pak for Watson AIOps) 3.2 with GitOps</li> <li>Prerequisite</li> <li>Install CP4WAIOPS Using OpenShift Web Console<ul> <li>Grant ArgoCD Cluster Admin Permission</li> <li>Login to ArgoCD</li> <li>Storage Consideration</li> <li>Verify Ceph Cluster Installation</li> <li>Install AI Manager</li> <li>Install Event Manager</li> <li>Install Using All-in-One Configuration</li> <li>Install AI Manager and Event Manager in One Go</li> <li>Install CP4WAIOps using Custom Build</li> <li>Verify CP4WAIOPS Installation</li> <li>Access Cloud Pak for Watson AIOps</li> </ul> </li> <li>Using CLI to Install CP4WAIOPS<ul> <li>Grant ArgoCD Cluster Admin Permission</li> <li>Login to ArgoCD</li> <li>(Optional) Storage Considerations</li> <li>Install AI Manager</li> <li>Install Event Manager</li> <li>Install Using All-in-One Configuration</li> <li>Verify CP4WAIOps Installation</li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-32/#deploy-cp4waiops-cloud-pak-for-watson-aiops-32-with-gitops","title":"Deploy CP4WAIOPS (Cloud Pak for Watson AIOps) 3.2 with GitOps","text":""},{"location":"how-to-deploy-cp4waiops-32/#prerequisite","title":"Prerequisite","text":"<ul> <li>NOTE: Only OpenShift 4.8 with CP4WAIOPS 3.2 are fully tested, NOT A RELEASED FEATURE FOR CP4WAIOPS.</li> <li>Refer to System requirements for Cloud Pak for Watson AIOps 3.2</li> <li>GitOps, refer to Installing GitOps Operator in web console</li> </ul>"},{"location":"how-to-deploy-cp4waiops-32/#install-cp4waiops-using-openshift-web-console","title":"Install CP4WAIOPS Using OpenShift Web Console","text":""},{"location":"how-to-deploy-cp4waiops-32/#grant-argocd-cluster-admin-permission","title":"Grant ArgoCD Cluster Admin Permission","text":"<ul> <li> <p>From the Red Hat OpenShift Console, go to User Management &gt; RoleBindings &gt; Create binding.</p> </li> <li> <p>Use the Form view to configure the properties for the ClusterRoleBinding, and select the Create button.</p> </li> <li>Binding type<ul> <li>Cluster-wide role binding (ClusterRoleBinding)</li> </ul> </li> <li>RoleBinding<ul> <li>Name: argocd-admin</li> </ul> </li> <li>Role<ul> <li>Role Name: cluster-admin</li> </ul> </li> <li>Subject<ul> <li>ServiceAccount: check it</li> <li>Subject namespace: openshift-gitops</li> <li>Subject name: openshift-gitops-argocd-application-controller</li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-32/#login-to-argocd","title":"Login to ArgoCD","text":"<ul> <li>You can now login to gitops UI as follows by clicking the menu on OpenShift top right.</li> </ul> <ul> <li>GitOps UI will be poped up and you can login with <code>LOG IN VIA OPENSHIFT</code>.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-32/#storage-consideration","title":"Storage Consideration","text":"<p>Please refer to Storage considerations for CP4WAIOSP 3.2.</p> <p>In this tutorial, we are using Ceph, you can select different storage based on your system requirement.</p> <p>From ArgoCD UI, click <code>NEW APP</code> and input parameters as follows for Ceph and then <code>Create</code>.</p> <p>The parameters for Ceph are as follows:</p> <ul> <li>GENERAL</li> <li>Application Name: ceph</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> <li>SOURCE</li> <li>REPO URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Target version: HEAD</li> <li>path: config/ceph</li> <li>DESTINATION</li> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: rook-ceph</li> </ul> <p></p>"},{"location":"how-to-deploy-cp4waiops-32/#verify-ceph-cluster-installation","title":"Verify Ceph Cluster Installation","text":"<p>After Ceph ArgoCD App was created, you can click the App from ArgoCD UI, and you will see the toplogy of all Ceph resources as follows:</p> <p></p> <p>You can also use the filters on the left to filter out the resources that has been failed, and click the resource to check logs and events.</p> <p></p> <p>You can also check all Ceph Pods using CLI as follows, make sure there is no pod in error state.</p> <p>If there are some pod got error, you can either check logs from ArgoCD UI or use CLI <code>oc logs</code> to check.</p> <pre><code>[root@api.body.cp.fyre.ibm.com ~]# oc get po -n rook-ceph\nNAME                                                              READY   STATUS      RESTARTS   AGE\ncsi-cephfsplugin-7b6jk                                            3/3     Running     0          2d\ncsi-cephfsplugin-l7mvz                                            3/3     Running     0          2d\ncsi-cephfsplugin-provisioner-695b574445-gfcwz                     6/6     Running     6          2d\ncsi-cephfsplugin-provisioner-695b574445-lb64p                     6/6     Running     7          2d\ncsi-cephfsplugin-qcsqz                                            3/3     Running     0          2d\ncsi-cephfsplugin-qdrtl                                            3/3     Running     0          2d\ncsi-cephfsplugin-wj7qq                                            3/3     Running     0          2d\ncsi-cephfsplugin-xlsnb                                            3/3     Running     0          2d\ncsi-rbdplugin-8xwdb                                               3/3     Running     0          2d\ncsi-rbdplugin-b6t9l                                               3/3     Running     0          2d\ncsi-rbdplugin-h965f                                               3/3     Running     0          2d\ncsi-rbdplugin-lv2hp                                               3/3     Running     0          2d\ncsi-rbdplugin-pqvrc                                               3/3     Running     0          2d\ncsi-rbdplugin-provisioner-7f9847cd48-48gqk                        6/6     Running     0          2d\ncsi-rbdplugin-provisioner-7f9847cd48-wxh2z                        6/6     Running     12         2d\ncsi-rbdplugin-x8cw9                                               3/3     Running     0          2d\nrook-ceph-crashcollector-worker0.body.cp.fyre.ibm.com-88f5bnbdc   1/1     Running     0          2d\nrook-ceph-crashcollector-worker1.body.cp.fyre.ibm.com-d4c7gdcts   1/1     Running     0          2d\nrook-ceph-crashcollector-worker2.body.cp.fyre.ibm.com-7767p8fxm   1/1     Running     0          2d\nrook-ceph-crashcollector-worker3.body.cp.fyre.ibm.com-6c5cqs4lk   1/1     Running     0          2d\nrook-ceph-crashcollector-worker4.body.cp.fyre.ibm.com-787f99czf   1/1     Running     0          2d\nrook-ceph-crashcollector-worker5.body.cp.fyre.ibm.com-94d4b654q   1/1     Running     0          2d\nrook-ceph-mds-myfs-a-7d48d48497-sbhld                             1/1     Running     0          2d\nrook-ceph-mds-myfs-b-66f4b746c7-2fnl2                             1/1     Running     0          2d\nrook-ceph-mgr-a-5c84cd7b7b-574lf                                  1/1     Running     0          2d\nrook-ceph-mon-a-7b947ddf45-74p49                                  1/1     Running     0          2d\nrook-ceph-mon-b-7cf885c589-5j6r9                                  1/1     Running     0          2d\nrook-ceph-mon-c-bcb6575d8-g9l5w                                   1/1     Running     0          2d\nrook-ceph-operator-54649856c4-cdx24                               1/1     Running     0          2d\nrook-ceph-osd-0-c44985597-gwkqk                                   1/1     Running     0          2d\nrook-ceph-osd-1-6f7d5cc955-v4862                                  1/1     Running     0          2d\nrook-ceph-osd-2-58df99c46f-5kl8z                                  1/1     Running     0          2d\nrook-ceph-osd-3-5c8579456c-bpcqz                                  1/1     Running     0          2d\nrook-ceph-osd-4-5668c69fbf-kvdf6                                  1/1     Running     0          2d\nrook-ceph-osd-5-cbbdb95-cqvjd                                     1/1     Running     0          2d\nrook-ceph-osd-prepare-worker0.body.cp.fyre.ibm.com-bxr7t          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker1.body.cp.fyre.ibm.com-fftd8          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker2.body.cp.fyre.ibm.com-scg84          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker3.body.cp.fyre.ibm.com-m488b          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker4.body.cp.fyre.ibm.com-dxcm5          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker5.body.cp.fyre.ibm.com-jclnq          0/1     Completed   0          4h16m\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-32/#install-ai-manager","title":"Install AI Manager","text":"<p>You can install CP4WAIOps - AI Manager using GitOps by creating an Argo CD App. The parameters for AI Manager are as follows:</p> <ul> <li>GENERAL</li> <li>Application Name: anyname (e.g.: \"aimanager-app\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> <li>SOURCE</li> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: HEAD</li> <li>path: config/3.2/ai-manager</li> <li>DESTINATION</li> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: cp4waiops</li> <li>PARAMETERS</li> <li>spec.imageCatalog: icr.io/cpopen/ibm-operator-catalog:latest</li> <li>spec.dockerUsername: cp</li> <li>spec.dockerPassword: REPLACE_IT</li> <li>spec.storageClass: rook-cephfs</li> <li>spec.storageClassLargeBlock: rook-cephfs</li> <li>spec.aiManager.channel: v3.2</li> <li>spec.aiManager.size: small</li> <li>spec.aiManager.namespace: cp4waiops</li> <li>spec.aiManager.pakModules.aiopsFoundation.enabled: true</li> <li>spec.aiManager.pakModules.applicationManager.enabled: true</li> <li>spec.aiManager.pakModules.aiManager.enabled: true</li> <li>spec.aiManager.pakModules.connection.enabled: true</li> </ul> <p>NOTE:</p> <ul> <li>For <code>Repository URL</code> and <code>Revision</code> field, if you use a repository forked from the official CP4WAIOps GitOps repository and/or on a different branch, please fill these fields using your own values. For example, if you use <code>https://github.com/&lt;myaccount&gt;/cp4waiops-gitops</code> and <code>dev</code> branch, the two fields need to be changed accordingly.</li> <li>For <code>spec.dockerPassword</code>, it is the entitlement key that you can copy from My IBM Container Software Library.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-32/#install-event-manager","title":"Install Event Manager","text":"<p>You can install CP4WAIOps - Event Manager using GitOps by creating an Argo CD App. The parameters for Event Manager are as follows:</p> <ul> <li>GENERAL</li> <li>Application Name: anyname (e.g.: \"eventmanager-app\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> <li>SOURCE</li> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: HEAD</li> <li>path: config/3.2/event-manager</li> <li>DESTINATION</li> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: noi </li> <li>PARAMETERS</li> <li>spec.imageCatalog: icr.io/cpopen/ibm-operator-catalog:latest</li> <li>spec.dockerUsername: cp</li> <li>spec.dockerPassword: REPLACE_IT</li> <li>spec.storageClass: rook-cephfs</li> <li>spec.storageClassLargeBlock: rook-cephfs</li> <li>spec.eventManager.version: 1.6.3.2</li> <li>spec.eventManager.clusterDomain: REPLACE_IT</li> <li>spec.eventManager.channel: v1.5</li> <li>spec.eventManager.deploymentType: trial</li> <li>spec.eventManager.namespace: noi</li> </ul> <p>NOTE:</p> <ul> <li>For <code>Repository URL</code> and <code>Revision</code> field, if you use a repository forked from the official CP4WAIOps GitOps repository and/or on a different branch, please fill these fields using your own values. For example, if you use <code>https://github.com/&lt;myaccount&gt;/cp4waiops-gitops</code> and <code>dev</code> branch, the two fields need to be changed accordingly.</li> <li>For <code>spec.dockerPassword</code>, it is the entitlement key that you can copy from My IBM Container Software Library.</li> <li>For <code>spec.eventManager.clusterDomain</code>, it is the domain name of the cluster where Event Manager is installed. Use fully qualified domain name (FQDN), e.g.: apps.clustername.abc.xyz.com.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-32/#install-using-all-in-one-configuration","title":"Install Using All-in-One Configuration","text":""},{"location":"how-to-deploy-cp4waiops-32/#install-ai-manager-and-event-manager-in-one-go","title":"Install AI Manager and Event Manager in One Go","text":"<p>The all-in-one configuration allows you to install following components in one go:</p> <ul> <li>Ceph storage (optional)</li> <li>AI Manager</li> <li>Event Manager</li> </ul> <p>Just fill in the form using the suggested field values listed in following table when you create the Argo CD App:</p> Field Value Application Name anyname (e.g. cp4waiops-app) Project default Sync Policy Automatic Repository URL https://github.com/IBM/cp4waiops-gitops Revision HEAD Path config/all-in-one Cluster URL https://kubernetes.default.svc Namespace openshift-gitops <p>Besides the basic information, when filling in the form, you can also update the following install parameters that are commonly used to customize the install behavior.</p> Parameter Type Default Value Description argocd.cluster string openshift The type of the cluster that Argo CD runs on, valid values include: openshift, kubernetes. argocd.allowLocalDeploy bool true Allow apps to be deployed on the same cluster where Argo CD runs. rookceph.enabled bool true Specify whether or not to install Ceph as storage used by CP4WAIOps. cp4waiops.version string v3.2 Specify the version of CP4WAIOps, e.g.: v3.2, v3.3. cp4waiops.profile string small The CP4WAIOps deployment profile, e.g.: x-small, small, large. cp4waiops.dockerUsername string cp The username of image registry used to pull images. cp4waiops.dockerPassword string REPLACE_IT The password of image registry used to pull images. cp4waiops.aiManager.enabled bool true Specify whether or not to install AI Manager. cp4waiops.aiManager.namespace string cp4waiops The namespace where AI Manager is installed. cp4waiops.aiManager.instanceName string aiops-installation The instance name of AI Manager. cp4waiops.eventManager.enabled bool true Specify whether or not to install Event Manager. cp4waiops.eventManager.namespace string noi The namespace where Event Manager is installed. cp4waiops.eventManager.clusterDomain string REPLACE_IT The domain name of the cluster where Event Manager is installed. <p>NOTE:</p> <ul> <li>For <code>cp4waiops.dockerPassword</code>, it is the entitlement key that you can copy from My IBM Container Software Library.</li> <li>For <code>cp4waiops.profile</code>, the profile <code>x-small</code> is only for demo, PoC, or dev environment. If you are looking for official installation, use profile such as <code>small</code> or <code>large</code> instead.</li> <li>For <code>cp4waiops.eventManager.enabled</code>, it needs to be false if you use <code>x-small</code> profile as it only covers AI Manager, not including Event Manager.</li> <li>For <code>cp4waiops.eventManager.clusterDomain</code>, it is the domain name of the cluster where Event Manager is installed. Use fully qualified domain name (FQDN), e.g.: apps.clustername.abc.xyz.com.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-32/#install-cp4waiops-using-custom-build","title":"Install CP4WAIOps using Custom Build","text":"<p>The all-in-one configuration also allows you to install CP4WAIOps using custom build by providing specific image catalog and channel.</p> <p>Just use the install parameters listed in following table when you create the Argo CD App:</p> Parameter Type Default Value Description cp4waiops.aiManager.imageCatalog string icr.io/cpopen/ibm-operator-catalog:latest The image catalog for AI Manager. cp4waiops.aiManager.channel string v3.2 The subscription channel for AI Manager. cp4waiops.eventManager.imageCatalog string icr.io/cpopen/ibm-operator-catalog:latest The image catalog for Event Manager. cp4waiops.eventManager.channel string v1.5 The subscription channel for Event Manager. <p>These parameters are invisible when you create the Argo CD App from UI, but you can add them when filling in the form in <code>HELM</code> &gt; <code>VALUES</code> field.</p> <p>For example, adding following YAML snippet to <code>HELM</code> &gt; <code>VALUES</code> field will install AI Manager and Event Manager using custom imageCatalog and channel:</p> <pre><code>cp4waiops:\naiManager:\nimageCatalog: &lt;my_custom_image_catalog_for_ai_manager&gt;\nchannel: &lt;my_custom_channel_for_ai_manager&gt;\neventManager:\nimageCatalog: &lt;my_custom_image_catalog_for_event_manager&gt;\nchannel: &lt;my_custom_channel_for_event_manager&gt;\n````\n\nBesides that, the all-in-one configuration exposes a few more install parameters invisible from UI that allows you to customize the install behavior in a more fine-grained manner. Below is just a list of some available parameters. To learn more on the usage of such parameters, please refer to [CP4WAIOps Advanced Install Options Using GitOps](./cp4waiops-advanced-install-options.md).\n\n| Parameter                             | Type   | Default Value | Description | ------------------------------------- |--------|---------------|-----------------------------------\n| cp4waiops.storageClass                | string | rook-cephfs   | The storage class for CP4WAIOps to use.\n| cp4waiops.storageClassLargeBlock      | string | rook-cephfs   | The storage class for large block for CP4WAIOps to use.\n| cp4waiops.eventManager.version        | string | 1.6.4         | The version of Event Manager.\n| cp4waiops.eventManager.deploymentType | string | trial         | The deployment type of Event Manager, valid values include: trial, production.\n| globalImagePullSecrets                | array  | n/a           | A list of registries for image pull when needed during the install.\n\nFor example, if the custom build to be installed includes images from registries other than the official IBM entitled registry, you can use `globalImagePullSecrets` to specify all necessary information for these registries including registry URLs, as well as username and password to access these registries.\n\nAgain, since these parameters are invisible, you can add them when filling in the form in `HELM` &gt; `VALUES` field:\n\n```yaml\nglobalImagePullSecrets:\n- registry: &lt;my_own_registry_1&gt;\nusername: &lt;username_to_registry_1&gt;\npassword: &lt;password_to_registry_1&gt;\n- registry: &lt;my_own_registry_2&gt;\nusername: &lt;username_to_registry_2&gt;\npassword: &lt;password_to_registry_2&gt;\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-32/#verify-cp4waiops-installation","title":"Verify CP4WAIOPS Installation","text":"<p>After both Ceph and Cloud Pak for Watson AIOps are ready, you will be able to see those two Apps from Argo CD UI as follows with status as <code>Healthy and Synced</code>.</p> <p></p> <p>Same as Ceph, you can also check the topology of Cloud Pak for Watson AIOps using ArgoCD UI as follows:</p> <p></p> <p>You can also check via termial as follows, and make sure there is no error pods.</p> <p>If there are some pod got error, you can either check logs from ArgoCD UI or use CLI <code>oc logs</code> to check.</p> <pre><code>[root@api.body.cp.fyre.ibm.com ~]# oc get po -n cp4waiops\nNAME                                                              READY   STATUS      RESTARTS   AGE\naimanager-aio-ai-platform-api-server-7c877989d6-7jh55             1/1     Running     0          47h\naimanager-aio-change-risk-654884bd8c-6xpxw                        1/1     Running     0          47h\naimanager-aio-chatops-orchestrator-7c54fc5664-rtmrp               1/1     Running     0          47h\naimanager-aio-chatops-slack-integrator-77fc9499c4-wtclt           1/1     Running     0          47h\naimanager-aio-chatops-teams-integrator-577f6b85bf-j2995           1/1     Running     0          47h\naimanager-aio-controller-86875d4b7-jfwwp                          1/1     Running     0          47h\naimanager-aio-create-secrets-ccjdg                                0/1     Completed   0          47h\naimanager-aio-create-truststore-5hxps                             0/1     Completed   0          47h\naimanager-aio-curator-job-27362220-k59t8                          0/1     Completed   0          142m\naimanager-aio-curator-job-27362280-n2w88                          0/1     Completed   0          82m\naimanager-aio-curator-job-27362340-qkwln                          0/1     Completed   0          22m\naimanager-aio-log-anomaly-detector-fdfcbb96b-rpb9q                1/1     Running     0          47h\naimanager-aio-log-anomaly-detector-fdfcbb96b-v426m                1/1     Running     0          47h\naimanager-aio-similar-incidents-service-77cc9d699f-qlxgg          1/1     Running     0          47h\naimanager-ibm-minio-0                                             1/1     Running     0          47h\naimanager-operator-585d799f9f-w22vz                               1/1     Running     0          47h\naiops-ai-model-ui-674b4f77f9-qv56n                                1/1     Running     0          47h\naiops-akora-ui-7bc6d5dd6b-6n9rs                                   1/1     Running     0          47h\naiops-application-details-ui-66779f957b-fqfhk                     1/1     Running     0          47h\naiops-base-ui-5b9f885888-pvm7z                                    1/1     Running     0          47h\naiops-connections-ui-7996699c55-m79fl                             1/1     Running     0          47h\naiops-ir-analytics-classifier-75869fd78b-p2s9v                    1/1     Running     0          47h\naiops-ir-analytics-probablecause-6dd5ffd867-rrg6b                 1/1     Running     2          47h\naiops-ir-analytics-spark-master-5cd57946d4-99bqt                  1/1     Running     0          47h\naiops-ir-analytics-spark-pipeline-composer-795f965b6d-vkjqw       1/1     Running     0          47h\naiops-ir-analytics-spark-worker-65d57f7f9c-4nsb8                  1/1     Running     0          47h\naiops-ir-core-archiving-754dcb5fcb-jm82z                          1/1     Running     0          47h\naiops-ir-core-archiving-setup-rrlkh                               0/1     Completed   0          47h\naiops-ir-core-cem-users-65b9b699b9-hzh9b                          1/1     Running     0          47h\naiops-ir-core-esarchiving-67dbb7c5d7-wg7dx                        1/1     Running     0          47h\naiops-ir-core-logstash-6c89d66f79-tlfcl                           1/1     Running     0          47h\naiops-ir-core-ncobackup-0                                         2/2     Running     0          47h\naiops-ir-core-ncodl-api-59f977b475-lx7n4                          1/1     Running     0          47h\naiops-ir-core-ncodl-if-66cf44c565-lkkgx                           1/1     Running     0          47h\naiops-ir-core-ncodl-ir-7469fd4866-wjfvf                           1/1     Running     0          47h\naiops-ir-core-ncodl-jobmgr-76d74b5567-t77wc                       1/1     Running     0          47h\naiops-ir-core-ncodl-setup-8hx6c                                   0/1     Completed   0          47h\naiops-ir-core-ncodl-std-7677546c8d-dbqm9                          1/1     Running     0          47h\naiops-ir-core-ncodl-std-7677546c8d-wf82d                          1/1     Running     0          47h\naiops-ir-core-ncoprimary-0                                        1/1     Running     0          47h\naiops-ir-lifecycle-create-policies-job-dljxp                      0/1     Completed   0          47h\naiops-ir-lifecycle-eventprocessor-ep-jobmanager-0                 2/2     Running     0          47h\naiops-ir-lifecycle-eventprocessor-ep-taskmanager-0                1/1     Running     0          47h\naiops-ir-lifecycle-logstash-77579f5d7f-9rhsx                      1/1     Running     0          47h\naiops-ir-lifecycle-policy-grpc-svc-6b59698569-cvhvq               1/1     Running     0          47h\naiops-ir-lifecycle-policy-registry-svc-68647d4cdc-t27mw           1/1     Running     0          47h\naiops-ir-lifecycle-policy-registry-svc-job-8gk89                  0/1     Completed   3          47h\naiops-ir-ui-api-graphql-68488c7675-87mbp                          1/1     Running     0          47h\naiops-topology-cassandra-0                                        1/1     Running     0          47h\naiops-topology-cassandra-auth-secret-generator-7mm84              0/1     Completed   0          47h\naiops-topology-file-observer-5757769dd5-xxc8j                     1/1     Running     0          47h\naiops-topology-kubernetes-observer-d4c8bcb55-ddbcg                1/1     Running     0          47h\naiops-topology-layout-6b957b5bbb-m28rd                            1/1     Running     0          47h\naiops-topology-merge-76c494795f-5b65g                             1/1     Running     0          47h\naiops-topology-observer-service-6f5d6fb44b-jswwp                  1/1     Running     0          47h\naiops-topology-rest-observer-799bfdf4c8-5nt6n                     1/1     Running     0          47h\naiops-topology-search-6cd7cc9d8-64bdk                             1/1     Running     0          47h\naiops-topology-secret-manager-2b84s                               0/1     Completed   0          47h\naiops-topology-servicenow-observer-84c588df5b-gm6p2               1/1     Running     0          47h\naiops-topology-status-58ddcdc845-mqpzg                            1/1     Running     0          47h\naiops-topology-topology-577b988f78-kc2m6                          1/1     Running     2          47h\naiops-topology-ui-api-bbd74965d-gzlfd                             1/1     Running     0          47h\naiops-topology-vmvcenter-observer-86b6c8dc44-krvtj                1/1     Running     0          47h\naiopsedge-github-topology-integrator-7b9db59cd8-nbdgz             1/1     Running     0          47h\naiopsedge-operator-controller-manager-9b68ddd75-5rqqz             1/1     Running     1          47h\naiopsedge-operator-controller-manager-9b68ddd75-xj7tq             1/1     Running     1          47h\nasm-operator-548c8894fd-r2dgv                                     1/1     Running     0          47h\nc-example-couchdbcluster-m-0                                      3/3     Running     0          47h\nc-example-redis-m-0                                               4/4     Running     0          47h\nc-example-redis-m-1                                               4/4     Running     0          47h\nc-example-redis-m-2                                               4/4     Running     0          47h\nc-example-redis-s-0                                               4/4     Running     0          47h\nc-example-redis-s-1                                               4/4     Running     0          47h\nc-example-redis-s-2                                               4/4     Running     0          47h\ncamel-k-kit-c7c60rolvegv49tvh8fg-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60sglvegv49tvh8g0-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60tglvegv49tvh8gg-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60tolvegv49tvh8h0-1-build                          0/1     Completed   0          47h\ncamel-k-operator-684f46fc4d-s6hf2                                 1/1     Running     0          47h\nconfigure-aiops-network-policy-967ll                              0/1     Completed   0          47h\nconnector-controller-bc7fc6668-f8nn5                              1/1     Running     0          47h\nconnector-synchronizer-7d4546ddd4-5kbrl                           1/1     Running     0          47h\ncouchdb-operator-d5cb7ff8c-rjnhx                                  1/1     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-jobmanager-0                 2/2     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-jobmanager-1                 2/2     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-taskmanager-0                1/1     Running     1          47h\ncp4waiops-eventprocessor-eve-29ee-ep-taskmanager-1                1/1     Running     0          47h\ncp4waiops-image-pull-secret-6fprf                                 0/1     Completed   0          2d\ncp4waiops-patch-j4qrm                                             0/1     Completed   0          2d\ncp4waiops-postgres-keeper-0                                       1/1     Running     0          47h\ncp4waiops-postgres-postgresql-create-cluster-7xb6t                0/1     Completed   0          47h\ncp4waiops-postgres-proxy-648bc64fd-x4mvv                          1/1     Running     0          47h\ncp4waiops-postgres-sentinel-5878f67f46-gvv7l                      1/1     Running     0          47h\ncp4waiops-postgresdb-postgresql-create-database-9j6kq             0/1     Completed   0          47h\ncreate-secrets-job-nx6dg                                          0/1     Completed   0          47h\ngateway-kong-5d45b77fb4-tgjcv                                     2/2     Running     2          47h\ngateway-kong-config-svc-27362360-9dmzc                            0/1     Completed   0          2m51s\niaf-core-operator-controller-manager-58dfd97f5c-bdd9t             1/1     Running     0          2d\niaf-eventprocessing-operator-controller-manager-5bc597797f6fxm4   1/1     Running     1          2d\niaf-flink-operator-controller-manager-7dc56c9b68-6rgtk            1/1     Running     0          2d\niaf-operator-controller-manager-6bc8f44ff7-rrrnx                  1/1     Running     0          2d\niaf-system-elasticsearch-es-aiops-0                               2/2     Running     0          47h\niaf-system-entity-operator-6b5444f575-7tdfw                       3/3     Running     0          47h\niaf-system-kafka-0                                                1/1     Running     0          47h\niaf-system-zookeeper-0                                            1/1     Running     0          47h\niaf-zen-tour-job-fhdfr                                            0/1     Completed   0          47h\niam-config-job-tfsst                                              0/1     Completed   0          47h\nibm-aiops-orchestrator-6c7cfc85b7-wqdnr                           1/1     Running     0          2d\nibm-cloud-databases-redis-operator-854cf65c4f-4rrvn               1/1     Running     0          47h\nibm-common-service-operator-5cd6947dc8-z8plb                      1/1     Running     0          2d\nibm-elastic-operator-controller-manager-5d6c467b55-wtrvg          1/1     Running     0          2d\nibm-ir-ai-operator-controller-manager-59b88c6bf6-ncnbt            1/1     Running     7          47h\nibm-kong-operator-6ff97bcdb9-rl7cp                                1/1     Running     0          47h\nibm-nginx-cd84b4d8-7ttn2                                          1/1     Running     0          47h\nibm-nginx-cd84b4d8-zp4t2                                          1/1     Running     0          47h\nibm-postgreservice-operator-controller-manager-8b7bdf589-hbg2g    1/1     Running     2          47h\nibm-secure-tunnel-operator-657dd7b78f-tsgws                       1/1     Running     0          47h\nibm-vault-deploy-consul-0                                         1/1     Running     0          47h\nibm-vault-deploy-vault-0                                          1/1     Running     0          47h\nibm-vault-deploy-vault-cron-job-27361440-qxpjl                    0/1     Completed   0          15h\nibm-vault-deploy-vault-injector-596567d459-wzkws                  1/1     Running     0          47h\nibm-vault-operator-controller-manager-5957bb5ff9-4zdrb            1/1     Running     0          47h\nibm-watson-aiops-ui-operator-controller-manager-b8cf6fff7-msspt   1/1     Running     0          47h\nir-core-operator-controller-manager-76dbdb699d-g97ng              1/1     Running     7          47h\nir-lifecycle-operator-controller-manager-64bdd8f7b6-pn46g         1/1     Running     9          47h\nmodel-train-classic-operator-56d487585c-4dv5b                     1/1     Running     2          47h\nmodeltrain-ibm-modeltrain-lcm-865b7f85cc-jfq4z                    1/1     Running     0          47h\nmodeltrain-ibm-modeltrain-ratelimiter-595f4f478-r9dwp             1/1     Running     0          47h\nmodeltrain-ibm-modeltrain-trainer-5b7f7888b5-c8cz5                1/1     Running     0          47h\npost-aiops-resources-t4ww9                                        0/1     Completed   0          47h\npost-aiops-translations-t58bb                                     0/1     Completed   0          47h\npost-aiops-update-user-role-kcr8k                                 0/1     Completed   0          47h\nscm-handlers-d655679fc-lvls2                                      2/2     Running     0          47h\nsetup-nginx-job-tn8sc                                             0/1     Completed   0          47h\nsnow-handlers-d8488f6f8-8lhxh                                     2/2     Running     0          47h\nsre-tunnel-controller-84565ff4f8-4qtwl                            1/1     Running     0          47h\nsre-tunnel-tunnel-network-api-589fd6646d-7znnh                    1/1     Running     0          47h\nsre-tunnel-tunnel-ui-mcmtunnelui-fff9b859b-g7dlk                  1/1     Running     0          47h\nusermgmt-5fb7986c7b-dwmk2                                         1/1     Running     0          47h\nusermgmt-5fb7986c7b-ssk86                                         1/1     Running     0          47h\nzen-audit-678b54b548-n7q7f                                        1/1     Running     0          47h\nzen-core-64c6d56db-d25zm                                          1/1     Running     0          47h\nzen-core-64c6d56db-glv65                                          1/1     Running     1          47h\nzen-core-api-85489478d6-95pck                                     1/1     Running     0          47h\nzen-core-api-85489478d6-n9x5s                                     1/1     Running     0          47h\nzen-metastoredb-0                                                 1/1     Running     0          47h\nzen-metastoredb-1                                                 1/1     Running     0          47h\nzen-metastoredb-2                                                 1/1     Running     0          47h\nzen-metastoredb-certs-lblhv                                       0/1     Completed   0          47h\nzen-metastoredb-init-hvlv2                                        0/1     Completed   0          47h\nzen-post-requisite-job-lpkfw                                      0/1     Completed   0          47h\nzen-pre-requisite-job-2klrt                                       0/1     Completed   0          47h\nzen-watcher-d8b795b46-2q6zx                                       1/1     Running     0          47h\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-32/#access-cloud-pak-for-watson-aiops","title":"Access Cloud Pak for Watson AIOps","text":"<p>If all pods are running for Cloud Pak for Watson AIOps, you can login to Cloud Pak for Watson AIOps UI as follows:</p> <ul> <li>Login to OCP UI, click the <code>Red Hat Applications icon</code> on top right.</li> </ul> <p></p> <ul> <li>Click the link for the <code>Cloud Pak for Administration</code>. Log in via <code>OpenShift authentication</code>.</li> </ul> <p></p> <ul> <li>Login to <code>Cloud Pak for Administration</code> and click the top right, select <code>IBM Automation (cp4waiops)</code>.</li> </ul> <p></p> <ul> <li>Log in via <code>OpenShift authentication</code> to Cloud Pak for Watson AIOps UI.</li> </ul> <p></p> <ul> <li>You will be navigated to Cloud Pak for Watson AIOps UI!</li> </ul> <p></p> <ul> <li>Congratulations! You are ready to play with Cloud Pak for Watson AIOps!</li> </ul>"},{"location":"how-to-deploy-cp4waiops-32/#using-cli-to-install-cp4waiops","title":"Using CLI to Install CP4WAIOPS","text":""},{"location":"how-to-deploy-cp4waiops-32/#grant-argocd-cluster-admin-permission_1","title":"Grant ArgoCD Cluster Admin Permission","text":"<pre><code>kind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\nname: argocd-admin\nsubjects:\n- kind: ServiceAccount\nname: openshift-gitops-argocd-application-controller\nnamespace: openshift-gitops\nroleRef:\napiGroup: rbac.authorization.k8s.io\nkind: ClusterRole\nname: cluster-admin\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-32/#login-to-argocd_1","title":"Login to ArgoCD","text":"<pre><code># OCP 4.8\nargo_route=openshift-gitops-server\nargo_secret=openshift-gitops-cluster\nsa_account=openshift-gitops-argocd-application-controller\n\nargo_pwd=$(oc get secret ${argo_secret} \\\n-n openshift-gitops \\\n-o jsonpath='{.data.admin\\.password}' | base64 -d ; echo ) \\\n&amp;&amp; argo_url=$(oc get route ${argo_route} \\\n-n openshift-gitops \\\n-o jsonpath='{.spec.host}') \\\n&amp;&amp; argocd login \"${argo_url}\" \\\n--username admin \\\n--password \"${argo_pwd}\" \\\n--insecure\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-32/#optional-storage-considerations","title":"(Optional) Storage Considerations","text":"<p>To create Argo CD App for Ceph storage from command line, run following command:</p> <pre><code>argocd app create ceph \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/ceph \\\n--revision HEAD \\\n--dest-namespace rook-ceph \\\n--dest-server https://kubernetes.default.svc\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-32/#install-ai-manager_1","title":"Install AI Manager","text":"<p>To create Argo CD App for AI Manager to install AI Manager using GitOps, run following command:</p> <pre><code>argocd app create aimanager-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/3.2/ai-manager \\\n--revision HEAD \\\n--dest-namespace cp4waiops \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.imageCatalog=icr.io/cpopen/ibm-operator-catalog:latest \\\n--helm-set spec.dockerUsername=cp \\\n--helm-set spec.dockerPassword=REPLACE_IT \\\n--helm-set spec.storageClass=rook-cephfs \\\n--helm-set spec.storageClassLargeBlock=rook-cephfs \\\n--helm-set spec.aiManager.namespace=cp4waiops \\\n--helm-set spec.aiManager.channel=v3.2 \\\n--helm-set spec.aiManager.size=small \\\n--helm-set spec.aiManager.pakModules.aiopsFoundation.enabled=true \\\n--helm-set spec.aiManager.pakModules.applicationManager.enabled=true \\\n--helm-set spec.aiManager.pakModules.aiManager.enabled=true \\\n--helm-set spec.aiManager.pakModules.connection.enabled=true\n</code></pre> <p>NOTE:</p> <ul> <li>For <code>spec.dockerPassword</code>, it is the entitlement key that you can copy from My IBM Container Software Library.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-32/#install-event-manager_1","title":"Install Event Manager","text":"<p>To create Argo CD App for Event Manager to install Event Manager using GitOps, run following command:</p> <pre><code>argocd app create eventmanager-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/3.2/event-manager \\\n--revision HEAD \\\n--dest-namespace noi \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.imageCatalog=icr.io/cpopen/ibm-operator-catalog:latest \\\n--helm-set spec.dockerUsername=cp \\\n--helm-set spec.dockerPassword=REPLACE_IT \\\n--helm-set spec.storageClass=rook-cephfs \\\n--helm-set spec.storageClassLargeBlock=rook-cephfs \\\n--helm-set spec.eventManager.namespace=noi \\\n--helm-set spec.eventManager.channel=v1.5 \\\n--helm-set spec.eventManager.version=1.6.3.2 \\\n--helm-set spec.eventManager.clusterDomain=REPLACE_IT \\\n--helm-set spec.eventManager.deploymentType=trial\n</code></pre> <p>NOTE:</p> <ul> <li>For <code>spec.dockerPassword</code>, it is the entitlement key that you can copy from My IBM Container Software Library.</li> <li>For <code>spec.eventManager.clusterDomain</code>, it is the domain name of the cluster where Event Manager is installed. Use fully qualified domain name (FQDN), e.g.: apps.clustername.abc.xyz.com.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-32/#install-using-all-in-one-configuration_1","title":"Install Using All-in-One Configuration","text":"<p>To install Ceph, AI Manager, and Event Manager in one go using all-in-one configuration, run following command:</p> <p><pre><code>argocd app create cp4waiops-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/all-in-one \\\n--revision HEAD \\\n--dest-namespace openshift-gitops \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set argocd.cluster=openshift \\\n--helm-set argocd.allowLocalDeploy=true \\\n--helm-set rookceph.enabled=true \\\n--helm-set cp4waiops.version=v3.2 \\\n--helm-set cp4waiops.dockerUsername=cp \\\n--helm-set cp4waiops.dockerPassword=REPLACE_IT \\\n--helm-set cp4waiops.profile=small \\\n--helm-set cp4waiops.aiManager.enabled=true \\\n--helm-set cp4waiops.aiManager.namespace=cp4waiops \\\n--helm-set cp4waiops.aiManager.instanceName=aiops-installation \\\n--helm-set cp4waiops.eventManager.enabled=true \\\n--helm-set cp4waiops.eventManager.clusterDomain=REPLACE_IT \\\n--helm-set cp4waiops.eventManager.namespace=noi\n</code></pre> NOTE:</p> <ul> <li>For <code>cp4waiops.dockerPassword</code>, it is the entitlement key that you can copy from My IBM Container Software Library.</li> <li>For <code>cp4waiops.profile</code>, the profile <code>x-small</code> is only for demo, PoC, or dev environment. If you are looking for official installation, use profile such as <code>small</code> or <code>large</code> instead.</li> <li>For <code>cp4waiops.eventManager.enabled</code>, it needs to be false if you use <code>x-small</code> profile as it only covers AI Manager, not including Event Manager.</li> <li>For <code>cp4waiops.eventManager.clusterDomain</code>, it is the domain name of the cluster where Event Manager is installed. Use fully qualified domain name (FQDN), e.g.: apps.clustername.abc.xyz.com.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-32/#verify-cp4waiops-installation_1","title":"Verify CP4WAIOps Installation","text":"<p>To verify the CP4WAIOps installation, run following command:</p> <pre><code>kubectl get application -A\n</code></pre> <p>The output will be something similar as follows:</p> <pre><code># kubectl get application -A\nNAMESPACE          NAME                      SYNC STATUS   HEALTH STATUS\nopenshift-gitops   cp4waiops                 Synced        Healthy\nopenshift-gitops   in-cluster-aimanager      Synced        Healthy\nopenshift-gitops   in-cluster-eventmanager   Synced        Healthy\nopenshift-gitops   in-cluster-rook-ceph      Synced        Healthy\n</code></pre> <p>Wait for a while and check if all pods under namespace <code>cp4waiops</code> and <code>noi</code> are up and running without any crash:</p> <pre><code>kubectl get pod -n cp4waiops\nkubectl get pod -n noi\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-33/","title":"How to deploy cp4waiops 33","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Deploy CP4WAIOps 3.3 using GitOps<ul> <li>Prerequisite</li> <li>Install CP4WAIOps from UI<ul> <li>Login to Argo CD</li> <li>Storage Considerations</li> <li>Option 1: Install AI Manager and Event Manager Separately<ul> <li>Grant Argo CD Cluster Admin Permission</li> <li>Install AI Manager</li> <li>Install Event Manager</li> </ul> </li> <li>Option 2: Install Using All-in-One Configuration<ul> <li>Install AI Manager and Event Manager in One Go</li> <li>Install CP4WAIOps using Custom Build</li> </ul> </li> <li>Verify CP4WAIOps Installation</li> <li>Access CP4WAIOps</li> </ul> </li> <li>Install CP4WAIOps from Command Line<ul> <li>Login to Argo CD</li> <li>Storage Considerations</li> <li>Option 1: Install AI Manager and Event Manager Separately<ul> <li>Grant Argo CD Cluster Admin Permission</li> <li>Install AI Manager</li> <li>Install Event Manager</li> </ul> </li> <li>Option 2: Install Using All-in-One Configuration</li> <li>Verify CP4WAIOps Installation</li> </ul> </li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-33/#deploy-cp4waiops-33-using-gitops","title":"Deploy CP4WAIOps 3.3 using GitOps","text":"<p>\u26a0\ufe0f NOTE: This is a TECHNICAL PREVIEW feature for IBM Cloud Pak for Watson AIOps 3.3 release!</p>"},{"location":"how-to-deploy-cp4waiops-33/#prerequisite","title":"Prerequisite","text":"<ul> <li>To learn CP4WAIOps system requirement, please refer to System requirements for Cloud Pak for Watson AIOps 3.3.</li> <li>To install OpenShift GitOps (Argo CD) on OpenShift cluster, please refer to Installing OpenShift GitOps.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-33/#install-cp4waiops-from-ui","title":"Install CP4WAIOps from UI","text":""},{"location":"how-to-deploy-cp4waiops-33/#login-to-argo-cd","title":"Login to Argo CD","text":"<p>You can now login to Argo CD UI as follows by clicking the drop down menu on top right.</p> <p></p> <p>Argo CD UI will be popped up and you can login using <code>LOG IN VIA OPENSHIFT</code>.</p> <p></p>"},{"location":"how-to-deploy-cp4waiops-33/#storage-considerations","title":"Storage Considerations","text":"<p>If your OpenShift cluster already have default storageclass configured, you can ignore this step. To learn more on storage considerations for CP4WAIOps, please refer to Storage Considerations.</p> <p>In this tutorial, we are using use Ceph just for PoC purpose, but NOT for production. You should always follow storage based on CP4WAIOPS requirements at Storage Considerations.</p> <p>From Argo CD UI, click <code>NEW APP</code> and input parameters as follows for Ceph and then click <code>CREATE</code> button.</p> <ul> <li>GENERAL<ul> <li>Application Name: ceph</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: HEAD</li> <li>path: config/ceph</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: rook-ceph</li> </ul> </li> </ul> <p></p> <p>After Argo CD App <code>ceph</code> is created, you can click the App from Argo CD UI to view the toplogy of all Ceph resources as follows:</p> <p></p> <p>You can use the filters on the left to filter out the resources, and click the resource to check logs and events.</p> <p></p> <p>You can also check all Ceph pods from command line as follows to make sure there is no pod in error state. If there are some pods in error state, you can check logs using <code>kubectl logs</code>.</p> <pre><code>[root@api.body.cp.fyre.ibm.com ~]# kubectl get po -n rook-ceph\nNAME                                                              READY   STATUS      RESTARTS   AGE\ncsi-cephfsplugin-7b6jk                                            3/3     Running     0          2d\ncsi-cephfsplugin-l7mvz                                            3/3     Running     0          2d\ncsi-cephfsplugin-provisioner-695b574445-gfcwz                     6/6     Running     6          2d\ncsi-cephfsplugin-provisioner-695b574445-lb64p                     6/6     Running     7          2d\ncsi-cephfsplugin-qcsqz                                            3/3     Running     0          2d\ncsi-cephfsplugin-qdrtl                                            3/3     Running     0          2d\ncsi-cephfsplugin-wj7qq                                            3/3     Running     0          2d\ncsi-cephfsplugin-xlsnb                                            3/3     Running     0          2d\ncsi-rbdplugin-8xwdb                                               3/3     Running     0          2d\ncsi-rbdplugin-b6t9l                                               3/3     Running     0          2d\ncsi-rbdplugin-h965f                                               3/3     Running     0          2d\ncsi-rbdplugin-lv2hp                                               3/3     Running     0          2d\ncsi-rbdplugin-pqvrc                                               3/3     Running     0          2d\ncsi-rbdplugin-provisioner-7f9847cd48-48gqk                        6/6     Running     0          2d\ncsi-rbdplugin-provisioner-7f9847cd48-wxh2z                        6/6     Running     12         2d\ncsi-rbdplugin-x8cw9                                               3/3     Running     0          2d\nrook-ceph-crashcollector-worker0.body.cp.fyre.ibm.com-88f5bnbdc   1/1     Running     0          2d\nrook-ceph-crashcollector-worker1.body.cp.fyre.ibm.com-d4c7gdcts   1/1     Running     0          2d\nrook-ceph-crashcollector-worker2.body.cp.fyre.ibm.com-7767p8fxm   1/1     Running     0          2d\nrook-ceph-crashcollector-worker3.body.cp.fyre.ibm.com-6c5cqs4lk   1/1     Running     0          2d\nrook-ceph-crashcollector-worker4.body.cp.fyre.ibm.com-787f99czf   1/1     Running     0          2d\nrook-ceph-crashcollector-worker5.body.cp.fyre.ibm.com-94d4b654q   1/1     Running     0          2d\nrook-ceph-mds-myfs-a-7d48d48497-sbhld                             1/1     Running     0          2d\nrook-ceph-mds-myfs-b-66f4b746c7-2fnl2                             1/1     Running     0          2d\nrook-ceph-mgr-a-5c84cd7b7b-574lf                                  1/1     Running     0          2d\nrook-ceph-mon-a-7b947ddf45-74p49                                  1/1     Running     0          2d\nrook-ceph-mon-b-7cf885c589-5j6r9                                  1/1     Running     0          2d\nrook-ceph-mon-c-bcb6575d8-g9l5w                                   1/1     Running     0          2d\nrook-ceph-operator-54649856c4-cdx24                               1/1     Running     0          2d\nrook-ceph-osd-0-c44985597-gwkqk                                   1/1     Running     0          2d\nrook-ceph-osd-1-6f7d5cc955-v4862                                  1/1     Running     0          2d\nrook-ceph-osd-2-58df99c46f-5kl8z                                  1/1     Running     0          2d\nrook-ceph-osd-3-5c8579456c-bpcqz                                  1/1     Running     0          2d\nrook-ceph-osd-4-5668c69fbf-kvdf6                                  1/1     Running     0          2d\nrook-ceph-osd-5-cbbdb95-cqvjd                                     1/1     Running     0          2d\nrook-ceph-osd-prepare-worker0.body.cp.fyre.ibm.com-bxr7t          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker1.body.cp.fyre.ibm.com-fftd8          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker2.body.cp.fyre.ibm.com-scg84          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker3.body.cp.fyre.ibm.com-m488b          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker4.body.cp.fyre.ibm.com-dxcm5          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker5.body.cp.fyre.ibm.com-jclnq          0/1     Completed   0          4h16m\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-33/#option-1-install-ai-manager-and-event-manager-separately","title":"Option 1: Install AI Manager and Event Manager Separately","text":""},{"location":"how-to-deploy-cp4waiops-33/#grant-argo-cd-cluster-admin-permission","title":"Grant Argo CD Cluster Admin Permission","text":"<p>From Red Hat OpenShift Console, go to <code>User Management</code> &gt; <code>RoleBindings</code> &gt; <code>Create binding</code>. Use the form view to configure the properties for the <code>ClusterRoleBinding</code> with values as follows, and click the <code>Create</code> button.</p> <ul> <li>Binding type<ul> <li>Cluster-wide role binding (ClusterRoleBinding)</li> </ul> </li> <li>RoleBinding<ul> <li>Name: argocd-admin</li> </ul> </li> <li>Role<ul> <li>Role Name: cluster-admin</li> </ul> </li> <li>Subject<ul> <li>ServiceAccount: check it</li> <li>Subject namespace: openshift-gitops</li> <li>Subject name: openshift-gitops-argocd-application-controller</li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-33/#install-ai-manager","title":"Install AI Manager","text":"<p>You can install CP4WAIOps - AI Manager using GitOps by creating an Argo CD App. The parameters for AI Manager are as follows:</p> <ul> <li>GENERAL<ul> <li>Application Name: anyname (e.g.: \"aimanager-app\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: HEAD</li> <li>path: config/3.3/ai-manager</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: cp4waiops</li> </ul> </li> <li>PARAMETERS<ul> <li>spec.imageCatalog: icr.io/cpopen/ibm-operator-catalog:latest</li> <li>spec.dockerUsername: cp</li> <li>spec.dockerPassword: REPLACE_IT</li> <li>spec.storageClass: rook-cephfs  (need to update the storage class to what is being used in your environment, check it with <code>oc get sc</code> command.)</li> <li>spec.storageClassLargeBlock: rook-cephfs  (need to update the storage class to what is being used in your environment, check it with <code>oc get sc</code> command.)</li> <li>spec.aiManager.channel: v3.3</li> <li>spec.aiManager.size: small</li> <li>spec.aiManager.namespace: cp4waiops</li> <li>spec.aiManager.pakModules.aiopsFoundation.enabled: true</li> <li>spec.aiManager.pakModules.applicationManager.enabled: true</li> <li>spec.aiManager.pakModules.aiManager.enabled: true</li> <li>spec.aiManager.pakModules.connection.enabled: true</li> </ul> </li> </ul> <p>NOTE:</p> <ul> <li>For <code>Repository URL</code> and <code>Revision</code> field, if you use a repository forked from the official CP4WAIOps GitOps repository and/or on a different branch, please fill these fields using your own values. For example, if you use <code>https://github.com/&lt;myaccount&gt;/cp4waiops-gitops</code> and <code>dev</code> branch, the two fields need to be changed accordingly.</li> <li>For <code>spec.dockerPassword</code>, it is the entitlement key that you can copy from My IBM Container Software Library.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-33/#install-event-manager","title":"Install Event Manager","text":"<p>You can install CP4WAIOps - Event Manager using GitOps by creating an Argo CD App. The parameters for Event Manager are as follows:</p> <ul> <li>GENERAL<ul> <li>Application Name: anyname (e.g.: \"eventmanager-app\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: HEAD</li> <li>path: config/3.3/event-manager</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: noi </li> </ul> </li> <li>PARAMETERS<ul> <li>spec.imageCatalog: icr.io/cpopen/ibm-operator-catalog:latest</li> <li>spec.dockerUsername: cp</li> <li>spec.dockerPassword: REPLACE_IT</li> <li>spec.storageClass: rook-cephfs  (need to update the storage class to what is being used in your environment, check it with <code>oc get sc</code> command.)</li> <li>spec.storageClassLargeBlock: rook-cephfs  (need to update the storage class to what is being used in your environment, check it with <code>oc get sc</code> command.)</li> <li>spec.eventManager.version: 1.6.4</li> <li>spec.eventManager.clusterDomain: REPLACE_IT</li> <li>spec.eventManager.channel: v1.7</li> <li>spec.eventManager.deploymentType: trial</li> <li>spec.eventManager.namespace: noi</li> </ul> </li> </ul> <p>NOTE:</p> <ul> <li>For <code>Repository URL</code> and <code>Revision</code> field, if you use a repository forked from the official CP4WAIOps GitOps repository and/or on a different branch, please fill these fields using your own values. For example, if you use <code>https://github.com/&lt;myaccount&gt;/cp4waiops-gitops</code> and <code>dev</code> branch, the two fields need to be changed accordingly.</li> <li>For <code>spec.dockerPassword</code>, it is the entitlement key that you can copy from My IBM Container Software Library.</li> <li>For <code>spec.eventManager.clusterDomain</code>, it is the domain name of the cluster where Event Manager is installed. Use fully qualified domain name (FQDN), e.g.: apps.clustername.abc.xyz.com.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-33/#option-2-install-using-all-in-one-configuration","title":"Option 2: Install Using All-in-One Configuration","text":""},{"location":"how-to-deploy-cp4waiops-33/#install-ai-manager-and-event-manager-in-one-go","title":"Install AI Manager and Event Manager in One Go","text":"<p>The all-in-one configuration allows you to install following components in one go:</p> <ul> <li>Ceph storage (optional)</li> <li>AI Manager</li> <li>Event Manager</li> </ul> <p>Just fill in the form using the suggested field values listed in following table when you create the Argo CD App:</p> Field Value Application Name anyname (e.g. cp4waiops-app) Project default Sync Policy Automatic Repository URL https://github.com/IBM/cp4waiops-gitops Revision HEAD Path config/all-in-one Cluster URL https://kubernetes.default.svc Namespace openshift-gitops <p>Besides the basic information, when filling in the form, you can also update the following install parameters that are commonly used to customize the install behavior.</p> Parameter Type Default Value Description argocd.cluster string openshift The type of the cluster that Argo CD runs on, valid values include: openshift, kubernetes. argocd.allowLocalDeploy bool true Allow apps to be deployed on the same cluster where Argo CD runs. rookceph.enabled bool true Specify whether or not to install Ceph as storage used by CP4WAIOps. cp4waiops.version string v3.3 Specify the version of CP4WAIOps, e.g.: v3.2, v3.3. cp4waiops.profile string small The CP4WAIOps deployment profile, e.g.: x-small, small, large. cp4waiops.dockerUsername string cp The username of image registry used to pull images. cp4waiops.dockerPassword string REPLACE_IT The password of image registry used to pull images. cp4waiops.aiManager.enabled bool true Specify whether or not to install AI Manager. cp4waiops.aiManager.namespace string cp4waiops The namespace where AI Manager is installed. cp4waiops.aiManager.instanceName string aiops-installation The instance name of AI Manager. cp4waiops.eventManager.enabled bool true Specify whether or not to install Event Manager. cp4waiops.eventManager.namespace string noi The namespace where Event Manager is installed. cp4waiops.eventManager.clusterDomain string REPLACE_IT The domain name of the cluster where Event Manager is installed. <p>NOTE:</p> <ul> <li>For <code>cp4waiops.dockerPassword</code>, it is the entitlement key that you can copy from My IBM Container Software Library.</li> <li>For <code>cp4waiops.profile</code>, the profile <code>x-small</code> is only for demo, PoC, or dev environment. If you are looking for official installation, use profile such as <code>small</code> or <code>large</code> instead.</li> <li>For <code>cp4waiops.eventManager.enabled</code>, it needs to be false if you use <code>x-small</code> profile as it only covers AI Manager, not including Event Manager.</li> <li>For <code>cp4waiops.eventManager.clusterDomain</code>, it is the domain name of the cluster where Event Manager is installed. Use fully qualified domain name (FQDN), e.g.: apps.clustername.abc.xyz.com.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-33/#install-cp4waiops-using-custom-build","title":"Install CP4WAIOps using Custom Build","text":"<p>The all-in-one configuration also allows you to install CP4WAIOps using custom build by providing specific image catalog and channel.</p> <p>Just use the install parameters listed in following table when you create the Argo CD App:</p> Parameter Type Default Value Description cp4waiops.aiManager.imageCatalog string icr.io/cpopen/ibm-operator-catalog:latest The image catalog for AI Manager. cp4waiops.aiManager.channel string v3.3 The subscription channel for AI Manager. cp4waiops.eventManager.imageCatalog string icr.io/cpopen/ibm-operator-catalog:latest The image catalog for Event Manager. cp4waiops.eventManager.channel string v1.7 The subscription channel for Event Manager. <p>These parameters are invisible when you create the Argo CD App from UI, but you can add them when filling in the form in <code>HELM</code> &gt; <code>VALUES</code> field.</p> <p>For example, adding following YAML snippet to <code>HELM</code> &gt; <code>VALUES</code> field will install AI Manager and Event Manager using custom imageCatalog and channel:</p> <pre><code>cp4waiops:\naiManager:\nimageCatalog: &lt;my_custom_image_catalog_for_ai_manager&gt;\nchannel: &lt;my_custom_channel_for_ai_manager&gt;\neventManager:\nimageCatalog: &lt;my_custom_image_catalog_for_event_manager&gt;\nchannel: &lt;my_custom_channel_for_event_manager&gt;\n````\n\nBesides that, the all-in-one configuration exposes a few more install parameters invisible from UI that allows you to customize the install behavior in a more fine-grained manner. Below is just a list of some available parameters. To learn more on the usage of such parameters, please refer to [CP4WAIOps Advanced Install Options Using GitOps](./cp4waiops-advanced-install-options.md).\n\n| Parameter                             | Type   | Default Value | Description | ------------------------------------- |--------|---------------|-----------------------------------\n| cp4waiops.storageClass                | string | rook-cephfs   | The storage class for CP4WAIOps to use.\n| cp4waiops.storageClassLargeBlock      | string | rook-cephfs   | The storage class for large block for CP4WAIOps to use.\n| cp4waiops.eventManager.version        | string | 1.6.4         | The version of Event Manager.\n| cp4waiops.eventManager.deploymentType | string | trial         | The deployment type of Event Manager, valid values include: trial, production.\n| globalImagePullSecrets                | array  | n/a           | A list of registries for image pull when needed during the install.\n\nFor example, if the custom build to be installed includes images from registries other than the official IBM entitled registry, you can use `globalImagePullSecrets` to specify all necessary information for these registries including registry URLs, as well as username and password to access these registries.\n\nAgain, since these parameters are invisible, you can add them when filling in the form in `HELM` &gt; `VALUES` field:\n\n```yaml\nglobalImagePullSecrets:\n- registry: &lt;my_own_registry_1&gt;\nusername: &lt;username_to_registry_1&gt;\npassword: &lt;password_to_registry_1&gt;\n- registry: &lt;my_own_registry_2&gt;\nusername: &lt;username_to_registry_2&gt;\npassword: &lt;password_to_registry_2&gt;\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-33/#verify-cp4waiops-installation","title":"Verify CP4WAIOps Installation","text":"<p>After both Ceph and CP4WAIOps are ready, you will be able to see those Apps from Argo CD UI as follows with status as <code>Healthy</code> and <code>Synced</code>.</p> <p></p> <p></p> <p>You can check the topology of CP4WAIOps using Argo CD UI as follows:</p> <p></p> <p></p> <p>You can also check from command line as follows, and make sure there are no error pods. If there are some pods in error state, you can check logs either from Argo CD UI or using <code>kubectl logs</code> from command line.</p> <p>For example, to check pods of AI Manager:</p> <pre><code>[root@api.body.cp.fyre.ibm.com ~]# kubectl get po -n cp4waiops\nNAME                                                              READY   STATUS      RESTARTS   AGE\naimanager-aio-ai-platform-api-server-7c877989d6-7jh55             1/1     Running     0          47h\naimanager-aio-change-risk-654884bd8c-6xpxw                        1/1     Running     0          47h\naimanager-aio-chatops-orchestrator-7c54fc5664-rtmrp               1/1     Running     0          47h\naimanager-aio-chatops-slack-integrator-77fc9499c4-wtclt           1/1     Running     0          47h\naimanager-aio-chatops-teams-integrator-577f6b85bf-j2995           1/1     Running     0          47h\naimanager-aio-controller-86875d4b7-jfwwp                          1/1     Running     0          47h\naimanager-aio-create-secrets-ccjdg                                0/1     Completed   0          47h\naimanager-aio-create-truststore-5hxps                             0/1     Completed   0          47h\naimanager-aio-curator-job-27362220-k59t8                          0/1     Completed   0          142m\naimanager-aio-curator-job-27362280-n2w88                          0/1     Completed   0          82m\naimanager-aio-curator-job-27362340-qkwln                          0/1     Completed   0          22m\naimanager-aio-log-anomaly-detector-fdfcbb96b-rpb9q                1/1     Running     0          47h\naimanager-aio-log-anomaly-detector-fdfcbb96b-v426m                1/1     Running     0          47h\naimanager-aio-similar-incidents-service-77cc9d699f-qlxgg          1/1     Running     0          47h\naimanager-ibm-minio-0                                             1/1     Running     0          47h\naimanager-operator-585d799f9f-w22vz                               1/1     Running     0          47h\naiops-ai-model-ui-674b4f77f9-qv56n                                1/1     Running     0          47h\naiops-akora-ui-7bc6d5dd6b-6n9rs                                   1/1     Running     0          47h\naiops-application-details-ui-66779f957b-fqfhk                     1/1     Running     0          47h\naiops-base-ui-5b9f885888-pvm7z                                    1/1     Running     0          47h\naiops-connections-ui-7996699c55-m79fl                             1/1     Running     0          47h\naiops-ir-analytics-classifier-75869fd78b-p2s9v                    1/1     Running     0          47h\naiops-ir-analytics-probablecause-6dd5ffd867-rrg6b                 1/1     Running     2          47h\naiops-ir-analytics-spark-master-5cd57946d4-99bqt                  1/1     Running     0          47h\naiops-ir-analytics-spark-pipeline-composer-795f965b6d-vkjqw       1/1     Running     0          47h\naiops-ir-analytics-spark-worker-65d57f7f9c-4nsb8                  1/1     Running     0          47h\naiops-ir-core-archiving-754dcb5fcb-jm82z                          1/1     Running     0          47h\naiops-ir-core-archiving-setup-rrlkh                               0/1     Completed   0          47h\naiops-ir-core-cem-users-65b9b699b9-hzh9b                          1/1     Running     0          47h\naiops-ir-core-esarchiving-67dbb7c5d7-wg7dx                        1/1     Running     0          47h\naiops-ir-core-logstash-6c89d66f79-tlfcl                           1/1     Running     0          47h\naiops-ir-core-ncobackup-0                                         2/2     Running     0          47h\naiops-ir-core-ncodl-api-59f977b475-lx7n4                          1/1     Running     0          47h\naiops-ir-core-ncodl-if-66cf44c565-lkkgx                           1/1     Running     0          47h\naiops-ir-core-ncodl-ir-7469fd4866-wjfvf                           1/1     Running     0          47h\naiops-ir-core-ncodl-jobmgr-76d74b5567-t77wc                       1/1     Running     0          47h\naiops-ir-core-ncodl-setup-8hx6c                                   0/1     Completed   0          47h\naiops-ir-core-ncodl-std-7677546c8d-dbqm9                          1/1     Running     0          47h\naiops-ir-core-ncodl-std-7677546c8d-wf82d                          1/1     Running     0          47h\naiops-ir-core-ncoprimary-0                                        1/1     Running     0          47h\naiops-ir-lifecycle-create-policies-job-dljxp                      0/1     Completed   0          47h\naiops-ir-lifecycle-eventprocessor-ep-jobmanager-0                 2/2     Running     0          47h\naiops-ir-lifecycle-eventprocessor-ep-taskmanager-0                1/1     Running     0          47h\naiops-ir-lifecycle-logstash-77579f5d7f-9rhsx                      1/1     Running     0          47h\naiops-ir-lifecycle-policy-grpc-svc-6b59698569-cvhvq               1/1     Running     0          47h\naiops-ir-lifecycle-policy-registry-svc-68647d4cdc-t27mw           1/1     Running     0          47h\naiops-ir-lifecycle-policy-registry-svc-job-8gk89                  0/1     Completed   3          47h\naiops-ir-ui-api-graphql-68488c7675-87mbp                          1/1     Running     0          47h\naiops-topology-cassandra-0                                        1/1     Running     0          47h\naiops-topology-cassandra-auth-secret-generator-7mm84              0/1     Completed   0          47h\naiops-topology-file-observer-5757769dd5-xxc8j                     1/1     Running     0          47h\naiops-topology-kubernetes-observer-d4c8bcb55-ddbcg                1/1     Running     0          47h\naiops-topology-layout-6b957b5bbb-m28rd                            1/1     Running     0          47h\naiops-topology-merge-76c494795f-5b65g                             1/1     Running     0          47h\naiops-topology-observer-service-6f5d6fb44b-jswwp                  1/1     Running     0          47h\naiops-topology-rest-observer-799bfdf4c8-5nt6n                     1/1     Running     0          47h\naiops-topology-search-6cd7cc9d8-64bdk                             1/1     Running     0          47h\naiops-topology-secret-manager-2b84s                               0/1     Completed   0          47h\naiops-topology-servicenow-observer-84c588df5b-gm6p2               1/1     Running     0          47h\naiops-topology-status-58ddcdc845-mqpzg                            1/1     Running     0          47h\naiops-topology-topology-577b988f78-kc2m6                          1/1     Running     2          47h\naiops-topology-ui-api-bbd74965d-gzlfd                             1/1     Running     0          47h\naiops-topology-vmvcenter-observer-86b6c8dc44-krvtj                1/1     Running     0          47h\naiopsedge-github-topology-integrator-7b9db59cd8-nbdgz             1/1     Running     0          47h\naiopsedge-operator-controller-manager-9b68ddd75-5rqqz             1/1     Running     1          47h\naiopsedge-operator-controller-manager-9b68ddd75-xj7tq             1/1     Running     1          47h\nasm-operator-548c8894fd-r2dgv                                     1/1     Running     0          47h\nc-example-couchdbcluster-m-0                                      3/3     Running     0          47h\nc-example-redis-m-0                                               4/4     Running     0          47h\nc-example-redis-m-1                                               4/4     Running     0          47h\nc-example-redis-m-2                                               4/4     Running     0          47h\nc-example-redis-s-0                                               4/4     Running     0          47h\nc-example-redis-s-1                                               4/4     Running     0          47h\nc-example-redis-s-2                                               4/4     Running     0          47h\ncamel-k-kit-c7c60rolvegv49tvh8fg-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60sglvegv49tvh8g0-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60tglvegv49tvh8gg-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60tolvegv49tvh8h0-1-build                          0/1     Completed   0          47h\ncamel-k-operator-684f46fc4d-s6hf2                                 1/1     Running     0          47h\nconfigure-aiops-network-policy-967ll                              0/1     Completed   0          47h\nconnector-controller-bc7fc6668-f8nn5                              1/1     Running     0          47h\nconnector-synchronizer-7d4546ddd4-5kbrl                           1/1     Running     0          47h\ncouchdb-operator-d5cb7ff8c-rjnhx                                  1/1     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-jobmanager-0                 2/2     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-jobmanager-1                 2/2     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-taskmanager-0                1/1     Running     1          47h\ncp4waiops-eventprocessor-eve-29ee-ep-taskmanager-1                1/1     Running     0          47h\ncp4waiops-image-pull-secret-6fprf                                 0/1     Completed   0          2d\ncp4waiops-patch-j4qrm                                             0/1     Completed   0          2d\ncp4waiops-postgres-keeper-0                                       1/1     Running     0          47h\ncp4waiops-postgres-postgresql-create-cluster-7xb6t                0/1     Completed   0          47h\ncp4waiops-postgres-proxy-648bc64fd-x4mvv                          1/1     Running     0          47h\ncp4waiops-postgres-sentinel-5878f67f46-gvv7l                      1/1     Running     0          47h\ncp4waiops-postgresdb-postgresql-create-database-9j6kq             0/1     Completed   0          47h\ncreate-secrets-job-nx6dg                                          0/1     Completed   0          47h\ngateway-kong-5d45b77fb4-tgjcv                                     2/2     Running     2          47h\ngateway-kong-config-svc-27362360-9dmzc                            0/1     Completed   0          2m51s\niaf-core-operator-controller-manager-58dfd97f5c-bdd9t             1/1     Running     0          2d\niaf-eventprocessing-operator-controller-manager-5bc597797f6fxm4   1/1     Running     1          2d\niaf-flink-operator-controller-manager-7dc56c9b68-6rgtk            1/1     Running     0          2d\niaf-operator-controller-manager-6bc8f44ff7-rrrnx                  1/1     Running     0          2d\niaf-system-elasticsearch-es-aiops-0                               2/2     Running     0          47h\niaf-system-entity-operator-6b5444f575-7tdfw                       3/3     Running     0          47h\niaf-system-kafka-0                                                1/1     Running     0          47h\niaf-system-zookeeper-0                                            1/1     Running     0          47h\niaf-zen-tour-job-fhdfr                                            0/1     Completed   0          47h\niam-config-job-tfsst                                              0/1     Completed   0          47h\nibm-aiops-orchestrator-6c7cfc85b7-wqdnr                           1/1     Running     0          2d\nibm-cloud-databases-redis-operator-854cf65c4f-4rrvn               1/1     Running     0          47h\nibm-common-service-operator-5cd6947dc8-z8plb                      1/1     Running     0          2d\nibm-elastic-operator-controller-manager-5d6c467b55-wtrvg          1/1     Running     0          2d\nibm-ir-ai-operator-controller-manager-59b88c6bf6-ncnbt            1/1     Running     7          47h\nibm-kong-operator-6ff97bcdb9-rl7cp                                1/1     Running     0          47h\nibm-nginx-cd84b4d8-7ttn2                                          1/1     Running     0          47h\nibm-nginx-cd84b4d8-zp4t2                                          1/1     Running     0          47h\nibm-postgreservice-operator-controller-manager-8b7bdf589-hbg2g    1/1     Running     2          47h\nibm-secure-tunnel-operator-657dd7b78f-tsgws                       1/1     Running     0          47h\nibm-vault-deploy-consul-0                                         1/1     Running     0          47h\nibm-vault-deploy-vault-0                                          1/1     Running     0          47h\nibm-vault-deploy-vault-cron-job-27361440-qxpjl                    0/1     Completed   0          15h\nibm-vault-deploy-vault-injector-596567d459-wzkws                  1/1     Running     0          47h\nibm-vault-operator-controller-manager-5957bb5ff9-4zdrb            1/1     Running     0          47h\nibm-watson-aiops-ui-operator-controller-manager-b8cf6fff7-msspt   1/1     Running     0          47h\nir-core-operator-controller-manager-76dbdb699d-g97ng              1/1     Running     7          47h\nir-lifecycle-operator-controller-manager-64bdd8f7b6-pn46g         1/1     Running     9          47h\nmodel-train-classic-operator-56d487585c-4dv5b                     1/1     Running     2          47h\nmodeltrain-ibm-modeltrain-lcm-865b7f85cc-jfq4z                    1/1     Running     0          47h\nmodeltrain-ibm-modeltrain-ratelimiter-595f4f478-r9dwp             1/1     Running     0          47h\nmodeltrain-ibm-modeltrain-trainer-5b7f7888b5-c8cz5                1/1     Running     0          47h\npost-aiops-resources-t4ww9                                        0/1     Completed   0          47h\npost-aiops-translations-t58bb                                     0/1     Completed   0          47h\npost-aiops-update-user-role-kcr8k                                 0/1     Completed   0          47h\nscm-handlers-d655679fc-lvls2                                      2/2     Running     0          47h\nsetup-nginx-job-tn8sc                                             0/1     Completed   0          47h\nsnow-handlers-d8488f6f8-8lhxh                                     2/2     Running     0          47h\nsre-tunnel-controller-84565ff4f8-4qtwl                            1/1     Running     0          47h\nsre-tunnel-tunnel-network-api-589fd6646d-7znnh                    1/1     Running     0          47h\nsre-tunnel-tunnel-ui-mcmtunnelui-fff9b859b-g7dlk                  1/1     Running     0          47h\nusermgmt-5fb7986c7b-dwmk2                                         1/1     Running     0          47h\nusermgmt-5fb7986c7b-ssk86                                         1/1     Running     0          47h\nzen-audit-678b54b548-n7q7f                                        1/1     Running     0          47h\nzen-core-64c6d56db-d25zm                                          1/1     Running     0          47h\nzen-core-64c6d56db-glv65                                          1/1     Running     1          47h\nzen-core-api-85489478d6-95pck                                     1/1     Running     0          47h\nzen-core-api-85489478d6-n9x5s                                     1/1     Running     0          47h\nzen-metastoredb-0                                                 1/1     Running     0          47h\nzen-metastoredb-1                                                 1/1     Running     0          47h\nzen-metastoredb-2                                                 1/1     Running     0          47h\nzen-metastoredb-certs-lblhv                                       0/1     Completed   0          47h\nzen-metastoredb-init-hvlv2                                        0/1     Completed   0          47h\nzen-post-requisite-job-lpkfw                                      0/1     Completed   0          47h\nzen-pre-requisite-job-2klrt                                       0/1     Completed   0          47h\nzen-watcher-d8b795b46-2q6zx                                       1/1     Running     0          47h\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-33/#access-cp4waiops","title":"Access CP4WAIOps","text":"<p>If all pods for CP4WAIOps are up and running, you can login to CP4WAIOps UI as follows:</p> <p>Login to Red Hat OpenShift Console, click the drop down menu on top right.</p> <p></p> <p>Click the link to <code>IBM Cloud Pak for Administration</code> and login via <code>OpenShift authentication</code>.</p> <p></p> <p>Login to <code>IBM Cloud Pak for Administration</code> and click the drop down menu on top right, then select <code>IBM Automation (cp4waiops)</code>.</p> <p></p> <p>Login to CP4WAIOps UI via <code>OpenShift authentication</code>.</p> <p></p> <p>You will be navigated to CP4WAIOps UI.</p> <p></p> <p>Congratulations! You are ready to play with CP4WAIOps!</p>"},{"location":"how-to-deploy-cp4waiops-33/#install-cp4waiops-from-command-line","title":"Install CP4WAIOps from Command Line","text":""},{"location":"how-to-deploy-cp4waiops-33/#login-to-argo-cd_1","title":"Login to Argo CD","text":"<p>Make sure you have installed Argo CD CLI, i.e.: the <code>argocd</code> command, then run following commands to login to Argo CD:</p> <pre><code>argo_route=openshift-gitops-server\nargo_secret=openshift-gitops-cluster\nsa_account=openshift-gitops-argocd-application-controller\n\nargo_pwd=$(kubectl get secret ${argo_secret} \\\n-n openshift-gitops \\\n-o jsonpath='{.data.admin\\.password}' | base64 -d ; echo ) \\\n&amp;&amp; argo_url=$(kubectl get route ${argo_route} \\\n-n openshift-gitops \\\n-o jsonpath='{.spec.host}') \\\n&amp;&amp; argocd login \"${argo_url}\" \\\n--username admin \\\n--password \"${argo_pwd}\" \\\n--insecure\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-33/#storage-considerations_1","title":"Storage Considerations","text":"<p>If your OpenShift cluster already have default storageclass configured, you can ignore this step. To learn more on storage considerations for CP4WAIOps, please refer to Storage Considerations.</p> <p>In this tutorial, we are using use Ceph just for PoC purpose, but NOT for production. You should always follow storage based on CP4WAIOPS requirements at Storage Considerations.</p> <p>To create Argo CD App for Ceph storage from command line, run following command:</p> <pre><code>argocd app create ceph \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/ceph \\\n--revision HEAD \\\n--dest-namespace rook-ceph \\\n--dest-server https://kubernetes.default.svc\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-33/#option-1-install-ai-manager-and-event-manager-separately_1","title":"Option 1: Install AI Manager and Event Manager Separately","text":""},{"location":"how-to-deploy-cp4waiops-33/#grant-argo-cd-cluster-admin-permission_1","title":"Grant Argo CD Cluster Admin Permission","text":"<p>Apply the following YAML manifest to the cluster where Argo CD runs:</p> <pre><code>kind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\nname: argocd-admin\nsubjects:\n- kind: ServiceAccount\nname: openshift-gitops-argocd-application-controller\nnamespace: openshift-gitops\nroleRef:\napiGroup: rbac.authorization.k8s.io\nkind: ClusterRole\nname: cluster-admin\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-33/#install-ai-manager_1","title":"Install AI Manager","text":"<p>To create Argo CD App for AI Manager to install AI Manager using GitOps, run following command:</p> <pre><code>argocd app create aimanager-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/3.3/ai-manager \\\n--revision HEAD \\\n--dest-namespace cp4waiops \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.imageCatalog=icr.io/cpopen/ibm-operator-catalog:latest \\\n--helm-set spec.dockerUsername=cp \\\n--helm-set spec.dockerPassword=REPLACE_IT \\\n--helm-set spec.storageClass=rook-cephfs \\\n--helm-set spec.storageClassLargeBlock=rook-cephfs \\\n--helm-set spec.aiManager.namespace=cp4waiops \\\n--helm-set spec.aiManager.channel=v3.3 \\\n--helm-set spec.aiManager.size=small \\\n--helm-set spec.aiManager.pakModules.aiopsFoundation.enabled=true \\\n--helm-set spec.aiManager.pakModules.applicationManager.enabled=true \\\n--helm-set spec.aiManager.pakModules.aiManager.enabled=true \\\n--helm-set spec.aiManager.pakModules.connection.enabled=true\n</code></pre> <p>NOTE:</p> <ul> <li>For <code>spec.dockerPassword</code>, it is the entitlement key that you can copy from My IBM Container Software Library.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-33/#install-event-manager_1","title":"Install Event Manager","text":"<p>To create Argo CD App for Event Manager to install Event Manager using GitOps, run following command:</p> <pre><code>argocd app create eventmanager-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/3.3/event-manager \\\n--revision HEAD \\\n--dest-namespace noi \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.imageCatalog=icr.io/cpopen/ibm-operator-catalog:latest \\\n--helm-set spec.dockerUsername=cp \\\n--helm-set spec.dockerPassword=REPLACE_IT \\\n--helm-set spec.storageClass=rook-cephfs \\\n--helm-set spec.storageClassLargeBlock=rook-cephfs \\\n--helm-set spec.eventManager.namespace=noi \\\n--helm-set spec.eventManager.channel=v1.7 \\\n--helm-set spec.eventManager.version=1.6.4 \\\n--helm-set spec.eventManager.clusterDomain=REPLACE_IT \\\n--helm-set spec.eventManager.deploymentType=trial\n</code></pre> <p>NOTE:</p> <ul> <li>For <code>spec.dockerPassword</code>, it is the entitlement key that you can copy from My IBM Container Software Library.</li> <li>For <code>spec.eventManager.clusterDomain</code>, it is the domain name of the cluster where Event Manager is installed. Use fully qualified domain name (FQDN), e.g.: apps.clustername.abc.xyz.com.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-33/#option-2-install-using-all-in-one-configuration_1","title":"Option 2: Install Using All-in-One Configuration","text":"<p>To install Ceph, AI Manager, and Event Manager in one go using all-in-one configuration, run following command:</p> <p><pre><code>argocd app create cp4waiops-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/all-in-one \\\n--revision HEAD \\\n--dest-namespace openshift-gitops \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set argocd.cluster=openshift \\\n--helm-set argocd.allowLocalDeploy=true \\\n--helm-set rookceph.enabled=true \\\n--helm-set cp4waiops.version=v3.3 \\\n--helm-set cp4waiops.dockerUsername=cp \\\n--helm-set cp4waiops.dockerPassword=REPLACE_IT \\\n--helm-set cp4waiops.profile=small \\\n--helm-set cp4waiops.aiManager.enabled=true \\\n--helm-set cp4waiops.aiManager.namespace=cp4waiops \\\n--helm-set cp4waiops.aiManager.instanceName=aiops-installation \\\n--helm-set cp4waiops.eventManager.enabled=true \\\n--helm-set cp4waiops.eventManager.clusterDomain=REPLACE_IT \\\n--helm-set cp4waiops.eventManager.namespace=noi\n</code></pre> NOTE:</p> <ul> <li>For <code>cp4waiops.dockerPassword</code>, it is the entitlement key that you can copy from My IBM Container Software Library.</li> <li>For <code>cp4waiops.profile</code>, the profile <code>x-small</code> is only for demo, PoC, or dev environment. If you are looking for official installation, use profile such as <code>small</code> or <code>large</code> instead.</li> <li>For <code>cp4waiops.eventManager.enabled</code>, it needs to be false if you use <code>x-small</code> profile as it only covers AI Manager, not including Event Manager.</li> <li>For <code>cp4waiops.eventManager.clusterDomain</code>, it is the domain name of the cluster where Event Manager is installed. Use fully qualified domain name (FQDN), e.g.: apps.clustername.abc.xyz.com.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-33/#verify-cp4waiops-installation_1","title":"Verify CP4WAIOps Installation","text":"<p>To verify the CP4WAIOps installation, run following command:</p> <pre><code>kubectl get application -A\n</code></pre> <p>The output will be something similar as follows:</p> <pre><code># kubectl get application -A\nNAMESPACE          NAME                      SYNC STATUS   HEALTH STATUS\nopenshift-gitops   cp4waiops                 Synced        Healthy\nopenshift-gitops   in-cluster-aimanager      Synced        Healthy\nopenshift-gitops   in-cluster-eventmanager   Synced        Healthy\nopenshift-gitops   in-cluster-rook-ceph      Synced        Healthy\n</code></pre> <p>Wait for a while and check if all pods under namespace <code>cp4waiops</code> and <code>noi</code> are up and running without any crash:</p> <pre><code>kubectl get pod -n cp4waiops\nkubectl get pod -n noi\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-34/","title":"How to deploy cp4waiops 34","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Deploy CP4WAIOps 3.4 using GitOps<ul> <li>Prerequisite</li> <li>Install CP4WAIOps from UI<ul> <li>Login to Argo CD</li> <li>Grant Argo CD Cluster Admin Permission</li> <li>Configure Argo CD</li> <li>Storage Considerations</li> <li>Obtain an entitlement key</li> <li>Update the OCP global pull secret<ul> <li>Update the global pull secret using the OpenShift console</li> </ul> </li> <li>Option 1: Install AI Manager and Event Manager Separately<ul> <li>Install shared components</li> <li>Install AI Manager</li> <li>Install Event Manager</li> </ul> </li> <li>Option 2: (Experimental) Install Using All-in-One Configuration<ul> <li>Install AI Manager and Event Manager in One Go</li> <li>Install CP4WAIOps using Custom Build</li> </ul> </li> <li>Verify CP4WAIOps Installation</li> <li>Access CP4WAIOps</li> </ul> </li> <li>Install CP4WAIOps from Command Line<ul> <li>Login to Argo CD (Cli)</li> <li>Storage Considerations (Cli)</li> <li>Option 1: Install AI Manager and Event Manager Separately (Cli)<ul> <li>Grant Argo CD Cluster Admin Permission (Cli)</li> <li>Install shared components (Cli)</li> <li>Install AI Manager (Cli)</li> <li>Install Event Manager (Cli)</li> </ul> </li> <li>Option 2: (Experimental)Install Using All-in-One Configuration (Cli)</li> <li>Verify CP4WAIOps Installation (Cli)</li> </ul> </li> <li>Trouble Shooting<ul> <li>Storage</li> </ul> </li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-34/#deploy-cp4waiops-34-using-gitops","title":"Deploy CP4WAIOps 3.4 using GitOps","text":"<p>:tada::tada::tada: Using GitOps to Install CP4WAIOps is a GA feature for 3.4 release! :tada::tada::tada:</p>"},{"location":"how-to-deploy-cp4waiops-34/#prerequisite","title":"Prerequisite","text":"<ul> <li>To learn CP4WAIOps system requirement, please refer to System requirements for Cloud Pak for Watson AIOps.</li> <li>To install OpenShift GitOps (Argo CD) on OpenShift cluster, please refer to Installing OpenShift GitOps.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-34/#install-cp4waiops-from-ui","title":"Install CP4WAIOps from UI","text":""},{"location":"how-to-deploy-cp4waiops-34/#login-to-argo-cd","title":"Login to Argo CD","text":"<p>You can now login to Argo CD UI as follows by clicking the drop down menu on top right.</p> <p></p> <p>Argo CD UI will be popped up and you can login using <code>LOG IN VIA OPENSHIFT</code>.</p> <p></p>"},{"location":"how-to-deploy-cp4waiops-34/#grant-argo-cd-cluster-admin-permission","title":"Grant Argo CD Cluster Admin Permission","text":"<p>From Red Hat OpenShift Console, go to <code>User Management</code> &gt; <code>RoleBindings</code> &gt; <code>Create binding</code>. Use the form view to configure the properties for the <code>ClusterRoleBinding</code> with values as follows, and click the <code>Create</code> button.</p> <ul> <li>Binding type<ul> <li>Cluster-wide role binding (ClusterRoleBinding)</li> </ul> </li> <li>RoleBinding<ul> <li>Name: argocd-admin</li> </ul> </li> <li>Role<ul> <li>Role Name: cluster-admin</li> </ul> </li> <li>Subject<ul> <li>ServiceAccount: check it</li> <li>Subject namespace: openshift-gitops</li> <li>Subject name: openshift-gitops-argocd-application-controller</li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-34/#configure-argo-cd","title":"Configure Argo CD","text":"<p>From Argo CD UI, click <code>NEW APP</code> and input parameters as follows and then click <code>CREATE</code> button.</p> <ul> <li>GENERAL<ul> <li>Application Name: argocd</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.4</li> <li>path: config/argocd/openshift</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: openshift-gitops</li> </ul> </li> </ul> <p>After Argo CD App <code>argocd</code> is created, you can click the App from Argo CD UI to view the toplogy of all of the resources.</p>"},{"location":"how-to-deploy-cp4waiops-34/#storage-considerations","title":"Storage Considerations","text":"<p>If your OpenShift cluster already have default storageclass configured, you can ignore this step. To learn more on storage considerations for CP4WAIOps, please refer to Storage Considerations.</p> <p>In this tutorial, we are using use Ceph just for PoC purpose, but NOT for production. You should always follow storage based on CP4WAIOPS requirements at Storage Considerations.</p> <p>For deploying on AWS, the EFS(Amazon Elastic File System) can be used for persistant storage. Please refer to AWS EFS guide for details. You can also follow the example of AWS EFS configuration instruction</p> <p>From Argo CD UI, click <code>NEW APP</code> and input parameters as follows for Ceph and then click <code>CREATE</code> button.</p> <ul> <li>GENERAL<ul> <li>Application Name: ceph</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.4</li> <li>path: config/ceph</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: rook-ceph</li> </ul> </li> </ul> <p></p> <p>After Argo CD App <code>ceph</code> is created, you can click the App from Argo CD UI to view the toplogy of all Ceph resources as follows:</p> <p></p> <p>You can use the filters on the left to filter out the resources, and click the resource to check logs and events.</p> <p></p> <p>You can also check all Ceph pods from command line as follows to make sure there is no pod in error state. If there are some pods in error state, you can check logs using <code>kubectl logs</code>.</p> <p><pre><code>[root@api.body.cp.fyre.ibm.com ~]# kubectl get po -n rook-ceph\nNAME                                                              READY   STATUS      RESTARTS   AGE\ncsi-cephfsplugin-7b6jk                                            3/3     Running     0          2d\ncsi-cephfsplugin-l7mvz                                            3/3     Running     0          2d\ncsi-cephfsplugin-provisioner-695b574445-gfcwz                     6/6     Running     6          2d\ncsi-cephfsplugin-provisioner-695b574445-lb64p                     6/6     Running     7          2d\ncsi-cephfsplugin-qcsqz                                            3/3     Running     0          2d\ncsi-cephfsplugin-qdrtl                                            3/3     Running     0          2d\ncsi-cephfsplugin-wj7qq                                            3/3     Running     0          2d\ncsi-cephfsplugin-xlsnb                                            3/3     Running     0          2d\ncsi-rbdplugin-8xwdb                                               3/3     Running     0          2d\ncsi-rbdplugin-b6t9l                                               3/3     Running     0          2d\ncsi-rbdplugin-h965f                                               3/3     Running     0          2d\ncsi-rbdplugin-lv2hp                                               3/3     Running     0          2d\ncsi-rbdplugin-pqvrc                                               3/3     Running     0          2d\ncsi-rbdplugin-provisioner-7f9847cd48-48gqk                        6/6     Running     0          2d\ncsi-rbdplugin-provisioner-7f9847cd48-wxh2z                        6/6     Running     12         2d\ncsi-rbdplugin-x8cw9                                               3/3     Running     0          2d\nrook-ceph-crashcollector-worker0.body.cp.fyre.ibm.com-88f5bnbdc   1/1     Running     0          2d\nrook-ceph-crashcollector-worker1.body.cp.fyre.ibm.com-d4c7gdcts   1/1     Running     0          2d\nrook-ceph-crashcollector-worker2.body.cp.fyre.ibm.com-7767p8fxm   1/1     Running     0          2d\nrook-ceph-crashcollector-worker3.body.cp.fyre.ibm.com-6c5cqs4lk   1/1     Running     0          2d\nrook-ceph-crashcollector-worker4.body.cp.fyre.ibm.com-787f99czf   1/1     Running     0          2d\nrook-ceph-crashcollector-worker5.body.cp.fyre.ibm.com-94d4b654q   1/1     Running     0          2d\nrook-ceph-mds-myfs-a-7d48d48497-sbhld                             1/1     Running     0          2d\nrook-ceph-mds-myfs-b-66f4b746c7-2fnl2                             1/1     Running     0          2d\nrook-ceph-mgr-a-5c84cd7b7b-574lf                                  1/1     Running     0          2d\nrook-ceph-mon-a-7b947ddf45-74p49                                  1/1     Running     0          2d\nrook-ceph-mon-b-7cf885c589-5j6r9                                  1/1     Running     0          2d\nrook-ceph-mon-c-bcb6575d8-g9l5w                                   1/1     Running     0          2d\nrook-ceph-operator-54649856c4-cdx24                               1/1     Running     0          2d\nrook-ceph-osd-0-c44985597-gwkqk                                   1/1     Running     0          2d\nrook-ceph-osd-1-6f7d5cc955-v4862                                  1/1     Running     0          2d\nrook-ceph-osd-2-58df99c46f-5kl8z                                  1/1     Running     0          2d\nrook-ceph-osd-3-5c8579456c-bpcqz                                  1/1     Running     0          2d\nrook-ceph-osd-4-5668c69fbf-kvdf6                                  1/1     Running     0          2d\nrook-ceph-osd-5-cbbdb95-cqvjd                                     1/1     Running     0          2d\nrook-ceph-osd-prepare-worker0.body.cp.fyre.ibm.com-bxr7t          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker1.body.cp.fyre.ibm.com-fftd8          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker2.body.cp.fyre.ibm.com-scg84          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker3.body.cp.fyre.ibm.com-m488b          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker4.body.cp.fyre.ibm.com-dxcm5          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker5.body.cp.fyre.ibm.com-jclnq          0/1     Completed   0          4h16m\n</code></pre> NOTE:</p> <ul> <li>In some cases, there're multiple storageclasse been set to default, and this will causes issue, to avoid that, you can check the cluster sc with follwoing command: <pre><code>oc get sc\n</code></pre>   In cases of multiple default storageclass appears in the list, you will need to remove all of the other default setting and only leave one storageclass set as the default storageclasse.   To remove the default setting from a sc, <ul> <li>use <code>oc edit sc [STORAGE-CLASS-NAME]</code> command.</li> <li>remove the <code>storageclass.kubernetes.io/is-default-class: \"true\"</code> line under <code>annotations</code></li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-34/#obtain-an-entitlement-key","title":"Obtain an entitlement key","text":"<p>If you don't already have an entitlement key to the IBM Entitled Registry, obtain your key using the following instructions:</p> <ol> <li> <p>Go to the Container software library.</p> </li> <li> <p>Click \"Copy key.\"</p> </li> <li> <p>Copy the entitlement key to a safe place so you can use it when updating the global pull secret for the cluster.</p> </li> <li> <p>(Optional) Verify the validity of the key by logging in to the IBM Entitled Registry using a container tool:    Depending on what contianer system you are using, you might need to use <code>docker login</code> instead of <code>podman login</code> for following commands.</p> </li> </ol> <pre><code>export IBM_ENTITLEMENT_KEY=the key from the previous steps\npodman login cp.icr.io --username cp --password \"${IBM_ENTITLEMENT_KEY:?}\"\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-34/#update-the-ocp-global-pull-secret","title":"Update the OCP global pull secret","text":"<p>Update the OCP global pull secret with the entitlement key.</p> <p>Keep in mind that the registry user for that secret is \"cp\". A common mistakes is to assume the registry user is the name or email of the user owning the entitlement key.</p>"},{"location":"how-to-deploy-cp4waiops-34/#update-the-global-pull-secret-using-the-openshift-console","title":"Update the global pull secret using the OpenShift console","text":"<ol> <li> <p>Navigate to the \"Workloads &gt; Secrets\" page in the \"Administrator\" perspective.</p> </li> <li> <p>Select the project \"openshift-config\".(for latest version ocp, the <code>Show default projects</code> switch under <code>Project:</code> need to be enabled before selecting project.)</p> </li> <li> <p>Select the object \"pull-secret\".</p> </li> <li> <p>Click on \"Actions -&gt; Edit secret\".</p> </li> <li> <p>Scroll to the bottom of that page and click on \"Add credentials\", using the following values for each field:</p> <ul> <li>\"Registry Server Address\" cp.icr.io</li> <li>\"Username\": cp</li> <li>\"Password\": paste the entitlement key you copied from the Obtain an entitlement key setp</li> <li>\"Email\": any email, valid or not, will work. This fields is mostly a hint to other people who may see the entry in the configuration</li> </ul> </li> <li> <p>Click on \"Save\"</p> </li> </ol>"},{"location":"how-to-deploy-cp4waiops-34/#option-1-install-ai-manager-and-event-manager-separately","title":"Option 1: Install AI Manager and Event Manager Separately","text":""},{"location":"how-to-deploy-cp4waiops-34/#install-shared-components","title":"Install shared components","text":"<ul> <li>GENERAL<ul> <li>Application Name: anyname (e.g.: \"cp-shared\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.4</li> <li>path: config/cp-shared/operators</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: openshift-marketplace</li> </ul> </li> <li>PARAMETERS<ul> <li>spec.imageCatalog: icr.io/cpopen/ibm-operator-catalog:latest</li> <li>spec.catalogName: ibm-operator-catalog</li> <li>spec.catalogNamespace: openshift-marketplace</li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-34/#install-ai-manager","title":"Install AI Manager","text":"<p>You can install CP4WAIOps - AI Manager using GitOps by creating an Argo CD App. The parameters for AI Manager are as follows:</p> <ul> <li>GENERAL<ul> <li>Application Name: anyname (e.g.: \"aimanager-app\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.4</li> <li>path: config/cp4waiops/install-aimgr</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: cp4waiops</li> </ul> </li> <li>PARAMETERS<ul> <li>spec.storageClass: rook-cephfs  (need to update the storage class to what is being used in your environment, check it with <code>oc get sc</code> command.)</li> <li>spec.storageClassLargeBlock: rook-cephfs  (need to update the storage class to what is being used in your environment, check it with <code>oc get sc</code> command.)</li> <li>spec.aiManager.channel: v3.4</li> <li>spec.aiManager.size: small</li> <li>spec.aiManager.namespace: cp4waiops</li> <li>spec.aiManager.pakModules.aiopsFoundation.enabled: true</li> <li>spec.aiManager.pakModules.applicationManager.enabled: true</li> <li>spec.aiManager.pakModules.aiManager.enabled: true</li> <li>spec.aiManager.pakModules.connection.enabled: true</li> </ul> </li> </ul> <p>NOTE:</p> <ul> <li>For <code>Repository URL</code> and <code>Revision</code> field, if you use a repository forked from the official CP4WAIOps GitOps repository and/or on a different branch, please fill these fields using your own values. For example, if you use <code>https://github.com/&lt;myaccount&gt;/cp4waiops-gitops</code> and <code>dev</code> branch, the two fields need to be changed accordingly.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-34/#install-event-manager","title":"Install Event Manager","text":"<p>You can install CP4WAIOps - Event Manager using GitOps by creating an Argo CD App. The parameters for Event Manager are as follows:</p> <ul> <li>GENERAL<ul> <li>Application Name: anyname (e.g.: \"eventmanager-app\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.4</li> <li>path: config/cp4waiops/install-emgr</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: noi </li> </ul> </li> <li>PARAMETERS<ul> <li>spec.imageCatalog: icr.io/cpopen/ibm-operator-catalog:latest</li> <li>spec.storageClass: rook-cephfs  (need to update the storage class to what is being used in your environment, check it with <code>oc get sc</code> command.)</li> <li>spec.storageClassLargeBlock: rook-cephfs  (need to update the storage class to what is being used in your environment, check it with <code>oc get sc</code> command.)</li> <li>spec.eventManager.version: 1.6.4</li> <li>spec.eventManager.clusterDomain: REPLACE_IT</li> <li>spec.eventManager.channel: v1.7</li> <li>spec.eventManager.deploymentType: trial</li> <li>spec.eventManager.namespace: noi</li> </ul> </li> </ul> <p>NOTE:</p> <ul> <li>For <code>Repository URL</code> and <code>Revision</code> field, if you use a repository forked from the official CP4WAIOps GitOps repository and/or on a different branch, please fill these fields using your own values. For example, if you use <code>https://github.com/&lt;myaccount&gt;/cp4waiops-gitops</code> and <code>dev</code> branch, the two fields need to be changed accordingly.</li> <li>For <code>spec.eventManager.clusterDomain</code>, it is the domain name of the cluster where Event Manager is installed. Use fully qualified domain name (FQDN), e.g.: apps.clustername.abc.xyz.com. You can also get it by running command below: <pre><code>INGRESS_OPERATOR_NAMESPACE=openshift-ingress-operator\nappDomain=`kubectl -n ${INGRESS_OPERATOR_NAMESPACE} get ingresscontrollers default -o json | python -c \"import json,sys;obj=json.load(sys.stdin);print obj['status']['domain'];\"`\necho ${appDomain}\n</code></pre></li> </ul>"},{"location":"how-to-deploy-cp4waiops-34/#option-2-experimental-install-using-all-in-one-configuration","title":"Option 2: (Experimental) Install Using All-in-One Configuration","text":""},{"location":"how-to-deploy-cp4waiops-34/#install-ai-manager-and-event-manager-in-one-go","title":"Install AI Manager and Event Manager in One Go","text":"<p>The all-in-one configuration allows you to install following components in one go:</p> <ul> <li>Ceph storage (optional)</li> <li>AI Manager</li> <li>Event Manager</li> </ul> <p>Just fill in the form using the suggested field values listed in following table when you create the Argo CD App:</p> Field Value Application Name anyname (e.g. cp4waiops-app) Project default Sync Policy Automatic Repository URL https://github.com/IBM/cp4waiops-gitops Revision release-3.4 Path config/all-in-one Cluster URL https://kubernetes.default.svc Namespace openshift-gitops <p>Besides the basic information, when filling in the form, you can also update the following install parameters that are commonly used to customize the install behavior.</p> Parameter Type Default Value Description argocd.cluster string openshift The type of the cluster that Argo CD runs on, valid values include: openshift, kubernetes. argocd.allowLocalDeploy bool true Allow apps to be deployed on the same cluster where Argo CD runs. rookceph.enabled bool true Specify whether or not to install Ceph as storage used by CP4WAIOps. cp4waiops.version string v3.4 Specify the version of CP4WAIOps v3.4. cp4waiops.profile string small The CP4WAIOps deployment profile, e.g.: x-small, small, large. cp4waiops.aiManager.enabled bool true Specify whether or not to install AI Manager. cp4waiops.aiManager.namespace string cp4waiops The namespace where AI Manager is installed. cp4waiops.aiManager.instanceName string aiops-installation The instance name of AI Manager. cp4waiops.eventManager.enabled bool true Specify whether or not to install Event Manager. cp4waiops.eventManager.namespace string noi The namespace where Event Manager is installed. cp4waiops.eventManager.clusterDomain string REPLACE_IT The domain name of the cluster where Event Manager is installed. <p>NOTE:</p> <ul> <li>For <code>cp4waiops.profile</code>, the profile <code>x-small</code> is only for demo, PoC, or dev environment. If you are looking for official installation, use profile such as <code>small</code> or <code>large</code> instead.</li> <li>For <code>cp4waiops.eventManager.enabled</code>, it needs to be false if you use <code>x-small</code> profile as it only covers AI Manager, not including Event Manager.</li> <li>For <code>cp4waiops.eventManager.clusterDomain</code>, it is the domain name of the cluster where Event Manager is installed. Use fully qualified domain name (FQDN), e.g.: apps.clustername.abc.xyz.com.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-34/#install-cp4waiops-using-custom-build","title":"Install CP4WAIOps using Custom Build","text":"<p>The all-in-one configuration also allows you to install CP4WAIOps using custom build by providing specific image catalog and channel.</p> <p>Just use the install parameters listed in following table when you create the Argo CD App:</p> Parameter Type Default Value Description cp4waiops.aiManager.imageCatalog string icr.io/cpopen/ibm-operator-catalog:latest The image catalog for AI Manager. cp4waiops.aiManager.channel string v3.4 The subscription channel for AI Manager. cp4waiops.eventManager.imageCatalog string icr.io/cpopen/ibm-operator-catalog:latest The image catalog for Event Manager. cp4waiops.eventManager.channel string v1.7 The subscription channel for Event Manager. <p>These parameters are invisible when you create the Argo CD App from UI, but you can add them when filling in the form in <code>HELM</code> &gt; <code>VALUES</code> field.</p> <p>For example, adding following YAML snippet to <code>HELM</code> &gt; <code>VALUES</code> field will install AI Manager and Event Manager using custom imageCatalog and channel:</p> <pre><code>cp4waiops:\naiManager:\nimageCatalog: &lt;my_custom_image_catalog_for_ai_manager&gt;\nchannel: &lt;my_custom_channel_for_ai_manager&gt;\neventManager:\nimageCatalog: &lt;my_custom_image_catalog_for_event_manager&gt;\nchannel: &lt;my_custom_channel_for_event_manager&gt;\n````\n\nBesides that, the all-in-one configuration exposes a few more install parameters invisible from UI that allows you to customize the install behavior in a more fine-grained manner. Below is just a list of some available parameters. To learn more on the usage of such parameters, please refer to [CP4WAIOps Customized Install Options Using GitOps](./cp4waiops-custom-install.md).\n\n| Parameter                             | Type   | Default Value | Description | ------------------------------------- |--------|---------------|-----------------------------------\n| cp4waiops.storageClass                | string | rook-cephfs   | The storage class for CP4WAIOps to use.\n| cp4waiops.storageClassLargeBlock      | string | rook-cephfs   | The storage class for large block for CP4WAIOps to use.\n| cp4waiops.eventManager.version        | string | 1.6.4         | The version of Event Manager.\n| cp4waiops.eventManager.deploymentType | string | trial         | The deployment type of Event Manager, valid values include: trial, production.\n| globalImagePullSecrets                | array  | n/a           | A list of registries for image pull when needed during the install.\n\nFor example, if the custom build to be installed includes images from registries other than the official IBM entitled registry, you can use `globalImagePullSecrets` to specify all necessary information for these registries including registry URLs, as well as username and password to access these registries.\n\nAgain, since these parameters are invisible, you can add them when filling in the form in `HELM` &gt; `VALUES` field:\n\n```yaml\nglobalImagePullSecrets:\n- registry: &lt;my_own_registry_1&gt;\nusername: &lt;username_to_registry_1&gt;\npassword: &lt;password_to_registry_1&gt;\n- registry: &lt;my_own_registry_2&gt;\nusername: &lt;username_to_registry_2&gt;\npassword: &lt;password_to_registry_2&gt;\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-34/#verify-cp4waiops-installation","title":"Verify CP4WAIOps Installation","text":"<p>After both Ceph and CP4WAIOps are ready, you will be able to see those Apps from Argo CD UI as follows with status as <code>Healthy</code> and <code>Synced</code>.</p> <p></p> <p></p> <p>You can check the topology of CP4WAIOps using Argo CD UI as follows:</p> <p></p> <p></p> <p>You can also check from command line as follows, and make sure there are no error pods. If there are some pods in error state, you can check logs either from Argo CD UI or using <code>kubectl logs</code> from command line.</p> <p>For example, to check pods of AI Manager:</p> <pre><code>[root@api.body.cp.fyre.ibm.com ~]# kubectl get po -n cp4waiops\nNAME                                                              READY   STATUS      RESTARTS   AGE\naimanager-aio-ai-platform-api-server-7c877989d6-7jh55             1/1     Running     0          47h\naimanager-aio-change-risk-654884bd8c-6xpxw                        1/1     Running     0          47h\naimanager-aio-chatops-orchestrator-7c54fc5664-rtmrp               1/1     Running     0          47h\naimanager-aio-chatops-slack-integrator-77fc9499c4-wtclt           1/1     Running     0          47h\naimanager-aio-chatops-teams-integrator-577f6b85bf-j2995           1/1     Running     0          47h\naimanager-aio-controller-86875d4b7-jfwwp                          1/1     Running     0          47h\naimanager-aio-create-secrets-ccjdg                                0/1     Completed   0          47h\naimanager-aio-create-truststore-5hxps                             0/1     Completed   0          47h\naimanager-aio-curator-job-27362220-k59t8                          0/1     Completed   0          142m\naimanager-aio-curator-job-27362280-n2w88                          0/1     Completed   0          82m\naimanager-aio-curator-job-27362340-qkwln                          0/1     Completed   0          22m\naimanager-aio-log-anomaly-detector-fdfcbb96b-rpb9q                1/1     Running     0          47h\naimanager-aio-log-anomaly-detector-fdfcbb96b-v426m                1/1     Running     0          47h\naimanager-aio-similar-incidents-service-77cc9d699f-qlxgg          1/1     Running     0          47h\naimanager-ibm-minio-0                                             1/1     Running     0          47h\naimanager-operator-585d799f9f-w22vz                               1/1     Running     0          47h\naiops-ai-model-ui-674b4f77f9-qv56n                                1/1     Running     0          47h\naiops-akora-ui-7bc6d5dd6b-6n9rs                                   1/1     Running     0          47h\naiops-application-details-ui-66779f957b-fqfhk                     1/1     Running     0          47h\naiops-base-ui-5b9f885888-pvm7z                                    1/1     Running     0          47h\naiops-connections-ui-7996699c55-m79fl                             1/1     Running     0          47h\naiops-ir-analytics-classifier-75869fd78b-p2s9v                    1/1     Running     0          47h\naiops-ir-analytics-probablecause-6dd5ffd867-rrg6b                 1/1     Running     2          47h\naiops-ir-analytics-spark-master-5cd57946d4-99bqt                  1/1     Running     0          47h\naiops-ir-analytics-spark-pipeline-composer-795f965b6d-vkjqw       1/1     Running     0          47h\naiops-ir-analytics-spark-worker-65d57f7f9c-4nsb8                  1/1     Running     0          47h\naiops-ir-core-archiving-754dcb5fcb-jm82z                          1/1     Running     0          47h\naiops-ir-core-archiving-setup-rrlkh                               0/1     Completed   0          47h\naiops-ir-core-cem-users-65b9b699b9-hzh9b                          1/1     Running     0          47h\naiops-ir-core-esarchiving-67dbb7c5d7-wg7dx                        1/1     Running     0          47h\naiops-ir-core-logstash-6c89d66f79-tlfcl                           1/1     Running     0          47h\naiops-ir-core-ncobackup-0                                         2/2     Running     0          47h\naiops-ir-core-ncodl-api-59f977b475-lx7n4                          1/1     Running     0          47h\naiops-ir-core-ncodl-if-66cf44c565-lkkgx                           1/1     Running     0          47h\naiops-ir-core-ncodl-ir-7469fd4866-wjfvf                           1/1     Running     0          47h\naiops-ir-core-ncodl-jobmgr-76d74b5567-t77wc                       1/1     Running     0          47h\naiops-ir-core-ncodl-setup-8hx6c                                   0/1     Completed   0          47h\naiops-ir-core-ncodl-std-7677546c8d-dbqm9                          1/1     Running     0          47h\naiops-ir-core-ncodl-std-7677546c8d-wf82d                          1/1     Running     0          47h\naiops-ir-core-ncoprimary-0                                        1/1     Running     0          47h\naiops-ir-lifecycle-create-policies-job-dljxp                      0/1     Completed   0          47h\naiops-ir-lifecycle-eventprocessor-ep-jobmanager-0                 2/2     Running     0          47h\naiops-ir-lifecycle-eventprocessor-ep-taskmanager-0                1/1     Running     0          47h\naiops-ir-lifecycle-logstash-77579f5d7f-9rhsx                      1/1     Running     0          47h\naiops-ir-lifecycle-policy-grpc-svc-6b59698569-cvhvq               1/1     Running     0          47h\naiops-ir-lifecycle-policy-registry-svc-68647d4cdc-t27mw           1/1     Running     0          47h\naiops-ir-lifecycle-policy-registry-svc-job-8gk89                  0/1     Completed   3          47h\naiops-ir-ui-api-graphql-68488c7675-87mbp                          1/1     Running     0          47h\naiops-topology-cassandra-0                                        1/1     Running     0          47h\naiops-topology-cassandra-auth-secret-generator-7mm84              0/1     Completed   0          47h\naiops-topology-file-observer-5757769dd5-xxc8j                     1/1     Running     0          47h\naiops-topology-kubernetes-observer-d4c8bcb55-ddbcg                1/1     Running     0          47h\naiops-topology-layout-6b957b5bbb-m28rd                            1/1     Running     0          47h\naiops-topology-merge-76c494795f-5b65g                             1/1     Running     0          47h\naiops-topology-observer-service-6f5d6fb44b-jswwp                  1/1     Running     0          47h\naiops-topology-rest-observer-799bfdf4c8-5nt6n                     1/1     Running     0          47h\naiops-topology-search-6cd7cc9d8-64bdk                             1/1     Running     0          47h\naiops-topology-secret-manager-2b84s                               0/1     Completed   0          47h\naiops-topology-servicenow-observer-84c588df5b-gm6p2               1/1     Running     0          47h\naiops-topology-status-58ddcdc845-mqpzg                            1/1     Running     0          47h\naiops-topology-topology-577b988f78-kc2m6                          1/1     Running     2          47h\naiops-topology-ui-api-bbd74965d-gzlfd                             1/1     Running     0          47h\naiops-topology-vmvcenter-observer-86b6c8dc44-krvtj                1/1     Running     0          47h\naiopsedge-github-topology-integrator-7b9db59cd8-nbdgz             1/1     Running     0          47h\naiopsedge-operator-controller-manager-9b68ddd75-5rqqz             1/1     Running     1          47h\naiopsedge-operator-controller-manager-9b68ddd75-xj7tq             1/1     Running     1          47h\nasm-operator-548c8894fd-r2dgv                                     1/1     Running     0          47h\nc-example-couchdbcluster-m-0                                      3/3     Running     0          47h\nc-example-redis-m-0                                               4/4     Running     0          47h\nc-example-redis-m-1                                               4/4     Running     0          47h\nc-example-redis-m-2                                               4/4     Running     0          47h\nc-example-redis-s-0                                               4/4     Running     0          47h\nc-example-redis-s-1                                               4/4     Running     0          47h\nc-example-redis-s-2                                               4/4     Running     0          47h\ncamel-k-kit-c7c60rolvegv49tvh8fg-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60sglvegv49tvh8g0-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60tglvegv49tvh8gg-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60tolvegv49tvh8h0-1-build                          0/1     Completed   0          47h\ncamel-k-operator-684f46fc4d-s6hf2                                 1/1     Running     0          47h\nconfigure-aiops-network-policy-967ll                              0/1     Completed   0          47h\nconnector-controller-bc7fc6668-f8nn5                              1/1     Running     0          47h\nconnector-synchronizer-7d4546ddd4-5kbrl                           1/1     Running     0          47h\ncouchdb-operator-d5cb7ff8c-rjnhx                                  1/1     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-jobmanager-0                 2/2     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-jobmanager-1                 2/2     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-taskmanager-0                1/1     Running     1          47h\ncp4waiops-eventprocessor-eve-29ee-ep-taskmanager-1                1/1     Running     0          47h\ncp4waiops-image-pull-secret-6fprf                                 0/1     Completed   0          2d\ncp4waiops-patch-j4qrm                                             0/1     Completed   0          2d\ncp4waiops-postgres-keeper-0                                       1/1     Running     0          47h\ncp4waiops-postgres-postgresql-create-cluster-7xb6t                0/1     Completed   0          47h\ncp4waiops-postgres-proxy-648bc64fd-x4mvv                          1/1     Running     0          47h\ncp4waiops-postgres-sentinel-5878f67f46-gvv7l                      1/1     Running     0          47h\ncp4waiops-postgresdb-postgresql-create-database-9j6kq             0/1     Completed   0          47h\ncreate-secrets-job-nx6dg                                          0/1     Completed   0          47h\ngateway-kong-5d45b77fb4-tgjcv                                     2/2     Running     2          47h\ngateway-kong-config-svc-27362360-9dmzc                            0/1     Completed   0          2m51s\niaf-core-operator-controller-manager-58dfd97f5c-bdd9t             1/1     Running     0          2d\niaf-eventprocessing-operator-controller-manager-5bc597797f6fxm4   1/1     Running     1          2d\niaf-flink-operator-controller-manager-7dc56c9b68-6rgtk            1/1     Running     0          2d\niaf-operator-controller-manager-6bc8f44ff7-rrrnx                  1/1     Running     0          2d\niaf-system-elasticsearch-es-aiops-0                               2/2     Running     0          47h\niaf-system-entity-operator-6b5444f575-7tdfw                       3/3     Running     0          47h\niaf-system-kafka-0                                                1/1     Running     0          47h\niaf-system-zookeeper-0                                            1/1     Running     0          47h\niaf-zen-tour-job-fhdfr                                            0/1     Completed   0          47h\niam-config-job-tfsst                                              0/1     Completed   0          47h\nibm-aiops-orchestrator-6c7cfc85b7-wqdnr                           1/1     Running     0          2d\nibm-cloud-databases-redis-operator-854cf65c4f-4rrvn               1/1     Running     0          47h\nibm-common-service-operator-5cd6947dc8-z8plb                      1/1     Running     0          2d\nibm-elastic-operator-controller-manager-5d6c467b55-wtrvg          1/1     Running     0          2d\nibm-ir-ai-operator-controller-manager-59b88c6bf6-ncnbt            1/1     Running     7          47h\nibm-kong-operator-6ff97bcdb9-rl7cp                                1/1     Running     0          47h\nibm-nginx-cd84b4d8-7ttn2                                          1/1     Running     0          47h\nibm-nginx-cd84b4d8-zp4t2                                          1/1     Running     0          47h\nibm-postgreservice-operator-controller-manager-8b7bdf589-hbg2g    1/1     Running     2          47h\nibm-secure-tunnel-operator-657dd7b78f-tsgws                       1/1     Running     0          47h\nibm-vault-deploy-consul-0                                         1/1     Running     0          47h\nibm-vault-deploy-vault-0                                          1/1     Running     0          47h\nibm-vault-deploy-vault-cron-job-27361440-qxpjl                    0/1     Completed   0          15h\nibm-vault-deploy-vault-injector-596567d459-wzkws                  1/1     Running     0          47h\nibm-vault-operator-controller-manager-5957bb5ff9-4zdrb            1/1     Running     0          47h\nibm-watson-aiops-ui-operator-controller-manager-b8cf6fff7-msspt   1/1     Running     0          47h\nir-core-operator-controller-manager-76dbdb699d-g97ng              1/1     Running     7          47h\nir-lifecycle-operator-controller-manager-64bdd8f7b6-pn46g         1/1     Running     9          47h\nmodel-train-classic-operator-56d487585c-4dv5b                     1/1     Running     2          47h\nmodeltrain-ibm-modeltrain-lcm-865b7f85cc-jfq4z                    1/1     Running     0          47h\nmodeltrain-ibm-modeltrain-ratelimiter-595f4f478-r9dwp             1/1     Running     0          47h\nmodeltrain-ibm-modeltrain-trainer-5b7f7888b5-c8cz5                1/1     Running     0          47h\npost-aiops-resources-t4ww9                                        0/1     Completed   0          47h\npost-aiops-translations-t58bb                                     0/1     Completed   0          47h\npost-aiops-update-user-role-kcr8k                                 0/1     Completed   0          47h\nscm-handlers-d655679fc-lvls2                                      2/2     Running     0          47h\nsetup-nginx-job-tn8sc                                             0/1     Completed   0          47h\nsnow-handlers-d8488f6f8-8lhxh                                     2/2     Running     0          47h\nsre-tunnel-controller-84565ff4f8-4qtwl                            1/1     Running     0          47h\nsre-tunnel-tunnel-network-api-589fd6646d-7znnh                    1/1     Running     0          47h\nsre-tunnel-tunnel-ui-mcmtunnelui-fff9b859b-g7dlk                  1/1     Running     0          47h\nusermgmt-5fb7986c7b-dwmk2                                         1/1     Running     0          47h\nusermgmt-5fb7986c7b-ssk86                                         1/1     Running     0          47h\nzen-audit-678b54b548-n7q7f                                        1/1     Running     0          47h\nzen-core-64c6d56db-d25zm                                          1/1     Running     0          47h\nzen-core-64c6d56db-glv65                                          1/1     Running     1          47h\nzen-core-api-85489478d6-95pck                                     1/1     Running     0          47h\nzen-core-api-85489478d6-n9x5s                                     1/1     Running     0          47h\nzen-metastoredb-0                                                 1/1     Running     0          47h\nzen-metastoredb-1                                                 1/1     Running     0          47h\nzen-metastoredb-2                                                 1/1     Running     0          47h\nzen-metastoredb-certs-lblhv                                       0/1     Completed   0          47h\nzen-metastoredb-init-hvlv2                                        0/1     Completed   0          47h\nzen-post-requisite-job-lpkfw                                      0/1     Completed   0          47h\nzen-pre-requisite-job-2klrt                                       0/1     Completed   0          47h\nzen-watcher-d8b795b46-2q6zx                                       1/1     Running     0          47h\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-34/#access-cp4waiops","title":"Access CP4WAIOps","text":"<p>If all pods for CP4WAIOps are up and running, you can login to CP4WAIOps UI as follows:</p> <p>Login to Red Hat OpenShift Console, click the drop down menu on top right.</p> <p></p> <p>Click the link to <code>IBM Cloud Pak for Administration</code> and login via <code>OpenShift authentication</code>.</p> <p></p> <p>Login to <code>IBM Cloud Pak for Administration</code> and click the drop down menu on top right, then select <code>IBM Automation (cp4waiops)</code>.</p> <p></p> <p>Login to CP4WAIOps UI via <code>OpenShift authentication</code>.</p> <p></p> <p>You will be navigated to CP4WAIOps UI.</p> <p></p> <p>Congratulations! You are ready to play with CP4WAIOps!</p>"},{"location":"how-to-deploy-cp4waiops-34/#install-cp4waiops-from-command-line","title":"Install CP4WAIOps from Command Line","text":""},{"location":"how-to-deploy-cp4waiops-34/#login-to-argo-cd-cli","title":"Login to Argo CD (Cli)","text":"<p>Make sure you have installed Argo CD CLI, i.e.: the <code>argocd</code> command, then run following commands to login to Argo CD:</p> <pre><code>argo_route=openshift-gitops-server\nargo_secret=openshift-gitops-cluster\nsa_account=openshift-gitops-argocd-application-controller\n\nargo_pwd=$(kubectl get secret ${argo_secret} \\\n-n openshift-gitops \\\n-o jsonpath='{.data.admin\\.password}' | base64 -d ; echo ) \\\n&amp;&amp; argo_url=$(kubectl get route ${argo_route} \\\n-n openshift-gitops \\\n-o jsonpath='{.spec.host}') \\\n&amp;&amp; argocd login \"${argo_url}\" \\\n--username admin \\\n--password \"${argo_pwd}\" \\\n--insecure\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-34/#storage-considerations-cli","title":"Storage Considerations (Cli)","text":"<p>If your OpenShift cluster already have default storageclass configured, you can ignore this step. To learn more on storage considerations for CP4WAIOps, please refer to Storage Considerations.</p> <p>In this tutorial, we are using use Ceph just for PoC purpose, but NOT for production. You should always follow storage based on CP4WAIOPS requirements at Storage Considerations.</p> <p>To create Argo CD App for Ceph storage from command line, run following command:</p> <pre><code>argocd app create ceph \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/ceph \\\n--revision release-3.4 \\\n--dest-namespace rook-ceph \\\n--dest-server https://kubernetes.default.svc\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-34/#option-1-install-ai-manager-and-event-manager-separately-cli","title":"Option 1: Install AI Manager and Event Manager Separately (Cli)","text":""},{"location":"how-to-deploy-cp4waiops-34/#grant-argo-cd-cluster-admin-permission-cli","title":"Grant Argo CD Cluster Admin Permission (Cli)","text":"<p>Apply the following YAML manifest to the cluster where Argo CD runs:</p> <pre><code>kind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\nname: argocd-admin\nsubjects:\n- kind: ServiceAccount\nname: openshift-gitops-argocd-application-controller\nnamespace: openshift-gitops\nroleRef:\napiGroup: rbac.authorization.k8s.io\nkind: ClusterRole\nname: cluster-admin\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-34/#install-shared-components-cli","title":"Install shared components (Cli)","text":"<pre><code>argocd app create cp-shared \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/cp-shared/operators \\\n--revision release-3.4 \\\n--dest-namespace openshift-marketplace \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.imageCatalog=icr.io/cpopen/ibm-operator-catalog:latest \\\n--helm-set spec.catalogName=ibm-operator-catalog \\\n--helm-set spec.catalogNamespace=openshift-marketplace\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-34/#install-ai-manager-cli","title":"Install AI Manager (Cli)","text":"<p>To create Argo CD App for AI Manager to install AI Manager using GitOps, run following command:</p> <pre><code>argocd app create aimanager-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/cp4waiops/install-aimgr \\\n--revision release-3.4 \\\n--dest-namespace cp4waiops \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.storageClass=rook-cephfs \\\n--helm-set spec.storageClassLargeBlock=rook-cephfs \\\n--helm-set spec.aiManager.namespace=cp4waiops \\\n--helm-set spec.aiManager.channel=v3.4 \\\n--helm-set spec.aiManager.size=small \\\n--helm-set spec.aiManager.pakModules.aiopsFoundation.enabled=true \\\n--helm-set spec.aiManager.pakModules.applicationManager.enabled=true \\\n--helm-set spec.aiManager.pakModules.aiManager.enabled=true \\\n--helm-set spec.aiManager.pakModules.connection.enabled=true\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-34/#install-event-manager-cli","title":"Install Event Manager (Cli)","text":"<p>To create Argo CD App for Event Manager to install Event Manager using GitOps, run following command:</p> <pre><code>argocd app create eventmanager-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/cp4waiops/install-emgr \\\n--revision release-3.4 \\\n--dest-namespace noi \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.imageCatalog=icr.io/cpopen/ibm-operator-catalog:latest \\\n--helm-set spec.storageClass=rook-cephfs \\\n--helm-set spec.storageClassLargeBlock=rook-cephfs \\\n--helm-set spec.eventManager.namespace=noi \\\n--helm-set spec.eventManager.channel=v1.7 \\\n--helm-set spec.eventManager.version=1.6.4 \\\n--helm-set spec.eventManager.clusterDomain=REPLACE_IT \\\n--helm-set spec.eventManager.deploymentType=trial\n</code></pre> <p>NOTE:</p> <ul> <li>For <code>spec.eventManager.clusterDomain</code>, it is the domain name of the cluster where Event Manager is installed. Use fully qualified domain name (FQDN), e.g.: apps.clustername.abc.xyz.com. You can also get it by running command below:  </li> </ul> <pre><code>INGRESS_OPERATOR_NAMESPACE=openshift-ingress-operator\nappDomain=`kubectl -n ${INGRESS_OPERATOR_NAMESPACE} get ingresscontrollers default -o json | python -c \"import json,sys;obj=json.load(sys.stdin);print obj['status']['domain'];\"`\necho ${appDomain}\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-34/#option-2-experimentalinstall-using-all-in-one-configuration-cli","title":"Option 2: (Experimental)Install Using All-in-One Configuration (Cli)","text":"<p>To install Ceph, AI Manager, and Event Manager in one go using all-in-one configuration, run following command:</p> <p><pre><code>argocd app create cp4waiops-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/all-in-one \\\n--revision release-3.4 \\\n--dest-namespace openshift-gitops \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set argocd.cluster=openshift \\\n--helm-set argocd.allowLocalDeploy=true \\\n--helm-set rookceph.enabled=true \\\n--helm-set cp4waiops.version=v3.4 \\\n--helm-set cp4waiops.profile=small \\\n--helm-set cp4waiops.aiManager.enabled=true \\\n--helm-set cp4waiops.aiManager.namespace=cp4waiops \\\n--helm-set cp4waiops.aiManager.instanceName=aiops-installation \\\n--helm-set cp4waiops.eventManager.enabled=true \\\n--helm-set cp4waiops.eventManager.clusterDomain=REPLACE_IT \\\n--helm-set cp4waiops.eventManager.namespace=noi\n</code></pre> NOTE:</p> <ul> <li>For <code>cp4waiops.profile</code>, the profile <code>x-small</code> is only for demo, PoC, or dev environment. If you are looking for official installation, use profile such as <code>small</code> or <code>large</code> instead.</li> <li>For <code>cp4waiops.eventManager.enabled</code>, it needs to be false if you use <code>x-small</code> profile as it only covers AI Manager, not including Event Manager.</li> <li>For <code>cp4waiops.eventManager.clusterDomain</code>, it is the domain name of the cluster where Event Manager is installed. Use fully qualified domain name (FQDN), e.g.: apps.clustername.abc.xyz.com.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-34/#verify-cp4waiops-installation-cli","title":"Verify CP4WAIOps Installation (Cli)","text":"<p>To verify the CP4WAIOps installation, run following command:</p> <pre><code>kubectl get application -A\n</code></pre> <p>The output will be something similar as follows:</p> <pre><code># kubectl get application -A\nNAMESPACE          NAME                      SYNC STATUS   HEALTH STATUS\nopenshift-gitops   cp4waiops                 Synced        Healthy\nopenshift-gitops   in-cluster-aimanager      Synced        Healthy\nopenshift-gitops   in-cluster-eventmanager   Synced        Healthy\nopenshift-gitops   in-cluster-rook-ceph      Synced        Healthy\n</code></pre> <p>Wait for a while and check if all pods under namespace <code>cp4waiops</code> and <code>noi</code> are up and running without any crash:</p> <pre><code>kubectl get pod -n cp4waiops\nkubectl get pod -n noi\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-34/#trouble-shooting","title":"Trouble Shooting","text":""},{"location":"how-to-deploy-cp4waiops-34/#storage","title":"Storage","text":"<ul> <li>ceph pod reporting <code>cephosd: failed to lookup binary path \"/rootfs/usr/sbin/lvm\" on the host rootfs</code> error.   Solution:   This is due to missing lvm2 support, refer to known issue 6705 here:    Simply install lvm2 on all nodes will solve the problem.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-35/","title":"How to deploy cp4waiops 35","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Deploy Cloud Pak for Watson AIOps 3.5 using GitOps<ul> <li>Prerequisites</li> <li>Installing Cloud Pak for Watson AIOps with the Argo CD UI<ul> <li>Log in to Argo CD</li> <li>Grant Argo CD cluster admin permission</li> <li>Configure Argo CD</li> <li>Storage considerations</li> <li>Obtain an entitlement key</li> <li>Update the OpenShift Container Platform global pull secret</li> <li>Option 1: Installing AI Manager and Event Manager separately<ul> <li>Install shared components</li> <li>Install AI Manager</li> <li>Install Event Manager</li> </ul> </li> <li>Option 2: (Technology preview) Installing AI Manager and Event Manager with an all-in-one configuration<ul> <li>Installing AI Manager and Event Manager together</li> <li>Installing Cloud Pak for Watson AIOps using a custom build</li> </ul> </li> <li>Verify the Cloud Pak for Watson AIOps installation</li> <li>Access Cloud Pak for Watson AIOps</li> </ul> </li> <li>Install Cloud Pak for Watson AIOps from the command line<ul> <li>Log in to Argo CD (CLI)</li> <li>Storage considerations (CLI)</li> <li>Option 1: Install AI Manager and Event Manager Separately (CLI)<ul> <li>Grant Argo CD cluster admin permission (CLI)</li> <li>Install shared components (CLI)</li> <li>Install AI Manager (CLI)</li> <li>Install Event Manager (CLI)</li> </ul> </li> <li>Option 2: (Technology preview) Installing AI Manager and Event Manager with an all-in-one configuration (CLI)</li> <li>Verify Cloud Pak for Watson AIOps installation (CLI)</li> </ul> </li> <li>Troubleshooting<ul> <li>Storage<ul> <li>Problem</li> <li>Cause</li> <li>Solution</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-35/#deploy-cloud-pak-for-watson-aiops-35-using-gitops","title":"Deploy Cloud Pak for Watson AIOps 3.5 using GitOps","text":"<p>Using GitOps to install Cloud Pak for Watson AIOps 3.5 is a GA feature!</p> <p>The use of GitOps enables IBM Cloud Pak for Watson AIOps to be deployed on a Red Hat OpenShift Container Platform cluster from a Git repository, with the ArgoCD tool.</p> <p>For more information about GitOps, see Understanding OpenShift GitOps in the Red Hat OpenShift documentation.</p> <p>For more information about Argo, see the Argo documentation.</p> <p>Cloud Pak for Watson AIOps can be installed with the Argo CD user interface (UI), or with the Argo CD command line (CLI). You can choose from two deployment options:</p> <p>Option 1: Install AI Manager and Event Manager separately</p> <p>Option 2: Install AI Manager and Event Manager with an all-in-one configuration (Technology preview)</p>"},{"location":"how-to-deploy-cp4waiops-35/#prerequisites","title":"Prerequisites","text":"<ul> <li>Ensure that you meet the supported platform, hardware, and storage requirements. For more information, see System requirements.</li> <li>You must have Red Hat OpenShift GitOps (Argo CD) installed on your Red Hat OpenShift cluster. For more information, see Installing OpenShift GitOps in the Red Hat OpenShift documentation.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-35/#installing-cloud-pak-for-watson-aiops-with-the-argo-cd-ui","title":"Installing Cloud Pak for Watson AIOps with the Argo CD UI","text":""},{"location":"how-to-deploy-cp4waiops-35/#log-in-to-argo-cd","title":"Log in to Argo CD","text":"<p>From your Red Hat OpenShift console, click the menu on the upper right, and select <code>Cluster Argo CD</code>.</p> <p></p> <p>The Argo CD UI is displayed. Click <code>LOG IN VIA OPENSHIFT</code>.</p> <p></p>"},{"location":"how-to-deploy-cp4waiops-35/#grant-argo-cd-cluster-admin-permission","title":"Grant Argo CD cluster admin permission","text":"<p>From the Red Hat OpenShift console, go to <code>User Management</code> &gt; <code>RoleBindings</code> &gt; <code>Create binding</code>. Use the form view to configure the properties for the <code>ClusterRoleBinding</code> with the following values and then click <code>Create</code>.</p> <ul> <li>Binding type<ul> <li>Cluster-wide role binding (ClusterRoleBinding)</li> </ul> </li> <li>RoleBinding<ul> <li>Name: argocd-admin</li> </ul> </li> <li>Role<ul> <li>Role Name: cluster-admin</li> </ul> </li> <li>Subject<ul> <li>ServiceAccount: check it</li> <li>Subject namespace: openshift-gitops</li> <li>Subject name: openshift-gitops-argocd-application-controller</li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-35/#configure-argo-cd","title":"Configure Argo CD","text":"<p>From the Argo CD UI, click <code>NEW APP</code>, input the following parameters, and then click <code>CREATE</code>.</p> <ul> <li>GENERAL<ul> <li>Application Name: argocd</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.5</li> <li>path: config/argocd/openshift</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: openshift-gitops</li> </ul> </li> </ul> <p>After the Argo CD App <code>argocd</code> is created, select the App from the Argo CD UI to view the topology of all of the resources.</p>"},{"location":"how-to-deploy-cp4waiops-35/#storage-considerations","title":"Storage considerations","text":"<p>If your Red Hat OpenShift cluster already has a default supported storage class, then skip this step.</p> <p>This tutorial uses Ceph storage for demonstration purpose. You must use a supported storage. For more information about supported storage, see Storage Considerations.</p> <p>If you are deploying on AWS, then EFS (Amazon Elastic File System) can be used for persistent storage. For more information, see Getting started with Amazon Elastic File System in the AWS documentation. You can also refer to the AWS EFS storage configuration example</p> <p>From the Argo CD UI, click <code>NEW APP</code>, input the following parameters for Ceph, and then click <code>CREATE</code>.</p> <ul> <li>GENERAL<ul> <li>Application Name: ceph</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.5</li> <li>path: config/ceph</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: rook-ceph</li> </ul> </li> </ul> <p></p> <p>After the Argo CD App <code>ceph</code> is created, you can click the App from the Argo CD UI to view the topology of the Ceph resources as follows:</p> <p></p> <p>The filters on the left can be used to filter out resources. Click a resource to check its logs and events.</p> <p></p> <p>Run the following command from the command line to check that none of the pods have an error status.</p> <pre><code>[root@xyz.test.cp.fyre.ibm.com ~]# kubectl get po -n rook-ceph\nNAME                                                              READY   STATUS      RESTARTS   AGE\ncsi-cephfsplugin-7b6jk                                            3/3     Running     0          2d\ncsi-cephfsplugin-l7mvz                                            3/3     Running     0          2d\ncsi-cephfsplugin-provisioner-695b574445-gfcwz                     6/6     Running     6          2d\ncsi-cephfsplugin-provisioner-695b574445-lb64p                     6/6     Running     7          2d\ncsi-cephfsplugin-qcsqz                                            3/3     Running     0          2d\ncsi-cephfsplugin-qdrtl                                            3/3     Running     0          2d\ncsi-cephfsplugin-wj7qq                                            3/3     Running     0          2d\ncsi-cephfsplugin-xlsnb                                            3/3     Running     0          2d\ncsi-rbdplugin-8xwdb                                               3/3     Running     0          2d\ncsi-rbdplugin-b6t9l                                               3/3     Running     0          2d\ncsi-rbdplugin-h965f                                               3/3     Running     0          2d\ncsi-rbdplugin-lv2hp                                               3/3     Running     0          2d\ncsi-rbdplugin-pqvrc                                               3/3     Running     0          2d\ncsi-rbdplugin-provisioner-7f9847cd48-48gqk                        6/6     Running     0          2d\ncsi-rbdplugin-provisioner-7f9847cd48-wxh2z                        6/6     Running     12         2d\ncsi-rbdplugin-x8cw9                                               3/3     Running     0          2d\nrook-ceph-crashcollector-worker0.body.cp.fyre.ibm.com-88f5bnbdc   1/1     Running     0          2d\nrook-ceph-crashcollector-worker1.body.cp.fyre.ibm.com-d4c7gdcts   1/1     Running     0          2d\nrook-ceph-crashcollector-worker2.body.cp.fyre.ibm.com-7767p8fxm   1/1     Running     0          2d\nrook-ceph-crashcollector-worker3.body.cp.fyre.ibm.com-6c5cqs4lk   1/1     Running     0          2d\nrook-ceph-crashcollector-worker4.body.cp.fyre.ibm.com-787f99czf   1/1     Running     0          2d\nrook-ceph-crashcollector-worker5.body.cp.fyre.ibm.com-94d4b654q   1/1     Running     0          2d\nrook-ceph-mds-myfs-a-7d48d48497-sbhld                             1/1     Running     0          2d\nrook-ceph-mds-myfs-b-66f4b746c7-2fnl2                             1/1     Running     0          2d\nrook-ceph-mgr-a-5c84cd7b7b-574lf                                  1/1     Running     0          2d\nrook-ceph-mon-a-7b947ddf45-74p49                                  1/1     Running     0          2d\nrook-ceph-mon-b-7cf885c589-5j6r9                                  1/1     Running     0          2d\nrook-ceph-mon-c-bcb6575d8-g9l5w                                   1/1     Running     0          2d\nrook-ceph-operator-54649856c4-cdx24                               1/1     Running     0          2d\nrook-ceph-osd-0-c44985597-gwkqk                                   1/1     Running     0          2d\nrook-ceph-osd-1-6f7d5cc955-v4862                                  1/1     Running     0          2d\nrook-ceph-osd-2-58df99c46f-5kl8z                                  1/1     Running     0          2d\nrook-ceph-osd-3-5c8579456c-bpcqz                                  1/1     Running     0          2d\nrook-ceph-osd-4-5668c69fbf-kvdf6                                  1/1     Running     0          2d\nrook-ceph-osd-5-cbbdb95-cqvjd                                     1/1     Running     0          2d\nrook-ceph-osd-prepare-worker0.body.cp.fyre.ibm.com-bxr7t          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker1.body.cp.fyre.ibm.com-fftd8          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker2.body.cp.fyre.ibm.com-scg84          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker3.body.cp.fyre.ibm.com-m488b          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker4.body.cp.fyre.ibm.com-dxcm5          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker5.body.cp.fyre.ibm.com-jclnq          0/1     Completed   0          4h16m\n</code></pre> <p>If any of the pods are in an error state, you can check the logs by using <code>kubectl logs</code>.</p> <p>NOTE: Multiple default storage classes cause deployment problems. Run the following command to check your cluster's storage class.</p> <pre><code>oc get sc\n</code></pre> <p>If your cluster has multiple default storage classes, then you must edit your storage classes to leave only one storage class as the default. To remove the default setting from a storage class, run the following command to edit the storage class, and then delete the <code>storageclass.kubernetes.io/is-default-class: \"true\"</code> line under <code>annotations</code>.</p> <pre><code>oc edit sc [STORAGE-CLASS-NAME]\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-35/#obtain-an-entitlement-key","title":"Obtain an entitlement key","text":"<p>Obtain your IBM Entitled Registry key to enable your deployment to pull images from the IBM Entitled Registry.</p> <ol> <li> <p>Obtain the entitlement key that is assigned to your IBMid. Log in to MyIBM Container Software Library with the IBMid and password details that are associated with the entitled software.</p> </li> <li> <p>In the \"Entitlement key\" section, select \"Copy key\" to copy the entitlement key to the clipboard.</p> </li> <li> <p>Copy the entitlement key to a safe place so that you can use it later when you update the global pull secret for the cluster.</p> </li> <li> <p>(Optional) Verify the validity of the key by logging in to the IBM Entitled Registry.</p> </li> </ol> <p>Depending on the container system that you are using, you might need to use <code>docker login</code> instead of <code>podman login</code> for the following command.</p> <pre><code>export IBM_ENTITLEMENT_KEY=the key from the previous steps\npodman login cp.icr.io --username cp --password \"${IBM_ENTITLEMENT_KEY:?}\"\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-35/#update-the-openshift-container-platform-global-pull-secret","title":"Update the OpenShift Container Platform global pull secret","text":"<ol> <li> <p>From the Red Hat OpenShift console, select the \"Administrator\" perspective, and then \"Workloads &gt; Secrets\".</p> </li> <li> <p>Select the project \"openshift-config\".(for latest version ocp, the <code>Show default projects</code> switch under <code>Project:</code> need to be enabled before selecting project.)</p> </li> <li> <p>Select the object \"pull-secret\".</p> </li> <li> <p>Click \"Actions &gt; Edit secret\".</p> </li> <li> <p>Scroll to the end of the page and click \"Add credentials\". Use the following values:</p> <ul> <li>\"Registry Server Address\" cp.icr.io</li> <li>\"Username\": cp</li> <li>\"Password\": paste the entitlement key that you copied from the Obtain an entitlement key step</li> <li>\"Email\": email address. This field is mostly a hint to other people who might see the entry in the configuration.</li> </ul> </li> </ol> <p>NOTE: The registry user for this secret is \"cp\", not the name or email of the user who owns the entitlement key.</p> <ol> <li>Click \"Save\".</li> </ol> <p>For more information, see Update the OpenShift Container Platform global pull secret in the Red Hat OpenShift documentation.</p>"},{"location":"how-to-deploy-cp4waiops-35/#option-1-installing-ai-manager-and-event-manager-separately","title":"Option 1: Installing AI Manager and Event Manager separately","text":""},{"location":"how-to-deploy-cp4waiops-35/#install-shared-components","title":"Install shared components","text":"<ul> <li>GENERAL<ul> <li>Application Name: anyname (for example: \"cp-shared\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.5</li> <li>path: config/cp-shared/operators</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: openshift-marketplace</li> </ul> </li> <li>PARAMETERS<ul> <li>spec.imageCatalog: icr.io/cpopen/ibm-operator-catalog:latest</li> <li>spec.catalogName: ibm-operator-catalog</li> <li>spec.catalogNamespace: openshift-marketplace</li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-35/#install-ai-manager","title":"Install AI Manager","text":"<p>Install AI Manager by using GitOps to create an Argo CD App for AI Manager. The parameters for AI Manager are as follows:</p> <ul> <li>GENERAL<ul> <li>Application Name: anyname (for example: \"aimanager-app\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.5</li> <li>path: config/cp4waiops/install-aimgr</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: cp4waiops</li> </ul> </li> <li>PARAMETERS<ul> <li>spec.storageClass: rook-cephfs  (need to update the storage class to what is being used in your environment, check it with <code>oc get sc</code> command.)</li> <li>spec.storageClassLargeBlock: rook-cephfs  (need to update the storage class to what is being used in your environment, check it with <code>oc get sc</code> command.)</li> <li>spec.aiManager.channel: v3.5</li> <li>spec.aiManager.size: small</li> <li>spec.aiManager.namespace: cp4waiops</li> <li>spec.aiManager.pakModules.aiopsFoundation.enabled: true</li> <li>spec.aiManager.pakModules.applicationManager.enabled: true</li> <li>spec.aiManager.pakModules.aiManager.enabled: true</li> <li>spec.aiManager.pakModules.connection.enabled: true</li> </ul> </li> </ul> <p>NOTE: If you use a repository that is forked from the official Cloud Pak for Watson AIOps GitOps repository or a different branch, then you must update the values of the <code>Repository URL</code> and <code>Revision</code> parameters to match your repository and branch. For example, if you use <code>https://github.com/&lt;myaccount&gt;/cp4waiops-gitops</code> and <code>dev</code> branch, then these two parameters must be changed.</p>"},{"location":"how-to-deploy-cp4waiops-35/#install-event-manager","title":"Install Event Manager","text":"<p>Install Event Manager by using GitOps to create an Argo CD App for Event Manager. The parameters for Event Manager are as follows:</p> <ul> <li>GENERAL<ul> <li>Application Name: anyname (for example: \"eventmanager-app\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.5</li> <li>path: config/cp4waiops/install-emgr</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: noi </li> </ul> </li> <li>PARAMETERS<ul> <li>spec.imageCatalog: icr.io/cpopen/ibm-operator-catalog:latest</li> <li>spec.storageClass: rook-cephfs  (need to update the storage class to what is being used in your environment, check it with <code>oc get sc</code> command.)</li> <li>spec.storageClassLargeBlock: rook-cephfs  (need to update the storage class to what is being used in your environment, check it with <code>oc get sc</code> command.)</li> <li>spec.eventManager.version: 1.6.6</li> <li>spec.eventManager.clusterDomain: REPLACE_IT</li> <li>spec.eventManager.channel: v1.10</li> <li>spec.eventManager.deploymentType: trial</li> <li>spec.eventManager.namespace: noi</li> </ul> </li> </ul> <p>NOTE: - If you use a repository that is forked from the official Cloud Pak for Watson AIOps GitOps repository or a different branch, then you must update the values of the <code>Repository URL</code> and <code>Revision</code> parameters to match your repository and branch. For example, if you use <code>https://github.com/&lt;myaccount&gt;/cp4waiops-gitops</code> and <code>dev</code> branch, then these two parameters must be changed. - <code>spec.eventManager.clusterDomain</code> is the domain name of the cluster where Event Manager is installed. You must use a fully qualified domain name (FQDN). For example, <code>apps.clustername.abc.xyz.com</code>. You can retrieve the FQDN by running the following command:</p> <pre><code>INGRESS_OPERATOR_NAMESPACE=openshift-ingress-operator\nappDomain=`kubectl -n ${INGRESS_OPERATOR_NAMESPACE} get ingresscontrollers default -o json | python -c \"import json,sys;obj=json.load(sys.stdin);print obj['status']['domain'];\"`\necho ${appDomain}\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-35/#option-2-technology-preview-installing-ai-manager-and-event-manager-with-an-all-in-one-configuration","title":"Option 2: (Technology preview) Installing AI Manager and Event Manager with an all-in-one configuration","text":"<p>NOTE: This option is a technology preview, and must not be used for production systems.</p>"},{"location":"how-to-deploy-cp4waiops-35/#installing-ai-manager-and-event-manager-together","title":"Installing AI Manager and Event Manager together","text":"<p>The all-in-one configuration enables the installation of the following components in one go.</p> <ul> <li>Ceph storage (optional)</li> <li>AI Manager</li> <li>Event Manager</li> </ul> <p>When you create the Argo CD app, complete the form with the following values.</p> Field Value Application Name anyname (for example cp4waiops-app) Project default Sync Policy Automatic Repository URL https://github.com/IBM/cp4waiops-gitops Revision release-3.5 Path config/all-in-one Cluster URL https://kubernetes.default.svc Namespace openshift-gitops <p>You can also update the following parameters to customize the installation.</p> Parameter Type Default Value Description argocd.cluster string openshift The type of the cluster that Argo CD runs on, valid values include: openshift, kubernetes. argocd.allowLocalDeploy bool true Allow apps to be deployed on the same cluster where Argo CD runs. rookceph.enabled bool true Specify whether to install Ceph as storage used by Cloud Pak for Watson AIOps. cp4waiops.version string v3.5 Specify the version of Cloud Pak for Watson AIOps v3.5. cp4waiops.profile string small The Cloud Pak for Watson AIOps deployment profile: x-small, small, or large. cp4waiops.aiManager.enabled bool true Specify whether to install AI Manager. cp4waiops.aiManager.namespace string cp4waiops The namespace where AI Manager is installed. cp4waiops.aiManager.instanceName string aiops-installation The instance name of AI Manager. cp4waiops.eventManager.enabled bool true Specify whether to install Event Manager. cp4waiops.eventManager.namespace string noi The namespace where Event Manager is installed. cp4waiops.eventManager.clusterDomain string REPLACE_IT The domain name of the cluster where Event Manager is installed. <p>NOTE:</p> <ul> <li><code>cp4waiops.profile</code> The profile <code>x-small</code> is only suitable for demonstrations and proof-of-concept deployments. Production environments must use a <code>small</code> or <code>large</code> profile.</li> <li><code>cp4waiops.eventManager.enabled</code> This must be false if you have a value of <code>x-small</code> for <code>cp4waiops.profile</code>, as this profile size is only suitable for deployments of AI Manager, and not for deployments of AI Manager and Event Manager.</li> <li><code>cp4waiops.eventManager.clusterDomain</code> This is the domain name of the cluster where Event Manager is installed. Use a fully qualified domain name (FQDN). For example, <code>apps.clustername.abc.xyz.com</code>.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-35/#installing-cloud-pak-for-watson-aiops-using-a-custom-build","title":"Installing Cloud Pak for Watson AIOps using a custom build","text":"<p>The all-in-one configuration enables a custom build of Cloud Pak for Watson AIOps to be installed by providing a specific image catalog and channel.</p> <p>Use the installation parameters listed in following table when you create the Argo CD App.</p> Parameter Type Default Value Description cp4waiops.aiManager.imageCatalog string icr.io/cpopen/ibm-operator-catalog:latest The image catalog for AI Manager. cp4waiops.aiManager.channel string v3.5 The subscription channel for AI Manager. cp4waiops.eventManager.imageCatalog string icr.io/cpopen/ibm-operator-catalog:latest The image catalog for Event Manager. cp4waiops.eventManager.channel string v1.10 The subscription channel for Event Manager. <p>These parameters are invisible when you create the Argo CD App from the UI, but you can add them in the <code>HELM</code> &gt; <code>VALUES</code> field when you are completing the form.</p> <p>For example, adding the following YAML snippet to the <code>HELM</code> &gt; <code>VALUES</code> field installs AI Manager and Event Manager with a custom <code>imageCatalog</code> and <code>channel</code>:</p> <pre><code>cp4waiops:\naiManager:\nimageCatalog: &lt;my_custom_image_catalog_for_ai_manager&gt;\nchannel: &lt;my_custom_channel_for_ai_manager&gt;\neventManager:\nimageCatalog: &lt;my_custom_image_catalog_for_event_manager&gt;\nchannel: &lt;my_custom_channel_for_event_manager&gt;\n</code></pre> <p>The all-in-one configuration also exposes some more installation parameters that are not visible from the UI that enable further customization of the installation. The following table lists some of these parameters. To find out more about the usage of these parameters, see Cloud Pak for Watson AIOps Customized Install Options Using GitOps.</p> Parameter Type Default Value Description cp4waiops.storageClass string rook-cephfs The storage class for Cloud Pak for Watson AIOps to use. cp4waiops.storageClassLargeBlock string rook-cephfs The storage class for large block for Cloud Pak for Watson AIOps to use. cp4waiops.eventManager.version string 1.6.6 The version of Event Manager. cp4waiops.eventManager.deploymentType string trial The deployment type of Event Manager, valid values include: trial, production. globalImagePullSecrets array n/a A list of registry secrets that are needed for pulling images during the installation. <p>For example, if the custom build to be installed includes images from registries other than the official IBM Entitled Registry, you can use <code>globalImagePullSecrets</code> to specify all the necessary information to access these registries, such as registry URL, username, and password.</p> <p>These parameters are invisible when you create the Argo CD App from the UI, but you can add them in the <code>HELM</code> &gt; <code>VALUES</code> field when you are completing the form. For example,</p> <pre><code>globalImagePullSecrets:\n- registry: &lt;my_own_registry_1&gt;\nusername: &lt;username_to_registry_1&gt;\npassword: &lt;password_to_registry_1&gt;\n- registry: &lt;my_own_registry_2&gt;\nusername: &lt;username_to_registry_2&gt;\npassword: &lt;password_to_registry_2&gt;\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-35/#verify-the-cloud-pak-for-watson-aiops-installation","title":"Verify the Cloud Pak for Watson AIOps installation","text":"<p>When Ceph and Cloud Pak for Watson AIOps are ready, you can see these Apps with a status of <code>Healthy</code> and <code>Synced</code> in the Argo CD UI.</p> <p></p> <p></p> <p>You can check the topology of Cloud Pak for Watson AIOps from the Argo CD UI as follows:</p> <p></p> <p></p> <p>You can also check your Cloud Pak for Watson AIOps installation from the command line. For example, to check the AI Manager pods, run the following command:</p> <pre><code>[root@api.body.cp.fyre.ibm.com ~]# kubectl get po -n cp4waiops\nNAME                                                              READY   STATUS      RESTARTS   AGE\naimanager-aio-ai-platform-api-server-7c877989d6-7jh55             1/1     Running     0          47h\naimanager-aio-change-risk-654884bd8c-6xpxw                        1/1     Running     0          47h\naimanager-aio-chatops-orchestrator-7c54fc5664-rtmrp               1/1     Running     0          47h\naimanager-aio-chatops-slack-integrator-77fc9499c4-wtclt           1/1     Running     0          47h\naimanager-aio-chatops-teams-integrator-577f6b85bf-j2995           1/1     Running     0          47h\naimanager-aio-controller-86875d4b7-jfwwp                          1/1     Running     0          47h\naimanager-aio-create-secrets-ccjdg                                0/1     Completed   0          47h\naimanager-aio-create-truststore-5hxps                             0/1     Completed   0          47h\naimanager-aio-curator-job-27362220-k59t8                          0/1     Completed   0          142m\naimanager-aio-curator-job-27362280-n2w88                          0/1     Completed   0          82m\naimanager-aio-curator-job-27362340-qkwln                          0/1     Completed   0          22m\naimanager-aio-log-anomaly-detector-fdfcbb96b-rpb9q                1/1     Running     0          47h\naimanager-aio-log-anomaly-detector-fdfcbb96b-v426m                1/1     Running     0          47h\naimanager-aio-similar-incidents-service-77cc9d699f-qlxgg          1/1     Running     0          47h\naimanager-ibm-minio-0                                             1/1     Running     0          47h\naimanager-operator-585d799f9f-w22vz                               1/1     Running     0          47h\naiops-ai-model-ui-674b4f77f9-qv56n                                1/1     Running     0          47h\naiops-akora-ui-7bc6d5dd6b-6n9rs                                   1/1     Running     0          47h\naiops-application-details-ui-66779f957b-fqfhk                     1/1     Running     0          47h\naiops-base-ui-5b9f885888-pvm7z                                    1/1     Running     0          47h\naiops-connections-ui-7996699c55-m79fl                             1/1     Running     0          47h\naiops-ir-analytics-classifier-75869fd78b-p2s9v                    1/1     Running     0          47h\naiops-ir-analytics-probablecause-6dd5ffd867-rrg6b                 1/1     Running     2          47h\naiops-ir-analytics-spark-master-5cd57946d4-99bqt                  1/1     Running     0          47h\naiops-ir-analytics-spark-pipeline-composer-795f965b6d-vkjqw       1/1     Running     0          47h\naiops-ir-analytics-spark-worker-65d57f7f9c-4nsb8                  1/1     Running     0          47h\naiops-ir-core-archiving-754dcb5fcb-jm82z                          1/1     Running     0          47h\naiops-ir-core-archiving-setup-rrlkh                               0/1     Completed   0          47h\naiops-ir-core-cem-users-65b9b699b9-hzh9b                          1/1     Running     0          47h\naiops-ir-core-esarchiving-67dbb7c5d7-wg7dx                        1/1     Running     0          47h\naiops-ir-core-logstash-6c89d66f79-tlfcl                           1/1     Running     0          47h\naiops-ir-core-ncobackup-0                                         2/2     Running     0          47h\naiops-ir-core-ncodl-api-59f977b475-lx7n4                          1/1     Running     0          47h\naiops-ir-core-ncodl-if-66cf44c565-lkkgx                           1/1     Running     0          47h\naiops-ir-core-ncodl-ir-7469fd4866-wjfvf                           1/1     Running     0          47h\naiops-ir-core-ncodl-jobmgr-76d74b5567-t77wc                       1/1     Running     0          47h\naiops-ir-core-ncodl-setup-8hx6c                                   0/1     Completed   0          47h\naiops-ir-core-ncodl-std-7677546c8d-dbqm9                          1/1     Running     0          47h\naiops-ir-core-ncodl-std-7677546c8d-wf82d                          1/1     Running     0          47h\naiops-ir-core-ncoprimary-0                                        1/1     Running     0          47h\naiops-ir-lifecycle-create-policies-job-dljxp                      0/1     Completed   0          47h\naiops-ir-lifecycle-eventprocessor-ep-jobmanager-0                 2/2     Running     0          47h\naiops-ir-lifecycle-eventprocessor-ep-taskmanager-0                1/1     Running     0          47h\naiops-ir-lifecycle-logstash-77579f5d7f-9rhsx                      1/1     Running     0          47h\naiops-ir-lifecycle-policy-grpc-svc-6b59698569-cvhvq               1/1     Running     0          47h\naiops-ir-lifecycle-policy-registry-svc-68647d4cdc-t27mw           1/1     Running     0          47h\naiops-ir-lifecycle-policy-registry-svc-job-8gk89                  0/1     Completed   3          47h\naiops-ir-ui-api-graphql-68488c7675-87mbp                          1/1     Running     0          47h\naiops-topology-cassandra-0                                        1/1     Running     0          47h\naiops-topology-cassandra-auth-secret-generator-7mm84              0/1     Completed   0          47h\naiops-topology-file-observer-5757769dd5-xxc8j                     1/1     Running     0          47h\naiops-topology-kubernetes-observer-d4c8bcb55-ddbcg                1/1     Running     0          47h\naiops-topology-layout-6b957b5bbb-m28rd                            1/1     Running     0          47h\naiops-topology-merge-76c494795f-5b65g                             1/1     Running     0          47h\naiops-topology-observer-service-6f5d6fb44b-jswwp                  1/1     Running     0          47h\naiops-topology-rest-observer-799bfdf4c8-5nt6n                     1/1     Running     0          47h\naiops-topology-search-6cd7cc9d8-64bdk                             1/1     Running     0          47h\naiops-topology-secret-manager-2b84s                               0/1     Completed   0          47h\naiops-topology-servicenow-observer-84c588df5b-gm6p2               1/1     Running     0          47h\naiops-topology-status-58ddcdc845-mqpzg                            1/1     Running     0          47h\naiops-topology-topology-577b988f78-kc2m6                          1/1     Running     2          47h\naiops-topology-ui-api-bbd74965d-gzlfd                             1/1     Running     0          47h\naiops-topology-vmvcenter-observer-86b6c8dc44-krvtj                1/1     Running     0          47h\naiopsedge-github-topology-integrator-7b9db59cd8-nbdgz             1/1     Running     0          47h\naiopsedge-operator-controller-manager-9b68ddd75-5rqqz             1/1     Running     1          47h\naiopsedge-operator-controller-manager-9b68ddd75-xj7tq             1/1     Running     1          47h\nasm-operator-548c8894fd-r2dgv                                     1/1     Running     0          47h\nc-example-couchdbcluster-m-0                                      3/3     Running     0          47h\nc-example-redis-m-0                                               4/4     Running     0          47h\nc-example-redis-m-1                                               4/4     Running     0          47h\nc-example-redis-m-2                                               4/4     Running     0          47h\nc-example-redis-s-0                                               4/4     Running     0          47h\nc-example-redis-s-1                                               4/4     Running     0          47h\nc-example-redis-s-2                                               4/4     Running     0          47h\ncamel-k-kit-c7c60rolvegv49tvh8fg-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60sglvegv49tvh8g0-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60tglvegv49tvh8gg-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60tolvegv49tvh8h0-1-build                          0/1     Completed   0          47h\ncamel-k-operator-684f46fc4d-s6hf2                                 1/1     Running     0          47h\nconfigure-aiops-network-policy-967ll                              0/1     Completed   0          47h\nconnector-controller-bc7fc6668-f8nn5                              1/1     Running     0          47h\nconnector-synchronizer-7d4546ddd4-5kbrl                           1/1     Running     0          47h\ncouchdb-operator-d5cb7ff8c-rjnhx                                  1/1     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-jobmanager-0                 2/2     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-jobmanager-1                 2/2     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-taskmanager-0                1/1     Running     1          47h\ncp4waiops-eventprocessor-eve-29ee-ep-taskmanager-1                1/1     Running     0          47h\ncp4waiops-image-pull-secret-6fprf                                 0/1     Completed   0          2d\ncp4waiops-patch-j4qrm                                             0/1     Completed   0          2d\ncp4waiops-postgres-keeper-0                                       1/1     Running     0          47h\ncp4waiops-postgres-postgresql-create-cluster-7xb6t                0/1     Completed   0          47h\ncp4waiops-postgres-proxy-648bc64fd-x4mvv                          1/1     Running     0          47h\ncp4waiops-postgres-sentinel-5878f67f46-gvv7l                      1/1     Running     0          47h\ncp4waiops-postgresdb-postgresql-create-database-9j6kq             0/1     Completed   0          47h\ncreate-secrets-job-nx6dg                                          0/1     Completed   0          47h\ngateway-kong-5d45b77fb4-tgjcv                                     2/2     Running     2          47h\ngateway-kong-config-svc-27362360-9dmzc                            0/1     Completed   0          2m51s\niaf-core-operator-controller-manager-58dfd97f5c-bdd9t             1/1     Running     0          2d\niaf-eventprocessing-operator-controller-manager-5bc597797f6fxm4   1/1     Running     1          2d\niaf-flink-operator-controller-manager-7dc56c9b68-6rgtk            1/1     Running     0          2d\niaf-operator-controller-manager-6bc8f44ff7-rrrnx                  1/1     Running     0          2d\niaf-system-elasticsearch-es-aiops-0                               2/2     Running     0          47h\niaf-system-entity-operator-6b5444f575-7tdfw                       3/3     Running     0          47h\niaf-system-kafka-0                                                1/1     Running     0          47h\niaf-system-zookeeper-0                                            1/1     Running     0          47h\niaf-zen-tour-job-fhdfr                                            0/1     Completed   0          47h\niam-config-job-tfsst                                              0/1     Completed   0          47h\nibm-aiops-orchestrator-6c7cfc85b7-wqdnr                           1/1     Running     0          2d\nibm-cloud-databases-redis-operator-854cf65c4f-4rrvn               1/1     Running     0          47h\nibm-common-service-operator-5cd6947dc8-z8plb                      1/1     Running     0          2d\nibm-elastic-operator-controller-manager-5d6c467b55-wtrvg          1/1     Running     0          2d\nibm-ir-ai-operator-controller-manager-59b88c6bf6-ncnbt            1/1     Running     7          47h\nibm-kong-operator-6ff97bcdb9-rl7cp                                1/1     Running     0          47h\nibm-nginx-cd84b4d8-7ttn2                                          1/1     Running     0          47h\nibm-nginx-cd84b4d8-zp4t2                                          1/1     Running     0          47h\nibm-postgreservice-operator-controller-manager-8b7bdf589-hbg2g    1/1     Running     2          47h\nibm-secure-tunnel-operator-657dd7b78f-tsgws                       1/1     Running     0          47h\nibm-vault-deploy-consul-0                                         1/1     Running     0          47h\nibm-vault-deploy-vault-0                                          1/1     Running     0          47h\nibm-vault-deploy-vault-cron-job-27361440-qxpjl                    0/1     Completed   0          15h\nibm-vault-deploy-vault-injector-596567d459-wzkws                  1/1     Running     0          47h\nibm-vault-operator-controller-manager-5957bb5ff9-4zdrb            1/1     Running     0          47h\nibm-watson-aiops-ui-operator-controller-manager-b8cf6fff7-msspt   1/1     Running     0          47h\nir-core-operator-controller-manager-76dbdb699d-g97ng              1/1     Running     7          47h\nir-lifecycle-operator-controller-manager-64bdd8f7b6-pn46g         1/1     Running     9          47h\nmodel-train-classic-operator-56d487585c-4dv5b                     1/1     Running     2          47h\nmodeltrain-ibm-modeltrain-lcm-865b7f85cc-jfq4z                    1/1     Running     0          47h\nmodeltrain-ibm-modeltrain-ratelimiter-595f4f478-r9dwp             1/1     Running     0          47h\nmodeltrain-ibm-modeltrain-trainer-5b7f7888b5-c8cz5                1/1     Running     0          47h\npost-aiops-resources-t4ww9                                        0/1     Completed   0          47h\npost-aiops-translations-t58bb                                     0/1     Completed   0          47h\npost-aiops-update-user-role-kcr8k                                 0/1     Completed   0          47h\nscm-handlers-d655679fc-lvls2                                      2/2     Running     0          47h\nsetup-nginx-job-tn8sc                                             0/1     Completed   0          47h\nsnow-handlers-d8488f6f8-8lhxh                                     2/2     Running     0          47h\nsre-tunnel-controller-84565ff4f8-4qtwl                            1/1     Running     0          47h\nsre-tunnel-tunnel-network-api-589fd6646d-7znnh                    1/1     Running     0          47h\nsre-tunnel-tunnel-ui-mcmtunnelui-fff9b859b-g7dlk                  1/1     Running     0          47h\nusermgmt-5fb7986c7b-dwmk2                                         1/1     Running     0          47h\nusermgmt-5fb7986c7b-ssk86                                         1/1     Running     0          47h\nzen-audit-678b54b548-n7q7f                                        1/1     Running     0          47h\nzen-core-64c6d56db-d25zm                                          1/1     Running     0          47h\nzen-core-64c6d56db-glv65                                          1/1     Running     1          47h\nzen-core-api-85489478d6-95pck                                     1/1     Running     0          47h\nzen-core-api-85489478d6-n9x5s                                     1/1     Running     0          47h\nzen-metastoredb-0                                                 1/1     Running     0          47h\nzen-metastoredb-1                                                 1/1     Running     0          47h\nzen-metastoredb-2                                                 1/1     Running     0          47h\nzen-metastoredb-certs-lblhv                                       0/1     Completed   0          47h\nzen-metastoredb-init-hvlv2                                        0/1     Completed   0          47h\nzen-post-requisite-job-lpkfw                                      0/1     Completed   0          47h\nzen-pre-requisite-job-2klrt                                       0/1     Completed   0          47h\nzen-watcher-d8b795b46-2q6zx                                       1/1     Running     0          47h\n</code></pre> <p>If any pods are in an error state, you can check the logs from the Argo CD UI, or you can run <code>kubectl logs</code> from the command line.</p>"},{"location":"how-to-deploy-cp4waiops-35/#access-cloud-pak-for-watson-aiops","title":"Access Cloud Pak for Watson AIOps","text":"<p>If all of the pods for Cloud Pak for Watson AIOps are up and running, then you can log in to Cloud Pak for Watson AIOps UI as follows.</p> <p>Log in to Red Hat OpenShift console, and then click the drop-down menu on the upper right.</p> <p></p> <p>Click the link to <code>IBM Cloud Pak for Administration</code> and select <code>OpenShift authentication</code>.</p> <p></p> <p>Log in to <code>IBM Cloud Pak for Administration</code>, click the drop-down menu on the upper right, and then select <code>IBM Automation (cp4waiops)</code>.</p> <p></p> <p>Log in to the Cloud Pak for Watson AIOps UI and then select <code>OpenShift authentication</code>.</p> <p></p> <p>The Cloud Pak for Watson AIOps user interface is displayed.</p> <p></p> <p>Congratulations! You are ready to play with Cloud Pak for Watson AIOps!</p>"},{"location":"how-to-deploy-cp4waiops-35/#install-cloud-pak-for-watson-aiops-from-the-command-line","title":"Install Cloud Pak for Watson AIOps from the command line","text":""},{"location":"how-to-deploy-cp4waiops-35/#log-in-to-argo-cd-cli","title":"Log in to Argo CD (CLI)","text":"<p>Make sure that the Argo CD CLI (<code>argocd</code> command) is installed. For more information, see the Argo documentation.</p> <p>Then run following commands to log in to Argo CD:</p> <pre><code>argo_route=openshift-gitops-server\nargo_secret=openshift-gitops-cluster\nsa_account=openshift-gitops-argocd-application-controller\n\nargo_pwd=$(kubectl get secret ${argo_secret} \\\n-n openshift-gitops \\\n-o jsonpath='{.data.admin\\.password}' | base64 -d ; echo ) \\\n&amp;&amp; argo_url=$(kubectl get route ${argo_route} \\\n-n openshift-gitops \\\n-o jsonpath='{.spec.host}') \\\n&amp;&amp; argocd login \"${argo_url}\" \\\n--username admin \\\n--password \"${argo_pwd}\" \\\n--insecure\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-35/#storage-considerations-cli","title":"Storage considerations (CLI)","text":"<p>If your Red Hat OpenShift cluster already has a default supported storage class, then skip this step.</p> <p>This tutorial uses Ceph storage for demonstration purpose. You must use a supported storage. For more information about supported storage, see Storage Considerations.</p> <p>To create an Argo CD App for Ceph storage, run the following command:</p> <pre><code>argocd app create ceph \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/ceph \\\n--revision release-3.5 \\\n--dest-namespace rook-ceph \\\n--dest-server https://kubernetes.default.svc\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-35/#option-1-install-ai-manager-and-event-manager-separately-cli","title":"Option 1: Install AI Manager and Event Manager Separately (CLI)","text":""},{"location":"how-to-deploy-cp4waiops-35/#grant-argo-cd-cluster-admin-permission-cli","title":"Grant Argo CD cluster admin permission (CLI)","text":"<p>Apply the following YAML manifest to the cluster where Argo CD runs:</p> <pre><code>kind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\nname: argocd-admin\nsubjects:\n- kind: ServiceAccount\nname: openshift-gitops-argocd-application-controller\nnamespace: openshift-gitops\nroleRef:\napiGroup: rbac.authorization.k8s.io\nkind: ClusterRole\nname: cluster-admin\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-35/#install-shared-components-cli","title":"Install shared components (CLI)","text":"<pre><code>argocd app create cp-shared \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/cp-shared/operators \\\n--revision release-3.5 \\\n--dest-namespace openshift-marketplace \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.imageCatalog=icr.io/cpopen/ibm-operator-catalog:latest \\\n--helm-set spec.catalogName=ibm-operator-catalog \\\n--helm-set spec.catalogNamespace=openshift-marketplace\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-35/#install-ai-manager-cli","title":"Install AI Manager (CLI)","text":"<p>Run the following command to install AI Manager by using GitOps to create an Argo CD App for AI Manager.</p> <pre><code>argocd app create aimanager-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/cp4waiops/install-aimgr \\\n--revision release-3.5 \\\n--dest-namespace cp4waiops \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.storageClass=rook-cephfs \\\n--helm-set spec.storageClassLargeBlock=rook-cephfs \\\n--helm-set spec.aiManager.namespace=cp4waiops \\\n--helm-set spec.aiManager.channel=v3.5 \\\n--helm-set spec.aiManager.size=small \\\n--helm-set spec.aiManager.pakModules.aiopsFoundation.enabled=true \\\n--helm-set spec.aiManager.pakModules.applicationManager.enabled=true \\\n--helm-set spec.aiManager.pakModules.aiManager.enabled=true \\\n--helm-set spec.aiManager.pakModules.connection.enabled=true\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-35/#install-event-manager-cli","title":"Install Event Manager (CLI)","text":"<p>Run the following command to install Event Manager by using GitOps to create an Argo CD App for Event Manager.</p> <pre><code>argocd app create eventmanager-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/cp4waiops/install-emgr \\\n--revision release-3.5 \\\n--dest-namespace noi \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.imageCatalog=icr.io/cpopen/ibm-operator-catalog:latest \\\n--helm-set spec.storageClass=rook-cephfs \\\n--helm-set spec.storageClassLargeBlock=rook-cephfs \\\n--helm-set spec.eventManager.namespace=noi \\\n--helm-set spec.eventManager.channel=v1.10 \\\n--helm-set spec.eventManager.version=1.6.6 \\\n--helm-set spec.eventManager.clusterDomain=REPLACE_IT \\\n--helm-set spec.eventManager.deploymentType=trial\n</code></pre> <p>NOTE:  - <code>cp4waiops.eventManager.clusterDomain</code> is the domain name of the cluster where Event Manager is installed. Use a fully qualified domain name (FQDN). For example, <code>apps.clustername.abc.xyz.com</code>. You can also retrieve the FDQN by running the following command:</p> <pre><code>INGRESS_OPERATOR_NAMESPACE=openshift-ingress-operator\nappDomain=`kubectl -n ${INGRESS_OPERATOR_NAMESPACE} get ingresscontrollers default -o json | python -c \"import json,sys;obj=json.load(sys.stdin);print obj['status']['domain'];\"`\necho ${appDomain}\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-35/#option-2-technology-preview-installing-ai-manager-and-event-manager-with-an-all-in-one-configuration-cli","title":"Option 2: (Technology preview) Installing AI Manager and Event Manager with an all-in-one configuration (CLI)","text":"<p>NOTE: This option is a technology preview, and must not be used for production systems.</p> <p>To install Ceph, AI Manager, and Event Manager in one go with an all-in-one configuration, run the following command.</p> <p><pre><code>argocd app create cp4waiops-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/all-in-one \\\n--revision release-3.5 \\\n--dest-namespace openshift-gitops \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set argocd.cluster=openshift \\\n--helm-set argocd.allowLocalDeploy=true \\\n--helm-set rookceph.enabled=true \\\n--helm-set cp4waiops.version=v3.5 \\\n--helm-set cp4waiops.profile=small \\\n--helm-set cp4waiops.aiManager.enabled=true \\\n--helm-set cp4waiops.aiManager.namespace=cp4waiops \\\n--helm-set cp4waiops.aiManager.instanceName=aiops-installation \\\n--helm-set cp4waiops.eventManager.enabled=true \\\n--helm-set cp4waiops.eventManager.clusterDomain=REPLACE_IT \\\n--helm-set cp4waiops.eventManager.namespace=noi\n</code></pre> NOTE:</p> <ul> <li><code>cp4waiops.profile</code> The profile <code>x-small</code> is only suitable for demonstrations and proof-of-concept deployments. Production environments must use a <code>small</code> or <code>large</code> profile.</li> <li><code>cp4waiops.eventManager.enabled</code> This must be false if you have a value of <code>x-small</code> for <code>cp4waiops.profile</code>, as this profile size is only suitable for deployments of AI Manager, and not for deployments of AI Manager and Event Manager.</li> <li><code>cp4waiops.eventManager.clusterDomain</code> This is the domain name of the cluster where Event Manager is installed. Use a fully qualified domain name (FQDN). For example, <code>apps.clustername.abc.xyz.com</code>.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-35/#verify-cloud-pak-for-watson-aiops-installation-cli","title":"Verify Cloud Pak for Watson AIOps installation (CLI)","text":"<p>Run the following command to verify that the Cloud Pak for Watson AIOps installation was successful:</p> <pre><code>kubectl get application -A\n</code></pre> <p>Example output from a successful installation:</p> <pre><code># kubectl get application -A\nNAMESPACE          NAME                      SYNC STATUS   HEALTH STATUS\nopenshift-gitops   cp4waiops                 Synced        Healthy\nopenshift-gitops   in-cluster-aimanager      Synced        Healthy\nopenshift-gitops   in-cluster-eventmanager   Synced        Healthy\nopenshift-gitops   in-cluster-rook-ceph      Synced        Healthy\n</code></pre> <p>Wait for a while and then run the following commands to verify that all of the pods in the <code>cp4waiops</code> and <code>noi</code> namespaces are running.</p> <pre><code>kubectl get pod -n cp4waiops\nkubectl get pod -n noi\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-35/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to-deploy-cp4waiops-35/#storage","title":"Storage","text":""},{"location":"how-to-deploy-cp4waiops-35/#problem","title":"Problem","text":"<p>Ceph pod reports the following error:</p> <p><code>cephosd: failed to lookup binary path \"/rootfs/usr/sbin/lvm\" on the host rootfs</code>.</p>"},{"location":"how-to-deploy-cp4waiops-35/#cause","title":"Cause","text":"<p>This problem is caused by missing lvm2 support. For more information, see issue 6705.</p>"},{"location":"how-to-deploy-cp4waiops-35/#solution","title":"Solution","text":"<p>Install lvm2 on all Red Hat OpenShift nodes.</p>"},{"location":"how-to-deploy-cp4waiops-36/","title":"Online Install","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Deploy IBM Cloud Pak for Watson AIOps 3.6 using GitOps<ul> <li>Prerequisites</li> <li>Installing Cloud Pak for Watson AIOps with the Argo CD UI<ul> <li>Log in to Argo CD</li> <li>Grant Argo CD cluster admin permission</li> <li>Configure Argo CD</li> <li>Storage considerations</li> <li>Obtain an entitlement key</li> <li>Update the OpenShift Container Platform global pull secret</li> <li>Installing AI Manager and Event Manager separately<ul> <li>Install shared components</li> <li>Install AI Manager</li> <li>Install Event Manager</li> </ul> </li> <li>Verify the Cloud Pak for Watson AIOps installation</li> <li>Access Cloud Pak for Watson AIOps</li> </ul> </li> <li>Installing Cloud Pak for Watson AIOps from the command line<ul> <li>Log in to Argo CD (CLI)</li> <li>Grant Argo CD cluster admin permission (CLI)</li> <li>Storage considerations (CLI)</li> <li>Obtain an entitlement key (CLI)</li> <li>Update the OpenShift Container Platform global pull secret (CLI)</li> <li>Installing AI Manager and Event Manager separately (CLI)<ul> <li>Install shared components (CLI)</li> <li>Install AI Manager (CLI)</li> <li>Install Event Manager (CLI)</li> </ul> </li> <li>Verify the Cloud Pak for Watson AIOps installation (CLI)</li> <li>Access Cloud Pak for Watson AIOps (CLI)</li> </ul> </li> <li>Troubleshooting<ul> <li>Storage<ul> <li>Problem</li> <li>Cause</li> <li>Solution</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-36/#deploy-ibm-cloud-pak-for-watson-aiops-36-using-gitops","title":"Deploy IBM Cloud Pak for Watson AIOps 3.6 using GitOps","text":"<p>Using GitOps to install Cloud Pak for Watson AIOps 3.6 is a GA feature!</p> <p>The use of GitOps enables IBM Cloud Pak for Watson AIOps to be deployed on a Red Hat OpenShift Container Platform cluster from a Git repository, with the ArgoCD tool. Cloud Pak for Watson AIOps can be installed with the Argo CD user interface (UI), or with the Argo CD command line (CLI).</p> <p>For more information about GitOps, see Understanding OpenShift GitOps in the Red Hat OpenShift documentation.</p> <p>For more information about Argo, see the Argo documentation.</p>"},{"location":"how-to-deploy-cp4waiops-36/#prerequisites","title":"Prerequisites","text":"<ul> <li>Ensure that you meet the supported platform, hardware, and storage requirements. For more information, see System requirements.</li> <li>You must have Red Hat OpenShift GitOps (Argo CD) installed on your Red Hat OpenShift cluster. For more information, see Installing OpenShift GitOps in the Red Hat OpenShift documentation.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-36/#installing-cloud-pak-for-watson-aiops-with-the-argo-cd-ui","title":"Installing Cloud Pak for Watson AIOps with the Argo CD UI","text":""},{"location":"how-to-deploy-cp4waiops-36/#log-in-to-argo-cd","title":"Log in to Argo CD","text":"<p>From your Red Hat OpenShift console, click the menu on the upper right, and select <code>Cluster Argo CD</code>.</p> <p></p> <p>The Argo CD UI is displayed. Click <code>LOG IN VIA OPENSHIFT</code>.</p> <p></p>"},{"location":"how-to-deploy-cp4waiops-36/#grant-argo-cd-cluster-admin-permission","title":"Grant Argo CD cluster admin permission","text":"<p>From the Red Hat OpenShift console, go to <code>User Management</code> &gt; <code>RoleBindings</code> &gt; <code>Create binding</code>. Use the form view to configure the properties for the <code>ClusterRoleBinding</code> with the following values and then click <code>Create</code>.</p> <ul> <li>Binding type  <ul> <li>Cluster-wide role binding (ClusterRoleBinding)  </li> </ul> </li> <li>RoleBinding  <ul> <li>Name: argocd-admin  </li> </ul> </li> <li>Role  <ul> <li>Role Name: cluster-admin  </li> </ul> </li> <li>Subject &gt; ServiceAccount<ul> <li>Subject namespace: openshift-gitops  </li> <li>Subject name: openshift-gitops-argocd-application-controller  </li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-36/#configure-argo-cd","title":"Configure Argo CD","text":"<p>From the Argo CD UI, click <code>NEW APP</code>, input the following parameters, and then click <code>CREATE</code>.</p> <ul> <li>GENERAL  <ul> <li>Application Name: argocd  </li> <li>Project: default  </li> <li>SYNC POLICY: Automatic  </li> </ul> </li> <li>SOURCE  <ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops  </li> <li>Revision: release-3.6  </li> <li>path: config/argocd/openshift  </li> </ul> </li> <li>DESTINATION   <ul> <li>Cluster URL: https://kubernetes.default.svc  </li> <li>Namespace: openshift-gitops  </li> </ul> </li> </ul> <p>After the Argo CD App <code>argocd</code> is created, select the App from the Argo CD UI to view the topology of all of the resources.</p>"},{"location":"how-to-deploy-cp4waiops-36/#storage-considerations","title":"Storage considerations","text":"<p>You must use a supported storage provider. For more information about supported storage, see Storage Considerations. If your Red Hat OpenShift cluster already has a single default supported storage class, then skip this step.</p> <p>Note: Multiple default storage classes cause deployment problems. Run the following command to check your cluster's storage class.</p> <pre><code>oc get sc\n</code></pre> <p>If your cluster has multiple default storage classes, then you must edit your storage classes to leave only one storage class as the default. To remove the default setting from a storage class, run the following command to edit the storage class, and then delete the <code>storageclass.kubernetes.io/is-default-class: \"true\"</code> line under <code>annotations</code>.</p> <pre><code>oc edit sc [STORAGE-CLASS-NAME]\n</code></pre> <p>This tutorial sets up and uses Ceph storage for demonstration purpose. </p> <p>From the Argo CD UI, click <code>NEW APP</code>, input the following parameters for Ceph, and then click <code>CREATE</code>.</p> <ul> <li>GENERAL<ul> <li>Application Name: ceph</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.6</li> <li>path: config/ceph</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: rook-ceph</li> </ul> </li> </ul> <p></p> <p>After the Argo CD App <code>ceph</code> is created, you can click the App from the Argo CD UI to view the topology of the Ceph resources as follows:</p> <p></p> <p>The filters on the left can be used to filter out resources. Click a resource to check its logs and events.</p> <p></p> <p>Run the following command from the command line to check that none of the pods have an error status.</p> <pre><code>[root@xyz.test.cp.fyre.ibm.com ~]# oc get po -n rook-ceph\nNAME                                                              READY   STATUS      RESTARTS   AGE\ncsi-cephfsplugin-7b6jk                                            3/3     Running     0          2d\ncsi-cephfsplugin-l7mvz                                            3/3     Running     0          2d\ncsi-cephfsplugin-provisioner-695b574445-gfcwz                     6/6     Running     6          2d\ncsi-cephfsplugin-provisioner-695b574445-lb64p                     6/6     Running     7          2d\ncsi-cephfsplugin-qcsqz                                            3/3     Running     0          2d\ncsi-cephfsplugin-qdrtl                                            3/3     Running     0          2d\ncsi-cephfsplugin-wj7qq                                            3/3     Running     0          2d\ncsi-cephfsplugin-xlsnb                                            3/3     Running     0          2d\ncsi-rbdplugin-8xwdb                                               3/3     Running     0          2d\ncsi-rbdplugin-b6t9l                                               3/3     Running     0          2d\ncsi-rbdplugin-h965f                                               3/3     Running     0          2d\ncsi-rbdplugin-lv2hp                                               3/3     Running     0          2d\ncsi-rbdplugin-pqvrc                                               3/3     Running     0          2d\ncsi-rbdplugin-provisioner-7f9847cd48-48gqk                        6/6     Running     0          2d\ncsi-rbdplugin-provisioner-7f9847cd48-wxh2z                        6/6     Running     12         2d\ncsi-rbdplugin-x8cw9                                               3/3     Running     0          2d\nrook-ceph-crashcollector-worker0.body.cp.fyre.ibm.com-88f5bnbdc   1/1     Running     0          2d\nrook-ceph-crashcollector-worker1.body.cp.fyre.ibm.com-d4c7gdcts   1/1     Running     0          2d\nrook-ceph-crashcollector-worker2.body.cp.fyre.ibm.com-7767p8fxm   1/1     Running     0          2d\nrook-ceph-crashcollector-worker3.body.cp.fyre.ibm.com-6c5cqs4lk   1/1     Running     0          2d\nrook-ceph-crashcollector-worker4.body.cp.fyre.ibm.com-787f99czf   1/1     Running     0          2d\nrook-ceph-crashcollector-worker5.body.cp.fyre.ibm.com-94d4b654q   1/1     Running     0          2d\nrook-ceph-mds-myfs-a-7d48d48497-sbhld                             1/1     Running     0          2d\nrook-ceph-mds-myfs-b-66f4b746c7-2fnl2                             1/1     Running     0          2d\nrook-ceph-mgr-a-5c84cd7b7b-574lf                                  1/1     Running     0          2d\nrook-ceph-mon-a-7b947ddf45-74p49                                  1/1     Running     0          2d\nrook-ceph-mon-b-7cf885c589-5j6r9                                  1/1     Running     0          2d\nrook-ceph-mon-c-bcb6575d8-g9l5w                                   1/1     Running     0          2d\nrook-ceph-operator-54649856c4-cdx24                               1/1     Running     0          2d\nrook-ceph-osd-0-c44985597-gwkqk                                   1/1     Running     0          2d\nrook-ceph-osd-1-6f7d5cc955-v4862                                  1/1     Running     0          2d\nrook-ceph-osd-2-58df99c46f-5kl8z                                  1/1     Running     0          2d\nrook-ceph-osd-3-5c8579456c-bpcqz                                  1/1     Running     0          2d\nrook-ceph-osd-4-5668c69fbf-kvdf6                                  1/1     Running     0          2d\nrook-ceph-osd-5-cbbdb95-cqvjd                                     1/1     Running     0          2d\nrook-ceph-osd-prepare-worker0.body.cp.fyre.ibm.com-bxr7t          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker1.body.cp.fyre.ibm.com-fftd8          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker2.body.cp.fyre.ibm.com-scg84          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker3.body.cp.fyre.ibm.com-m488b          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker4.body.cp.fyre.ibm.com-dxcm5          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker5.body.cp.fyre.ibm.com-jclnq          0/1     Completed   0          4h16m\n</code></pre> <p>If any of the pods are in an error state, you can check the logs by using <code>oc logs</code>.</p>"},{"location":"how-to-deploy-cp4waiops-36/#obtain-an-entitlement-key","title":"Obtain an entitlement key","text":"<p>Obtain your IBM Entitled Registry key to enable your deployment to pull images from the IBM Entitled Registry.</p> <ol> <li> <p>Obtain the entitlement key that is assigned to your IBMid. Log in to MyIBM Container Software Library with the IBMid and password details that are associated with the entitled software.</p> </li> <li> <p>In the \"Entitlement key\" section, select \"Copy key\" to copy the entitlement key to the clipboard.</p> </li> <li> <p>Copy the entitlement key to a safe place so that you can use it later when you update the global pull secret for the cluster.</p> </li> <li> <p>(Optional) Verify the validity of the key by logging in to the IBM Entitled Registry.</p> </li> </ol> <p>Depending on the container system that you are using, you might need to use <code>docker login</code> instead of <code>podman login</code> for the following command.</p> <pre><code>export IBM_ENTITLEMENT_KEY=the key from the previous steps\npodman login cp.icr.io --username cp --password \"${IBM_ENTITLEMENT_KEY:?}\"\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-36/#update-the-openshift-container-platform-global-pull-secret","title":"Update the OpenShift Container Platform global pull secret","text":"<ol> <li> <p>From the Red Hat OpenShift console, select the \"Administrator\" perspective, and then select \"Workloads &gt; Secrets\".</p> </li> <li> <p>Select the project \"openshift-config\". </p> </li> <li> <p>Select the object \"pull-secret\".</p> </li> <li> <p>Click \"Actions &gt; Edit secret\".</p> </li> <li> <p>Scroll to the end of the page and click \"Add credentials\". Use the following values:</p> <ul> <li>\"Registry Server Address\" cp.icr.io</li> <li>\"Username\": cp</li> <li>\"Password\": paste the entitlement key that you copied from the Obtain an entitlement key step</li> <li>\"Email\": email address. This field is mostly a hint to other people who might see the entry in the configuration.</li> </ul> <p>Note: The registry user for this secret is \"cp\", not the name or email of the user who owns the entitlement key.</p> </li> <li> <p>Click \"Save\".</p> </li> </ol> <p>For more information, see Update the OpenShift Container Platform global pull secret in the Red Hat OpenShift documentation.</p>"},{"location":"how-to-deploy-cp4waiops-36/#installing-ai-manager-and-event-manager-separately","title":"Installing AI Manager and Event Manager separately","text":""},{"location":"how-to-deploy-cp4waiops-36/#install-shared-components","title":"Install shared components","text":"<ul> <li>GENERAL<ul> <li>Application Name: anyname (for example: \"cp-shared\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.6</li> <li>path: config/cp-shared/operators</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: openshift-marketplace</li> </ul> </li> <li>PARAMETERS<ul> <li>spec.imageCatalog: icr.io/cpopen/ibm-operator-catalog:latest</li> <li>spec.catalogName: ibm-operator-catalog</li> <li>spec.catalogNamespace: openshift-marketplace</li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-36/#install-ai-manager","title":"Install AI Manager","text":"<p>Install AI Manager by using GitOps to create an Argo CD App for AI Manager. The parameters for AI Manager are as follows:</p> <ul> <li>GENERAL<ul> <li>Application Name: anyname (for example: \"aimanager-app\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.6</li> <li>path: config/cp4waiops/install-aimgr</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: cp4waiops</li> </ul> </li> <li>PARAMETERS<ul> <li>spec.storageClass: rook-cephfs  (you must update this value to be the RWX storage class that is being used in your environment. You can find this by running the command <code>oc get sc</code>.)</li> <li>spec.storageClassLargeBlock: rook-cephfs  (you must update this value to be the RWO storage that is being used in your environment. You can find this by running the command <code>oc get sc</code>.)</li> <li>spec.aiManager.channel: v3.6</li> <li>spec.aiManager.size: small</li> <li>spec.aiManager.namespace: cp4waiops</li> <li>spec.aiManager.pakModules.aiopsFoundation.enabled: true</li> <li>spec.aiManager.pakModules.applicationManager.enabled: true</li> <li>spec.aiManager.pakModules.aiManager.enabled: true</li> <li>spec.aiManager.pakModules.connection.enabled: true</li> </ul> </li> </ul> <p>NOTE: If you use a repository that is forked from the official Cloud Pak for Watson AIOps GitOps repository or a different branch, then you must update the values of the <code>Repository URL</code> and <code>Revision</code> parameters to match your repository and branch. For example, if you use <code>https://github.com/&lt;myaccount&gt;/cp4waiops-gitops</code> and <code>dev</code> branch, then these two parameters must be changed.</p>"},{"location":"how-to-deploy-cp4waiops-36/#install-event-manager","title":"Install Event Manager","text":"<p>Install Event Manager by using GitOps to create an Argo CD App for Event Manager. The parameters for Event Manager are as follows:</p> <ul> <li>GENERAL<ul> <li>Application Name: anyname (for example: \"eventmanager-app\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.6</li> <li>path: config/cp4waiops/install-emgr</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: noi </li> </ul> </li> <li>PARAMETERS<ul> <li>spec.imageCatalog: icr.io/cpopen/ibm-operator-catalog:latest</li> <li>spec.storageClass: rook-cephfs  (you must update this value to be the RWX storage class that is being used in your environment. You can find this by running the command <code>oc get sc</code>.)</li> <li>spec.storageClassLargeBlock: rook-cephfs  (you must update this value to be the RWO storage class that is being used in your environment. You can find this by running the command <code>oc get sc</code>.)</li> <li>spec.eventManager.version: 1.6.6</li> <li>spec.eventManager.clusterDomain:  <li>spec.eventManager.channel: v1.10</li> <li>spec.eventManager.deploymentType: trial</li> <li>spec.eventManager.namespace: noi</li> <p>Where <code>&lt;domain_name&gt;</code> is the domain name of the cluster where Event Manager is installed. You must use a fully qualified domain name (FQDN). For example, <code>apps.clustername.abc.xyz.com</code>. You can retrieve the FQDN by running the following command:</p> <pre><code>INGRESS_OPERATOR_NAMESPACE=openshift-ingress-operator\nappDomain=`oc -n ${INGRESS_OPERATOR_NAMESPACE} get ingresscontrollers default -o json | python -c \"import json,sys;obj=json.load(sys.stdin);print obj['status']['domain'];\"`\necho ${appDomain}\n</code></pre> <p>Note: - If you use a repository that is forked from the official Cloud Pak for Watson AIOps GitOps repository or a different branch, then you must update the values of the <code>Repository URL</code> and <code>Revision</code> parameters to match your repository and branch. For example, if you use <code>https://github.com/&lt;myaccount&gt;/cp4waiops-gitops</code> and <code>dev</code> branch, then these two parameters must be changed.</p>"},{"location":"how-to-deploy-cp4waiops-36/#verify-the-cloud-pak-for-watson-aiops-installation","title":"Verify the Cloud Pak for Watson AIOps installation","text":"<p>When Ceph and Cloud Pak for Watson AIOps are ready, you can see these Apps with a status of <code>Healthy</code> and <code>Synced</code> in the Argo CD UI.</p> <p></p> <p></p> <p>You can check the topology of Cloud Pak for Watson AIOps from the Argo CD UI as follows:</p> <p></p> <p></p> <p>You can also check your Cloud Pak for Watson AIOps installation from the command line. For example, to check the AI Manager pods, run the following command:</p> <pre><code>[root@api.body.cp.fyre.ibm.com ~]# oc get po -n cp4waiops\nNAME                                                              READY   STATUS      RESTARTS   AGE\naimanager-aio-ai-platform-api-server-7c877989d6-7jh55             1/1     Running     0          47h\naimanager-aio-change-risk-654884bd8c-6xpxw                        1/1     Running     0          47h\naimanager-aio-chatops-orchestrator-7c54fc5664-rtmrp               1/1     Running     0          47h\naimanager-aio-chatops-slack-integrator-77fc9499c4-wtclt           1/1     Running     0          47h\naimanager-aio-chatops-teams-integrator-577f6b85bf-j2995           1/1     Running     0          47h\naimanager-aio-controller-86875d4b7-jfwwp                          1/1     Running     0          47h\naimanager-aio-create-secrets-ccjdg                                0/1     Completed   0          47h\naimanager-aio-create-truststore-5hxps                             0/1     Completed   0          47h\naimanager-aio-curator-job-27362220-k59t8                          0/1     Completed   0          142m\naimanager-aio-curator-job-27362280-n2w88                          0/1     Completed   0          82m\naimanager-aio-curator-job-27362340-qkwln                          0/1     Completed   0          22m\naimanager-aio-log-anomaly-detector-fdfcbb96b-rpb9q                1/1     Running     0          47h\naimanager-aio-log-anomaly-detector-fdfcbb96b-v426m                1/1     Running     0          47h\naimanager-aio-similar-incidents-service-77cc9d699f-qlxgg          1/1     Running     0          47h\naimanager-ibm-minio-0                                             1/1     Running     0          47h\naimanager-operator-585d799f9f-w22vz                               1/1     Running     0          47h\naiops-ai-model-ui-674b4f77f9-qv56n                                1/1     Running     0          47h\naiops-akora-ui-7bc6d5dd6b-6n9rs                                   1/1     Running     0          47h\naiops-application-details-ui-66779f957b-fqfhk                     1/1     Running     0          47h\naiops-base-ui-5b9f885888-pvm7z                                    1/1     Running     0          47h\naiops-connections-ui-7996699c55-m79fl                             1/1     Running     0          47h\naiops-ir-analytics-classifier-75869fd78b-p2s9v                    1/1     Running     0          47h\naiops-ir-analytics-probablecause-6dd5ffd867-rrg6b                 1/1     Running     2          47h\naiops-ir-analytics-spark-master-5cd57946d4-99bqt                  1/1     Running     0          47h\naiops-ir-analytics-spark-pipeline-composer-795f965b6d-vkjqw       1/1     Running     0          47h\naiops-ir-analytics-spark-worker-65d57f7f9c-4nsb8                  1/1     Running     0          47h\naiops-ir-core-archiving-754dcb5fcb-jm82z                          1/1     Running     0          47h\naiops-ir-core-archiving-setup-rrlkh                               0/1     Completed   0          47h\naiops-ir-core-cem-users-65b9b699b9-hzh9b                          1/1     Running     0          47h\naiops-ir-core-esarchiving-67dbb7c5d7-wg7dx                        1/1     Running     0          47h\naiops-ir-core-logstash-6c89d66f79-tlfcl                           1/1     Running     0          47h\naiops-ir-core-ncobackup-0                                         2/2     Running     0          47h\naiops-ir-core-ncodl-api-59f977b475-lx7n4                          1/1     Running     0          47h\naiops-ir-core-ncodl-if-66cf44c565-lkkgx                           1/1     Running     0          47h\naiops-ir-core-ncodl-ir-7469fd4866-wjfvf                           1/1     Running     0          47h\naiops-ir-core-ncodl-jobmgr-76d74b5567-t77wc                       1/1     Running     0          47h\naiops-ir-core-ncodl-setup-8hx6c                                   0/1     Completed   0          47h\naiops-ir-core-ncodl-std-7677546c8d-dbqm9                          1/1     Running     0          47h\naiops-ir-core-ncodl-std-7677546c8d-wf82d                          1/1     Running     0          47h\naiops-ir-core-ncoprimary-0                                        1/1     Running     0          47h\naiops-ir-lifecycle-create-policies-job-dljxp                      0/1     Completed   0          47h\naiops-ir-lifecycle-eventprocessor-ep-jobmanager-0                 2/2     Running     0          47h\naiops-ir-lifecycle-eventprocessor-ep-taskmanager-0                1/1     Running     0          47h\naiops-ir-lifecycle-logstash-77579f5d7f-9rhsx                      1/1     Running     0          47h\naiops-ir-lifecycle-policy-grpc-svc-6b59698569-cvhvq               1/1     Running     0          47h\naiops-ir-lifecycle-policy-registry-svc-68647d4cdc-t27mw           1/1     Running     0          47h\naiops-ir-lifecycle-policy-registry-svc-job-8gk89                  0/1     Completed   3          47h\naiops-ir-ui-api-graphql-68488c7675-87mbp                          1/1     Running     0          47h\naiops-topology-cassandra-0                                        1/1     Running     0          47h\naiops-topology-cassandra-auth-secret-generator-7mm84              0/1     Completed   0          47h\naiops-topology-file-observer-5757769dd5-xxc8j                     1/1     Running     0          47h\naiops-topology-kubernetes-observer-d4c8bcb55-ddbcg                1/1     Running     0          47h\naiops-topology-layout-6b957b5bbb-m28rd                            1/1     Running     0          47h\naiops-topology-merge-76c494795f-5b65g                             1/1     Running     0          47h\naiops-topology-observer-service-6f5d6fb44b-jswwp                  1/1     Running     0          47h\naiops-topology-rest-observer-799bfdf4c8-5nt6n                     1/1     Running     0          47h\naiops-topology-search-6cd7cc9d8-64bdk                             1/1     Running     0          47h\naiops-topology-secret-manager-2b84s                               0/1     Completed   0          47h\naiops-topology-servicenow-observer-84c588df5b-gm6p2               1/1     Running     0          47h\naiops-topology-status-58ddcdc845-mqpzg                            1/1     Running     0          47h\naiops-topology-topology-577b988f78-kc2m6                          1/1     Running     2          47h\naiops-topology-ui-api-bbd74965d-gzlfd                             1/1     Running     0          47h\naiops-topology-vmvcenter-observer-86b6c8dc44-krvtj                1/1     Running     0          47h\naiopsedge-github-topology-integrator-7b9db59cd8-nbdgz             1/1     Running     0          47h\naiopsedge-operator-controller-manager-9b68ddd75-5rqqz             1/1     Running     1          47h\naiopsedge-operator-controller-manager-9b68ddd75-xj7tq             1/1     Running     1          47h\nasm-operator-548c8894fd-r2dgv                                     1/1     Running     0          47h\nc-example-couchdbcluster-m-0                                      3/3     Running     0          47h\nc-example-redis-m-0                                               4/4     Running     0          47h\nc-example-redis-m-1                                               4/4     Running     0          47h\nc-example-redis-m-2                                               4/4     Running     0          47h\nc-example-redis-s-0                                               4/4     Running     0          47h\nc-example-redis-s-1                                               4/4     Running     0          47h\nc-example-redis-s-2                                               4/4     Running     0          47h\ncamel-k-kit-c7c60rolvegv49tvh8fg-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60sglvegv49tvh8g0-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60tglvegv49tvh8gg-1-build                          0/1     Completed   0          47h\ncamel-k-kit-c7c60tolvegv49tvh8h0-1-build                          0/1     Completed   0          47h\ncamel-k-operator-684f46fc4d-s6hf2                                 1/1     Running     0          47h\nconfigure-aiops-network-policy-967ll                              0/1     Completed   0          47h\nconnector-controller-bc7fc6668-f8nn5                              1/1     Running     0          47h\nconnector-synchronizer-7d4546ddd4-5kbrl                           1/1     Running     0          47h\ncouchdb-operator-d5cb7ff8c-rjnhx                                  1/1     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-jobmanager-0                 2/2     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-jobmanager-1                 2/2     Running     0          47h\ncp4waiops-eventprocessor-eve-29ee-ep-taskmanager-0                1/1     Running     1          47h\ncp4waiops-eventprocessor-eve-29ee-ep-taskmanager-1                1/1     Running     0          47h\ncp4waiops-image-pull-secret-6fprf                                 0/1     Completed   0          2d\ncp4waiops-patch-j4qrm                                             0/1     Completed   0          2d\ncp4waiops-postgres-keeper-0                                       1/1     Running     0          47h\ncp4waiops-postgres-postgresql-create-cluster-7xb6t                0/1     Completed   0          47h\ncp4waiops-postgres-proxy-648bc64fd-x4mvv                          1/1     Running     0          47h\ncp4waiops-postgres-sentinel-5878f67f46-gvv7l                      1/1     Running     0          47h\ncp4waiops-postgresdb-postgresql-create-database-9j6kq             0/1     Completed   0          47h\ncreate-secrets-job-nx6dg                                          0/1     Completed   0          47h\ngateway-kong-5d45b77fb4-tgjcv                                     2/2     Running     2          47h\ngateway-kong-config-svc-27362360-9dmzc                            0/1     Completed   0          2m51s\niaf-core-operator-controller-manager-58dfd97f5c-bdd9t             1/1     Running     0          2d\niaf-eventprocessing-operator-controller-manager-5bc597797f6fxm4   1/1     Running     1          2d\niaf-flink-operator-controller-manager-7dc56c9b68-6rgtk            1/1     Running     0          2d\niaf-operator-controller-manager-6bc8f44ff7-rrrnx                  1/1     Running     0          2d\niaf-system-elasticsearch-es-aiops-0                               2/2     Running     0          47h\niaf-system-entity-operator-6b5444f575-7tdfw                       3/3     Running     0          47h\niaf-system-kafka-0                                                1/1     Running     0          47h\niaf-system-zookeeper-0                                            1/1     Running     0          47h\niaf-zen-tour-job-fhdfr                                            0/1     Completed   0          47h\niam-config-job-tfsst                                              0/1     Completed   0          47h\nibm-aiops-orchestrator-6c7cfc85b7-wqdnr                           1/1     Running     0          2d\nibm-cloud-databases-redis-operator-854cf65c4f-4rrvn               1/1     Running     0          47h\nibm-common-service-operator-5cd6947dc8-z8plb                      1/1     Running     0          2d\nibm-elastic-operator-controller-manager-5d6c467b55-wtrvg          1/1     Running     0          2d\nibm-ir-ai-operator-controller-manager-59b88c6bf6-ncnbt            1/1     Running     7          47h\nibm-kong-operator-6ff97bcdb9-rl7cp                                1/1     Running     0          47h\nibm-nginx-cd84b4d8-7ttn2                                          1/1     Running     0          47h\nibm-nginx-cd84b4d8-zp4t2                                          1/1     Running     0          47h\nibm-postgreservice-operator-controller-manager-8b7bdf589-hbg2g    1/1     Running     2          47h\nibm-secure-tunnel-operator-657dd7b78f-tsgws                       1/1     Running     0          47h\nibm-vault-deploy-consul-0                                         1/1     Running     0          47h\nibm-vault-deploy-vault-0                                          1/1     Running     0          47h\nibm-vault-deploy-vault-cron-job-27361440-qxpjl                    0/1     Completed   0          15h\nibm-vault-deploy-vault-injector-596567d459-wzkws                  1/1     Running     0          47h\nibm-vault-operator-controller-manager-5957bb5ff9-4zdrb            1/1     Running     0          47h\nibm-watson-aiops-ui-operator-controller-manager-b8cf6fff7-msspt   1/1     Running     0          47h\nir-core-operator-controller-manager-76dbdb699d-g97ng              1/1     Running     7          47h\nir-lifecycle-operator-controller-manager-64bdd8f7b6-pn46g         1/1     Running     9          47h\nmodel-train-classic-operator-56d487585c-4dv5b                     1/1     Running     2          47h\nmodeltrain-ibm-modeltrain-lcm-865b7f85cc-jfq4z                    1/1     Running     0          47h\nmodeltrain-ibm-modeltrain-ratelimiter-595f4f478-r9dwp             1/1     Running     0          47h\nmodeltrain-ibm-modeltrain-trainer-5b7f7888b5-c8cz5                1/1     Running     0          47h\npost-aiops-resources-t4ww9                                        0/1     Completed   0          47h\npost-aiops-translations-t58bb                                     0/1     Completed   0          47h\npost-aiops-update-user-role-kcr8k                                 0/1     Completed   0          47h\nscm-handlers-d655679fc-lvls2                                      2/2     Running     0          47h\nsetup-nginx-job-tn8sc                                             0/1     Completed   0          47h\nsnow-handlers-d8488f6f8-8lhxh                                     2/2     Running     0          47h\nsre-tunnel-controller-84565ff4f8-4qtwl                            1/1     Running     0          47h\nsre-tunnel-tunnel-network-api-589fd6646d-7znnh                    1/1     Running     0          47h\nsre-tunnel-tunnel-ui-mcmtunnelui-fff9b859b-g7dlk                  1/1     Running     0          47h\nusermgmt-5fb7986c7b-dwmk2                                         1/1     Running     0          47h\nusermgmt-5fb7986c7b-ssk86                                         1/1     Running     0          47h\nzen-audit-678b54b548-n7q7f                                        1/1     Running     0          47h\nzen-core-64c6d56db-d25zm                                          1/1     Running     0          47h\nzen-core-64c6d56db-glv65                                          1/1     Running     1          47h\nzen-core-api-85489478d6-95pck                                     1/1     Running     0          47h\nzen-core-api-85489478d6-n9x5s                                     1/1     Running     0          47h\nzen-metastoredb-0                                                 1/1     Running     0          47h\nzen-metastoredb-1                                                 1/1     Running     0          47h\nzen-metastoredb-2                                                 1/1     Running     0          47h\nzen-metastoredb-certs-lblhv                                       0/1     Completed   0          47h\nzen-metastoredb-init-hvlv2                                        0/1     Completed   0          47h\nzen-post-requisite-job-lpkfw                                      0/1     Completed   0          47h\nzen-pre-requisite-job-2klrt                                       0/1     Completed   0          47h\nzen-watcher-d8b795b46-2q6zx                                       1/1     Running     0          47h\n</code></pre> <p>If any pods are in an error state, you can check the logs from the Argo CD UI, or you can run <code>oc logs</code> from the command line.</p>"},{"location":"how-to-deploy-cp4waiops-36/#access-cloud-pak-for-watson-aiops","title":"Access Cloud Pak for Watson AIOps","text":"<p>If all of the pods for Cloud Pak for Watson AIOps are up and running, then you can log in to the Cloud Pak for Watson AIOps UI as follows.</p> <p>Log in to the Red Hat OpenShift console, and then click the drop-down menu on the upper right.</p> <p></p> <p>Click the <code>IBM Cloud Pak for Administration</code> link, and select <code>OpenShift authentication</code>.</p> <p></p> <p>Log in to <code>IBM Cloud Pak for Administration</code>, click the drop-down menu on the upper right, and then select <code>IBM Automation (cp4waiops)</code>.</p> <p></p> <p>Log in to the Cloud Pak for Watson AIOps UI and then select <code>OpenShift authentication</code>.</p> <p></p> <p>The Cloud Pak for Watson AIOps user interface is displayed.</p> <p></p> <p>Congratulations! You are ready to play with Cloud Pak for Watson AIOps!</p>"},{"location":"how-to-deploy-cp4waiops-36/#installing-cloud-pak-for-watson-aiops-from-the-command-line","title":"Installing Cloud Pak for Watson AIOps from the command line","text":""},{"location":"how-to-deploy-cp4waiops-36/#log-in-to-argo-cd-cli","title":"Log in to Argo CD (CLI)","text":"<p>Make sure that the Argo CD CLI (<code>argocd</code> command) is installed. For more information, see the Argo documentation.</p> <p>Then, run the following commands to log in to Argo CD:</p> <pre><code>argo_route=openshift-gitops-server\nargo_secret=openshift-gitops-cluster\nsa_account=openshift-gitops-argocd-application-controller\n\nargo_pwd=$(oc get secret ${argo_secret} \\\n-n openshift-gitops \\\n-o jsonpath='{.data.admin\\.password}' | base64 -d ; echo ) \\\n&amp;&amp; argo_url=$(oc get route ${argo_route} \\\n-n openshift-gitops \\\n-o jsonpath='{.spec.host}') \\\n&amp;&amp; argocd login \"${argo_url}\" \\\n--username admin \\\n--password \"${argo_pwd}\" \\\n--insecure\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-36/#grant-argo-cd-cluster-admin-permission-cli","title":"Grant Argo CD cluster admin permission (CLI)","text":"<p>Apply the following YAML manifest to the cluster where Argo CD runs:</p> <pre><code>kind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\nname: argocd-admin\nsubjects:\n- kind: ServiceAccount\nname: openshift-gitops-argocd-application-controller\nnamespace: openshift-gitops\nroleRef:\napiGroup: rbac.authorization.k8s.io\nkind: ClusterRole\nname: cluster-admin\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-36/#storage-considerations-cli","title":"Storage considerations (CLI)","text":"<p>You must use a supported storage provider. For more information about supported storage, see Storage Considerations. If your Red Hat OpenShift cluster already has a single default supported storage class, then skip this step.</p> <p>Note: Multiple default storage classes cause deployment problems. Run the following command to check your cluster's storage class.</p> <pre><code>oc get sc\n</code></pre> <p>If your cluster has multiple default storage classes, then you must edit your storage classes to leave only one storage class as the default. To remove the default setting from a storage class, run the following command to edit the storage class, and then delete the <code>storageclass.kubernetes.io/is-default-class: \"true\"</code> line under <code>annotations</code>.</p> <pre><code>oc edit sc [STORAGE-CLASS-NAME]\n</code></pre> <p>This tutorial sets up and uses Ceph storage for demonstration purpose. </p> <p>To create an Argo CD App for Ceph storage, run the following command:</p> <pre><code>argocd app create ceph \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/ceph \\\n--revision release-3.6 \\\n--dest-namespace rook-ceph \\\n--dest-server https://kubernetes.default.svc\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-36/#obtain-an-entitlement-key-cli","title":"Obtain an entitlement key (CLI)","text":"<p>Obtain your IBM Entitled Registry key to enable your deployment to pull images from the IBM Entitled Registry.</p> <ol> <li> <p>Obtain the entitlement key that is assigned to your IBMid. Log in to MyIBM Container Software Library with the IBMid and password details that are associated with the entitled software.</p> </li> <li> <p>In the \"Entitlement key\" section, select \"Copy key\" to copy the entitlement key to the clipboard.</p> </li> <li> <p>Copy the entitlement key to a safe place so that you can use it later when you update the global pull secret for the cluster.</p> </li> <li> <p>(Optional) Verify the validity of the key by logging in to the IBM Entitled Registry.</p> </li> </ol> <p>Depending on the container system that you are using, you might need to use <code>docker login</code> instead of <code>podman login</code> for the following command.</p> <pre><code>export IBM_ENTITLEMENT_KEY=the key from the previous steps\npodman login cp.icr.io --username cp --password \"${IBM_ENTITLEMENT_KEY:?}\"\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-36/#update-the-openshift-container-platform-global-pull-secret-cli","title":"Update the OpenShift Container Platform global pull secret (CLI)","text":"<p>Run the following command to create the entitlement key pull secret:</p> <pre><code>oc create secret docker-registry ibm-entitlement-key \\\n    --docker-username=cp \\\n    --docker-password=&lt;entitlement-key&gt; \\\n    --docker-server=cp.icr.io \\\n    --namespace=cp4waiops\n</code></pre> <p>Where <code>&lt;entitlement-key&gt;</code> is the entitlement key that you copied in the previous step.</p>"},{"location":"how-to-deploy-cp4waiops-36/#installing-ai-manager-and-event-manager-separately-cli","title":"Installing AI Manager and Event Manager separately (CLI)","text":""},{"location":"how-to-deploy-cp4waiops-36/#install-shared-components-cli","title":"Install shared components (CLI)","text":"<pre><code>argocd app create cp-shared \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/cp-shared/operators \\\n--revision release-3.6 \\\n--dest-namespace openshift-marketplace \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.imageCatalog=icr.io/cpopen/ibm-operator-catalog:latest \\\n--helm-set spec.catalogName=ibm-operator-catalog \\\n--helm-set spec.catalogNamespace=openshift-marketplace\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-36/#install-ai-manager-cli","title":"Install AI Manager (CLI)","text":"<p>Run the following command to install AI Manager by using GitOps to create an Argo CD App for AI Manager.</p> <pre><code>argocd app create aimanager-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/cp4waiops/install-aimgr \\\n--revision release-3.6 \\\n--dest-namespace cp4waiops \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.storageClass=rook-cephfs \\\n--helm-set spec.storageClassLargeBlock=rook-cephfs \\\n--helm-set spec.aiManager.namespace=cp4waiops \\\n--helm-set spec.aiManager.channel=v3.6 \\\n--helm-set spec.aiManager.size=small \\\n--helm-set spec.aiManager.pakModules.aiopsFoundation.enabled=true \\\n--helm-set spec.aiManager.pakModules.applicationManager.enabled=true \\\n--helm-set spec.aiManager.pakModules.aiManager.enabled=true \\\n--helm-set spec.aiManager.pakModules.connection.enabled=true\n</code></pre> <p>Important: You must update the values of spec.storageClass and storageClassLargeBlock to be the RWX and RWO storage classes that are being used in your environment. You can find this by running the command <code>oc get sc</code>.</p>"},{"location":"how-to-deploy-cp4waiops-36/#install-event-manager-cli","title":"Install Event Manager (CLI)","text":"<p>Run the following command to install Event Manager by using GitOps to create an Argo CD App for Event Manager.</p> <pre><code>argocd app create eventmanager-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/cp4waiops/install-emgr \\\n--revision release-3.6 \\\n--dest-namespace noi \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.imageCatalog=icr.io/cpopen/ibm-operator-catalog:latest \\\n--helm-set spec.storageClass=rook-cephfs \\\n--helm-set spec.storageClassLargeBlock=rook-cephfs \\\n--helm-set spec.eventManager.namespace=noi \\\n--helm-set spec.eventManager.channel=v1.10 \\\n--helm-set spec.eventManager.version=1.6.6 \\\n--helm-set spec.eventManager.clusterDomain=&lt;domain_name&gt; \\\n--helm-set spec.eventManager.deploymentType=trial\n</code></pre> <p>Important: - You must update the values of spec.storageClass and storageClassLargeBlock to be the RWX and RWO storage classes that are being used in your environment. You can find this by running the command <code>oc get sc</code>. - <code>&lt;domain_name&gt;</code> must be the domain name of the cluster where Event Manager is installed. Use a fully qualified domain name (FQDN). For example, <code>apps.clustername.abc.xyz.com</code>. You can also retrieve the FDQN by running the following command:</p> <pre><code>INGRESS_OPERATOR_NAMESPACE=openshift-ingress-operator\nappDomain=`oc -n ${INGRESS_OPERATOR_NAMESPACE} get ingresscontrollers default -o json | python -c \"import json,sys;obj=json.load(sys.stdin);print obj['status']['domain'];\"`\necho ${appDomain}\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-36/#verify-the-cloud-pak-for-watson-aiops-installation-cli","title":"Verify the Cloud Pak for Watson AIOps installation (CLI)","text":"<p>Run the following command to verify that the Cloud Pak for Watson AIOps installation was successful:</p> <pre><code>oc get application -A\n</code></pre> <p>Example output from a successful installation:</p> <pre><code># oc get application -A\nNAMESPACE          NAME                      SYNC STATUS   HEALTH STATUS\nopenshift-gitops   cp4waiops                 Synced        Healthy\nopenshift-gitops   in-cluster-aimanager      Synced        Healthy\nopenshift-gitops   in-cluster-eventmanager   Synced        Healthy\nopenshift-gitops   in-cluster-rook-ceph      Synced        Healthy\n</code></pre> <p>Wait for a while and then run the following commands to verify that all of the pods in the <code>cp4waiops</code> and <code>noi</code> namespaces are running.</p> <pre><code>oc get pod -n cp4waiops\noc get pod -n noi\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-36/#access-cloud-pak-for-watson-aiops-cli","title":"Access Cloud Pak for Watson AIOps (CLI)","text":"<p>If all of the pods for Cloud Pak for Watson AIOps are up and running, then you can log in to the Cloud Pak for Watson AIOps UI as follows.</p> <p>Log in to the Red Hat OpenShift console, and then click the drop-down menu on the upper right.</p> <p></p> <p>Click the <code>IBM Cloud Pak for Administration</code> link, and select <code>OpenShift authentication</code>.</p> <p></p> <p>Log in to <code>IBM Cloud Pak for Administration</code>, click the drop-down menu on the upper right, and then select <code>IBM Automation (cp4waiops)</code>.</p> <p></p> <p>Log in to the Cloud Pak for Watson AIOps UI and then select <code>OpenShift authentication</code>.</p> <p></p> <p>The Cloud Pak for Watson AIOps user interface is displayed.</p> <p></p> <p>Congratulations! You are ready to play with Cloud Pak for Watson AIOps!</p>"},{"location":"how-to-deploy-cp4waiops-36/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to-deploy-cp4waiops-36/#storage","title":"Storage","text":""},{"location":"how-to-deploy-cp4waiops-36/#problem","title":"Problem","text":"<p>Ceph pod reports the following error:</p> <p><code>cephosd: failed to lookup binary path \"/rootfs/usr/sbin/lvm\" on the host rootfs</code>.</p>"},{"location":"how-to-deploy-cp4waiops-36/#cause","title":"Cause","text":"<p>This problem is caused by missing lvm2 support. For more information, see issue 6705.</p>"},{"location":"how-to-deploy-cp4waiops-36/#solution","title":"Solution","text":"<p>Install lvm2 on all Red Hat OpenShift nodes.</p>"},{"location":"how-to-deploy-cp4waiops-37/","title":"Online Install","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Deploy IBM Cloud Pak for Watson AIOps 3.7 using GitOps<ul> <li>Prerequisites</li> <li>Installing Cloud Pak for Watson AIOps with the Argo CD UI<ul> <li>Log in to Argo CD</li> <li>Grant Argo CD cluster admin permission</li> <li>Configure Argo CD</li> <li>Storage considerations</li> <li>Obtain an entitlement key</li> <li>Update the OpenShift Container Platform global pull secret</li> <li>Installing AI Manager and Event Manager separately<ul> <li>Install shared components</li> <li>Install AI Manager</li> <li>Install Event Manager</li> </ul> </li> <li>Verify the Cloud Pak for Watson AIOps installation</li> <li>Access Cloud Pak for Watson AIOps</li> </ul> </li> <li>Installing Cloud Pak for Watson AIOps from the command line<ul> <li>Log in to Argo CD (CLI)</li> <li>Grant Argo CD cluster admin permission (CLI)</li> <li>Storage considerations (CLI)</li> <li>Obtain an entitlement key (CLI)</li> <li>Update the OpenShift Container Platform global pull secret (CLI)</li> <li>Installing AI Manager and Event Manager separately (CLI)<ul> <li>Install shared components (CLI)</li> <li>Install AI Manager (CLI)</li> <li>Install Event Manager (CLI)</li> </ul> </li> <li>Verify the Cloud Pak for Watson AIOps installation (CLI)</li> <li>Access Cloud Pak for Watson AIOps (CLI)</li> </ul> </li> <li>Troubleshooting<ul> <li>Storage<ul> <li>Problem</li> <li>Cause</li> <li>Solution</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-37/#deploy-ibm-cloud-pak-for-watson-aiops-37-using-gitops","title":"Deploy IBM Cloud Pak for Watson AIOps 3.7 using GitOps","text":"<p>Using GitOps to install Cloud Pak for Watson AIOps 3.7 is a GA feature!</p> <p>The use of GitOps enables IBM Cloud Pak for Watson AIOps to be deployed on a Red Hat OpenShift Container Platform cluster from a Git repository, with the ArgoCD tool. Cloud Pak for Watson AIOps can be installed with the Argo CD user interface (UI), or with the Argo CD command line (CLI).</p> <p>For more information about GitOps, see Understanding OpenShift GitOps in the Red Hat OpenShift documentation.</p> <p>For more information about Argo, see the Argo documentation.</p>"},{"location":"how-to-deploy-cp4waiops-37/#prerequisites","title":"Prerequisites","text":"<ul> <li>Ensure that you meet the supported platform, hardware, and storage requirements. For more information, see System requirements.</li> <li>You must have Red Hat OpenShift GitOps (Argo CD) installed on your Red Hat OpenShift cluster. For more information, see Installing OpenShift GitOps in the Red Hat OpenShift documentation.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-37/#installing-cloud-pak-for-watson-aiops-with-the-argo-cd-ui","title":"Installing Cloud Pak for Watson AIOps with the Argo CD UI","text":""},{"location":"how-to-deploy-cp4waiops-37/#log-in-to-argo-cd","title":"Log in to Argo CD","text":"<p>From your Red Hat OpenShift console, click the menu on the upper right, and select <code>Cluster Argo CD</code>.</p> <p></p> <p>The Argo CD UI is displayed. Click <code>LOG IN VIA OPENSHIFT</code>.</p> <p></p>"},{"location":"how-to-deploy-cp4waiops-37/#grant-argo-cd-cluster-admin-permission","title":"Grant Argo CD cluster admin permission","text":"<p>From the Red Hat OpenShift console, go to <code>User Management</code> &gt; <code>RoleBindings</code> &gt; <code>Create binding</code>. Use the form view to configure the properties for the <code>ClusterRoleBinding</code> with the following values and then click <code>Create</code>.</p> <ul> <li>Binding type  <ul> <li>Cluster-wide role binding (ClusterRoleBinding)  </li> </ul> </li> <li>RoleBinding  <ul> <li>Name: argocd-admin  </li> </ul> </li> <li>Role  <ul> <li>Role Name: cluster-admin  </li> </ul> </li> <li>Subject &gt; ServiceAccount<ul> <li>Subject namespace: openshift-gitops  </li> <li>Subject name: openshift-gitops-argocd-application-controller  </li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-37/#configure-argo-cd","title":"Configure Argo CD","text":"<p>From the Argo CD UI, click <code>NEW APP</code>, input the following parameters, and then click <code>CREATE</code>.</p> <ul> <li>GENERAL  <ul> <li>Application Name: argocd  </li> <li>Project: default  </li> <li>SYNC POLICY: Automatic  </li> </ul> </li> <li>SOURCE  <ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops  </li> <li>Revision: release-3.7  </li> <li>path: config/argocd/openshift  </li> </ul> </li> <li>DESTINATION   <ul> <li>Cluster URL: https://kubernetes.default.svc  </li> <li>Namespace: openshift-gitops  </li> </ul> </li> </ul> <p>After the Argo CD App <code>argocd</code> is created, select the App from the Argo CD UI to view the topology of all of the resources.</p>"},{"location":"how-to-deploy-cp4waiops-37/#storage-considerations","title":"Storage considerations","text":"<p>You must use a supported storage provider. For more information about supported storage, see Storage Considerations. If your Red Hat OpenShift cluster already has a single default supported storage class, then skip this step.</p> <p>Note: Multiple default storage classes cause deployment problems. Run the following command to check your cluster's storage class.</p> <pre><code>oc get sc\n</code></pre> <p>If your cluster has multiple default storage classes, then you must edit your storage classes to leave only one storage class as the default. To remove the default setting from a storage class, run the following command to edit the storage class, and then delete the <code>storageclass.kubernetes.io/is-default-class: \"true\"</code> line under <code>annotations</code>.</p> <pre><code>oc edit sc [STORAGE-CLASS-NAME]\n</code></pre> <p>This tutorial sets up and uses Ceph storage for demonstration purpose. </p> <p>From the Argo CD UI, click <code>NEW APP</code>, input the following parameters for Ceph, and then click <code>CREATE</code>.</p> <ul> <li>GENERAL<ul> <li>Application Name: ceph</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.7</li> <li>path: config/ceph</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: rook-ceph</li> </ul> </li> </ul> <p></p> <p>After the Argo CD App <code>ceph</code> is created, you can click the App from the Argo CD UI to view the topology of the Ceph resources as follows:</p> <p></p> <p>The filters on the left can be used to filter out resources. Click a resource to check its logs and events.</p> <p></p> <p>Run the following command from the command line to check that none of the pods have an error status.</p> <pre><code>[root@xyz.test.cp.fyre.ibm.com ~]# oc get po -n rook-ceph\nNAME                                                              READY   STATUS      RESTARTS   AGE\ncsi-cephfsplugin-7b6jk                                            3/3     Running     0          2d\ncsi-cephfsplugin-l7mvz                                            3/3     Running     0          2d\ncsi-cephfsplugin-provisioner-695b574445-gfcwz                     6/6     Running     6          2d\ncsi-cephfsplugin-provisioner-695b574445-lb64p                     6/6     Running     7          2d\ncsi-cephfsplugin-qcsqz                                            3/3     Running     0          2d\ncsi-cephfsplugin-qdrtl                                            3/3     Running     0          2d\ncsi-cephfsplugin-wj7qq                                            3/3     Running     0          2d\ncsi-cephfsplugin-xlsnb                                            3/3     Running     0          2d\ncsi-rbdplugin-8xwdb                                               3/3     Running     0          2d\ncsi-rbdplugin-b6t9l                                               3/3     Running     0          2d\ncsi-rbdplugin-h965f                                               3/3     Running     0          2d\ncsi-rbdplugin-lv2hp                                               3/3     Running     0          2d\ncsi-rbdplugin-pqvrc                                               3/3     Running     0          2d\ncsi-rbdplugin-provisioner-7f9847cd48-48gqk                        6/6     Running     0          2d\ncsi-rbdplugin-provisioner-7f9847cd48-wxh2z                        6/6     Running     12         2d\ncsi-rbdplugin-x8cw9                                               3/3     Running     0          2d\nrook-ceph-crashcollector-worker0.body.cp.fyre.ibm.com-88f5bnbdc   1/1     Running     0          2d\nrook-ceph-crashcollector-worker1.body.cp.fyre.ibm.com-d4c7gdcts   1/1     Running     0          2d\nrook-ceph-crashcollector-worker2.body.cp.fyre.ibm.com-7767p8fxm   1/1     Running     0          2d\nrook-ceph-crashcollector-worker3.body.cp.fyre.ibm.com-6c5cqs4lk   1/1     Running     0          2d\nrook-ceph-crashcollector-worker4.body.cp.fyre.ibm.com-787f99czf   1/1     Running     0          2d\nrook-ceph-crashcollector-worker5.body.cp.fyre.ibm.com-94d4b654q   1/1     Running     0          2d\nrook-ceph-mds-myfs-a-7d48d48497-sbhld                             1/1     Running     0          2d\nrook-ceph-mds-myfs-b-66f4b746c7-2fnl2                             1/1     Running     0          2d\nrook-ceph-mgr-a-5c84cd7b7b-574lf                                  1/1     Running     0          2d\nrook-ceph-mon-a-7b947ddf45-74p49                                  1/1     Running     0          2d\nrook-ceph-mon-b-7cf885c589-5j6r9                                  1/1     Running     0          2d\nrook-ceph-mon-c-bcb6575d8-g9l5w                                   1/1     Running     0          2d\nrook-ceph-operator-54649856c4-cdx24                               1/1     Running     0          2d\nrook-ceph-osd-0-c44985597-gwkqk                                   1/1     Running     0          2d\nrook-ceph-osd-1-6f7d5cc955-v4862                                  1/1     Running     0          2d\nrook-ceph-osd-2-58df99c46f-5kl8z                                  1/1     Running     0          2d\nrook-ceph-osd-3-5c8579456c-bpcqz                                  1/1     Running     0          2d\nrook-ceph-osd-4-5668c69fbf-kvdf6                                  1/1     Running     0          2d\nrook-ceph-osd-5-cbbdb95-cqvjd                                     1/1     Running     0          2d\nrook-ceph-osd-prepare-worker0.body.cp.fyre.ibm.com-bxr7t          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker1.body.cp.fyre.ibm.com-fftd8          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker2.body.cp.fyre.ibm.com-scg84          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker3.body.cp.fyre.ibm.com-m488b          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker4.body.cp.fyre.ibm.com-dxcm5          0/1     Completed   0          4h16m\nrook-ceph-osd-prepare-worker5.body.cp.fyre.ibm.com-jclnq          0/1     Completed   0          4h16m\n</code></pre> <p>If any of the pods are in an error state, you can check the logs by using <code>oc logs</code>.</p>"},{"location":"how-to-deploy-cp4waiops-37/#obtain-an-entitlement-key","title":"Obtain an entitlement key","text":"<p>Obtain your IBM Entitled Registry key to enable your deployment to pull images from the IBM Entitled Registry.</p> <ol> <li> <p>Obtain the entitlement key that is assigned to your IBMid. Log in to MyIBM Container Software Library with the IBMid and password details that are associated with the entitled software.</p> </li> <li> <p>In the \"Entitlement key\" section, select \"Copy key\" to copy the entitlement key to the clipboard.</p> </li> <li> <p>Copy the entitlement key to a safe place so that you can use it later when you update the global pull secret for the cluster.</p> </li> <li> <p>(Optional) Verify the validity of the key by logging in to the IBM Entitled Registry.</p> </li> </ol> <p>Depending on the container system that you are using, you might need to use <code>docker login</code> instead of <code>podman login</code> for the following command.</p> <pre><code>export IBM_ENTITLEMENT_KEY=the key from the previous steps\npodman login cp.icr.io --username cp --password \"${IBM_ENTITLEMENT_KEY:?}\"\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-37/#update-the-openshift-container-platform-global-pull-secret","title":"Update the OpenShift Container Platform global pull secret","text":"<ol> <li> <p>From the Red Hat OpenShift console, select the \"Administrator\" perspective, and then select \"Workloads &gt; Secrets\".</p> </li> <li> <p>Select the project \"openshift-config\". </p> </li> <li> <p>Select the object \"pull-secret\".</p> </li> <li> <p>Click \"Actions &gt; Edit secret\".</p> </li> <li> <p>Scroll to the end of the page and click \"Add credentials\". Use the following values:</p> <ul> <li>\"Registry Server Address\" cp.icr.io</li> <li>\"Username\": cp</li> <li>\"Password\": paste the entitlement key that you copied from the Obtain an entitlement key step</li> <li>\"Email\": email address. This field is mostly a hint to other people who might see the entry in the configuration.</li> </ul> <p>Note: The registry user for this secret is \"cp\", not the name or email of the user who owns the entitlement key.</p> </li> <li> <p>Click \"Save\".</p> </li> </ol> <p>For more information, see Update the OpenShift Container Platform global pull secret in the Red Hat OpenShift documentation.</p>"},{"location":"how-to-deploy-cp4waiops-37/#installing-ai-manager-and-event-manager-separately","title":"Installing AI Manager and Event Manager separately","text":""},{"location":"how-to-deploy-cp4waiops-37/#install-shared-components","title":"Install shared components","text":"<ul> <li>GENERAL<ul> <li>Application Name: anyname (for example: \"cp-shared\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.7</li> <li>path: config/cp-shared/operators</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: openshift-marketplace</li> </ul> </li> <li>PARAMETERS<ul> <li>spec.imageCatalog: icr.io/cpopen/ibm-operator-catalog:latest</li> <li>spec.catalogName: ibm-operator-catalog</li> <li>spec.catalogNamespace: openshift-marketplace</li> </ul> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-37/#install-ai-manager","title":"Install AI Manager","text":"<p>Install AI Manager by using GitOps to create an Argo CD App for AI Manager. The parameters for AI Manager are as follows:</p> <ul> <li>GENERAL<ul> <li>Application Name: anyname (for example: \"aimanager-app\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.7</li> <li>path: config/cp4waiops/install-aimgr</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: cp4waiops</li> </ul> </li> <li>PARAMETERS<ul> <li>spec.storageClass: rook-cephfs  (you must update this value to be the RWX storage class that is being used in your environment. You can find this by running the command <code>oc get sc</code>.)</li> <li>spec.storageClassLargeBlock: rook-cephfs  (you must update this value to be the RWO storage that is being used in your environment. You can find this by running the command <code>oc get sc</code>.)</li> <li>spec.aiManager.channel: v3.7</li> <li>spec.aiManager.size: small</li> <li>spec.aiManager.namespace: cp4waiops</li> <li>spec.aiManager.pakModules.aiopsFoundation.enabled: true</li> <li>spec.aiManager.pakModules.applicationManager.enabled: true</li> <li>spec.aiManager.pakModules.aiManager.enabled: true</li> <li>spec.aiManager.pakModules.connection.enabled: true</li> </ul> </li> </ul> <p>NOTE: If you use a repository that is forked from the official Cloud Pak for Watson AIOps GitOps repository or a different branch, then you must update the values of the <code>Repository URL</code> and <code>Revision</code> parameters to match your repository and branch. For example, if you use <code>https://github.com/&lt;myaccount&gt;/cp4waiops-gitops</code> and <code>dev</code> branch, then these two parameters must be changed.</p>"},{"location":"how-to-deploy-cp4waiops-37/#install-event-manager","title":"Install Event Manager","text":"<p>Install Event Manager by using GitOps to create an Argo CD App for Event Manager. The parameters for Event Manager are as follows:</p> <ul> <li>GENERAL<ul> <li>Application Name: anyname (for example: \"eventmanager-app\")</li> <li>Project: default</li> <li>SYNC POLICY: Automatic</li> </ul> </li> <li>SOURCE<ul> <li>Repository URL : https://github.com/IBM/cp4waiops-gitops</li> <li>Revision: release-3.7</li> <li>path: config/cp4waiops/install-emgr</li> </ul> </li> <li>DESTINATION<ul> <li>Cluster URL: https://kubernetes.default.svc</li> <li>Namespace: noi </li> </ul> </li> <li>PARAMETERS<ul> <li>spec.imageCatalog: icr.io/cpopen/ibm-operator-catalog:latest</li> <li>spec.storageClass: rook-cephfs  (you must update this value to be the RWX storage class that is being used in your environment. You can find this by running the command <code>oc get sc</code>.)</li> <li>spec.storageClassLargeBlock: rook-cephfs  (you must update this value to be the RWO storage class that is being used in your environment. You can find this by running the command <code>oc get sc</code>.)</li> <li>spec.eventManager.version: 1.6.8</li> <li>spec.eventManager.clusterDomain:  <li>spec.eventManager.channel: v1.12</li> <li>spec.eventManager.deploymentType: trial</li> <li>spec.eventManager.namespace: noi</li> <p>Where <code>&lt;domain_name&gt;</code> is the domain name of the cluster where Event Manager is installed. You must use a fully qualified domain name (FQDN). For example, <code>apps.clustername.abc.xyz.com</code>. You can retrieve the FQDN by running the following command:</p> <pre><code>INGRESS_OPERATOR_NAMESPACE=openshift-ingress-operator\nappDomain=`oc -n ${INGRESS_OPERATOR_NAMESPACE} get ingresscontrollers default -o yaml | yq .status.domain`\necho ${appDomain}\n</code></pre> <p>Note: - If you use a repository that is forked from the official Cloud Pak for Watson AIOps GitOps repository or a different branch, then you must update the values of the <code>Repository URL</code> and <code>Revision</code> parameters to match your repository and branch. For example, if you use <code>https://github.com/&lt;myaccount&gt;/cp4waiops-gitops</code> and <code>dev</code> branch, then these two parameters must be changed.</p>"},{"location":"how-to-deploy-cp4waiops-37/#verify-the-cloud-pak-for-watson-aiops-installation","title":"Verify the Cloud Pak for Watson AIOps installation","text":"<p>When Ceph and Cloud Pak for Watson AIOps are ready, you can see these Apps with a status of <code>Healthy</code> and <code>Synced</code> in the Argo CD UI.</p> <p></p> <p></p> <p>You can check the topology of Cloud Pak for Watson AIOps from the Argo CD UI as follows:</p> <p></p> <p></p> <p>You can also check your Cloud Pak for Watson AIOps installation from the command line. For example, to check the AI Manager pods, run the following command:</p> <pre><code># oc get po -n cp4waiops\nNAME                                                              READY   STATUS      RESTARTS        AGE\naimanager-aio-ai-platform-api-server-7d48c6dd89-6bn9t             1/1     Running     0               3h33m\naimanager-aio-change-risk-bd78c587c-fhg67                         1/1     Running     0               3h33m\naimanager-aio-chatops-orchestrator-6d897b4497-7xjwt               1/1     Running     0               3h33m\naimanager-aio-chatops-slack-integrator-5b8dcb9785-flcs9           1/1     Running     0               3h33m\naimanager-aio-chatops-teams-integrator-8d586fc7f-h5bpg            1/1     Running     0               3h33m\naimanager-aio-controller-5f7d877f-9zxfj                           1/1     Running     0               3h33m\naimanager-aio-cr-api-865c8f8f85-bthhw                             1/1     Running     0               3h33m\naimanager-aio-create-certificate-k9zmp                            0/1     Completed   0               3h36m\naimanager-aio-create-luigi-prereqs-glmrz                          0/1     Completed   0               3h33m\naimanager-aio-create-postgres-database-68j48                      0/1     Completed   0               3h35m\naimanager-aio-create-secrets-lkd69                                0/1     Completed   0               3h35m\naimanager-aio-create-truststore-k66d8                             0/1     Completed   0               3h34m\naimanager-aio-curator-job-28004340-sp9sl                          0/1     Completed   0               178m\naimanager-aio-curator-job-28004400-qt45t                          0/1     Completed   0               118m\naimanager-aio-curator-job-28004460-4phlp                          0/1     Completed   0               58m\naimanager-aio-log-anomaly-detector-6bc99f9988-kj6kh               1/1     Running     0               3h33m\naimanager-aio-log-anomaly-detector-6bc99f9988-mf8kb               1/1     Running     0               3h33m\naimanager-aio-log-anomaly-feedback-learning-6d848588c7-9ptg7      1/1     Running     0               3h33m\naimanager-aio-luigi-daemon-0                                      1/1     Running     0               3h33m\naimanager-aio-oob-recommended-actions-f6fd5465d-dzhqv             1/1     Running     0               3h33m\naimanager-aio-pruning-job-28004340-6f94t                          0/1     Completed   0               178m\naimanager-aio-pruning-job-28004400-z9xm2                          0/1     Completed   0               118m\naimanager-aio-pruning-job-28004460-p5j2b                          0/1     Completed   0               58m\naimanager-aio-similar-incidents-service-68597967fb-s7jbg          1/1     Running     0               3h33m\naimanager-ibm-minio-0                                             1/1     Running     0               3h33m\naimanager-operator-controller-manager-c49879bc-w69md              1/1     Running     0               4h33m\naiops-ai-model-ui-7bcff98898-j7x9q                                1/1     Running     0               4h7m\naiops-akora-ui-7c4f67dc8f-dvdw6                                   1/1     Running     0               4h2m\naiops-application-details-ui-api-56655575f-whz6w                  1/1     Running     0               4h2m\naiops-base-ui-5596f5dbf9-d8rmj                                    1/1     Running     0               4h6m\naiops-connections-ui-589b76885-qtkl5                              1/1     Running     0               4h7m\naiops-insights-pg-setup-bvnsv                                     0/1     Completed   0               3h50m\naiops-insights-ui-api-6cfbf4779c-5n2hj                            1/1     Running     0               3h50m\naiops-insights-ui-datarouting-7dfdf6c5bc-xc8sn                    1/1     Running     1 (3h45m ago)   3h50m\naiops-insights-ui-f9fc67876-lk4fz                                 1/1     Running     0               4h7m\naiops-installation-edb-postgres-1                                 1/1     Running     0               4h33m\naiops-ir-analytics-cassandra-setup-96mhh                          0/1     Completed   0               3h48m\naiops-ir-analytics-classifier-5f78f877db-nrgf8                    1/1     Running     0               3h38m\naiops-ir-analytics-metric-action-8658f45c78-kncld                 1/1     Running     2 (3h30m ago)   3h37m\naiops-ir-analytics-metric-api-6796c5594b-ctw84                    1/1     Running     0               3h38m\naiops-ir-analytics-metric-spark-59c45f6b55-zv4pr                  1/1     Running     0               3h38m\naiops-ir-analytics-probable-cause-initialisation-lrftt            0/3     Completed   0               3h45m\naiops-ir-analytics-probablecause-84c7d88f48-ldlzf                 1/1     Running     0               3h37m\naiops-ir-analytics-spark-master-75bbc97cc-dwgr5                   1/1     Running     0               3h37m\naiops-ir-analytics-spark-pipeline-composer-7ccf698df8-xskx9       1/1     Running     1 (3h31m ago)   3h37m\naiops-ir-analytics-spark-worker-0                                 1/1     Running     0               3h37m\naiops-ir-analytics-spark-worker-1                                 1/1     Running     0               3h33m\naiops-ir-analytics-xiny-initialisation-2dlvj                      0/1     Completed   0               3h38m\naiops-ir-core-archiving-7f9d8d9fb7-shz2z                          1/1     Running     0               3h36m\naiops-ir-core-archiving-setup-264bx                               0/1     Completed   0               3h47m\naiops-ir-core-cem-users-7b7748cfbd-4j8fq                          1/1     Running     0               3h36m\naiops-ir-core-datarouting-5f744668b5-xflcb                        1/1     Running     0               3h36m\naiops-ir-core-esarchiving-5bc58f5c64-7glrr                        1/1     Running     0               3h36m\naiops-ir-core-ncobackup-0                                         2/2     Running     0               3h37m\naiops-ir-core-ncodl-api-84f6697d4d-b4s7h                          1/1     Running     0               3h36m\naiops-ir-core-ncodl-cjob-tdata-28004460-xm7k6                     0/1     Completed   0               58m\naiops-ir-core-ncodl-if-d76449d68-25qb4                            1/1     Running     0               3h36m\naiops-ir-core-ncodl-jobmgr-669bf484cd-crvgk                       1/1     Running     0               3h36m\naiops-ir-core-ncodl-presetup-2bwtx                                0/1     Completed   0               3h47m\naiops-ir-core-ncodl-setup-hts29                                   0/1     Completed   0               3h34m\naiops-ir-core-ncodl-std-576558c484-8blgp                          1/1     Running     0               3h36m\naiops-ir-core-ncoprimary-0                                        1/1     Running     0               3h40m\naiops-ir-core-rba-as-864d9596f9-lpgv6                             1/1     Running     0               3h36m\naiops-ir-core-rba-rbs-7f7d4fb4c-pwxs4                             1/1     Running     0               3h36m\naiops-ir-core-usercfg-5ddbdfc9c4-h6njm                            1/1     Running     0               3h36m\naiops-ir-core-usercfg-presetup-6p7fz                              0/1     Completed   0               3h47m\naiops-ir-lifecycle-create-policies-job-x526x                      0/1     Completed   0               3h43m\naiops-ir-lifecycle-datarouting-66cf4cd87-xtk5w                    1/1     Running     0               3h43m\naiops-ir-lifecycle-eventprocessor-ep-jobmanager-0                 2/2     Running     0               3h45m\naiops-ir-lifecycle-eventprocessor-ep-taskmanager-0                1/1     Running     0               3h44m\naiops-ir-lifecycle-policy-grpc-svc-7cd87f4644-nhsc9               1/1     Running     0               3h39m\naiops-ir-lifecycle-policy-registry-svc-7ccf749948-klxw5           1/1     Running     1 (3h40m ago)   3h43m\naiops-ir-lifecycle-policy-registry-svc-job-4tggl                  0/1     Completed   0               3h43m\naiops-ir-ui-api-graphql-dc6896488-4ccvh                           1/1     Running     0               4h2m\naiops-topology-cassandra-0                                        1/1     Running     0               3h48m\naiops-topology-cassandra-auth-secret-generator-f5ns6              0/1     Completed   0               3h49m\naiops-topology-file-observer-6f6586649b-mfzf7                     1/1     Running     0               3h30m\naiops-topology-inventory-5ddfb9fbd5-2bhgc                         1/1     Running     0               3h30m\naiops-topology-inventory-schema-bdtqh                             0/1     Completed   0               3h33m\naiops-topology-kubernetes-observer-d7bc69989-wz7l9                1/1     Running     0               3h30m\naiops-topology-layout-7dcd79b585-57ls4                            1/1     Running     0               3h30m\naiops-topology-merge-f579ddc98-2mh99                              1/1     Running     0               3h30m\naiops-topology-observer-service-769cbcb68d-4hrwc                  1/1     Running     0               3h30m\naiops-topology-rest-observer-666cc7b874-wtb2p                     1/1     Running     0               3h30m\naiops-topology-servicenow-observer-546c86fff4-dtzvm               1/1     Running     0               3h30m\naiops-topology-sevone-observer-7cc9954459-x96c9                   1/1     Running     0               3h30m\naiops-topology-status-668cf96f65-7v4c9                            1/1     Running     0               3h30m\naiops-topology-topology-74c6c6864c-cjtjk                          1/1     Running     0               3h30m\naiops-topology-ui-api-d5bcd664f-n69zc                             1/1     Running     0               3h30m\naiops-topology-vmvcenter-observer-854b549747-fvrlf                1/1     Running     0               3h30m\naiopsedge-instana-topology-integrator-867db845b8-lsvg6            1/1     Running     0               3h50m\naiopsedge-operator-controller-manager-58885dd575-dck2k            1/1     Running     2 (4h24m ago)   4h33m\naiopsedge-operator-controller-manager-58885dd575-qscdq            1/1     Running     2 (4h27m ago)   4h33m\nasm-operator-9966456b8-mtmk8                                      1/1     Running     0               4h33m\nc-example-couchdbcluster-m-0                                      2/2     Running     0               3h43m\nc-example-redis-m-0                                               4/4     Running     0               4h31m\nc-example-redis-m-1                                               4/4     Running     0               4h31m\nc-example-redis-m-2                                               4/4     Running     0               4h31m\nc-example-redis-s-0                                               4/4     Running     0               4h26m\nc-example-redis-s-1                                               4/4     Running     0               4h26m\nc-example-redis-s-2                                               4/4     Running     0               4h26m\ncheck-aiops-prereqs-7bdpz                                         0/1     Completed   0               4h43m\nconfigure-aiops-network-policy-q4qqb                              0/1     Completed   0               4h42m\nconnector-bridge-58ccbf8cd4-8hhkr                                 1/1     Running     1 (3h48m ago)   3h50m\nconnector-manager-d8649b9c9-bvjc6                                 1/1     Running     0               4h21m\nconnector-orchestrator-56b78565cc-nlqq9                           1/1     Running     0               3h50m\ncp4waiops-connectors-deploy-69784d7658-h2wjg                      1/1     Running     0               4h22m\ncp4waiops-eventprocessor-eve-29ee-ep-jobmanager-0                 2/2     Running     0               3h28m\ncp4waiops-eventprocessor-eve-29ee-ep-taskmanager-0                1/1     Running     0               3h28m\ncp4waiops-metricsprocessor-789fccfc47-9x2q5                       1/1     Running     0               4h21m\ncreate-secrets-job-sjckp                                          0/1     Completed   0               4h28m\ngateway-kong-config-svc-28004510-6j4n5                            0/1     Completed   0               8m28s\ngateway-kong-f999c794b-7mlzs                                      2/2     Running     0               4h31m\ngateway-kong-post-install-resources-5b554                         0/1     Completed   0               4h31m\niaf-core-operator-controller-manager-568cfb459b-2czwd             1/1     Running     0               4h40m\niaf-eventprocessing-operator-controller-manager-6b6f6f758cvxb68   1/1     Running     1 (4h37m ago)   4h40m\niaf-flink-operator-controller-manager-b7b9ccb99-jb75p             1/1     Running     0               4h40m\niaf-operator-controller-manager-bc6458cf5-wcn84                   1/1     Running     0               4h40m\niaf-system-elasticsearch-es-aiops-0                               2/2     Running     0               4h22m\niaf-system-entity-operator-5fc7c64f56-xrh7d                       3/3     Running     0               4h18m\niaf-system-kafka-0                                                1/1     Running     0               4h20m\niaf-system-zookeeper-0                                            1/1     Running     0               4h23m\niaf-zen-tour-job-xbb96                                            0/1     Completed   0               3h53m\niam-config-job-7cxv8                                              0/1     Completed   0               4h\nibm-aiops-orchestrator-controller-manager-54688c665-p2fkb         1/1     Running     0               4h38m\nibm-cloud-databases-redis-operator-8b8978d84-h74rb                1/1     Running     0               4h33m\nibm-common-service-operator-7664b948b8-cwlz6                      1/1     Running     1 (4h40m ago)   4h40m\nibm-elastic-operator-controller-manager-f98ffdd48-mrrdf           1/1     Running     0               4h40m\nibm-ir-ai-operator-controller-manager-7776894cb5-jldzv            1/1     Running     0               4h33m\nibm-kong-operator-57f47b648d-d47ql                                1/1     Running     0               4h33m\nibm-nginx-cdd99b479-lkx6h                                         1/1     Running     0               3h54m\nibm-nginx-cdd99b479-tf9nm                                         1/1     Running     0               3h54m\nibm-nginx-tester-6676c6b8c6-dsk2s                                 1/1     Running     0               4h4m\nibm-secure-tunnel-operator-57d7766796-h7xmv                       1/1     Running     0               4h33m\nibm-vault-deploy-consul-0                                         1/1     Running     0               4h21m\nibm-vault-deploy-vault-0                                          1/1     Running     0               4h21m\nibm-vault-deploy-vault-injector-5d86877867-7dntk                  1/1     Running     0               4h21m\nibm-vault-operator-controller-manager-fdcf4b74d-g4gxj             1/1     Running     0               4h28m\nibm-watson-aiops-ui-operator-controller-manager-8fb86db7b-cdf6n   1/1     Running     11 (4h8m ago)   4h33m\nir-core-operator-controller-manager-64d9777669-qq94s              1/1     Running     0               4h33m\nir-lifecycle-operator-controller-manager-69bdd94544-5nsgt         1/1     Running     0               4h33m\npost-aiops-resources-d9nqp                                        0/1     Completed   0               4h7m\npost-aiops-translations-qmpb5                                     0/1     Completed   0               4h7m\npost-aiops-update-user-role-csbwc                                 0/1     Completed   2               4h7m\nsetup-nginx-job-26rql                                             0/1     Completed   0               4h11m\nsre-tunnel-controller-0                                           1/1     Running     0               4h26m\nsre-tunnel-tunnel-network-api-7c6596d94f-g4sbb                    1/1     Running     0               4h29m\nsre-tunnel-tunnel-ui-mcmtunnelui-7877465766-lgzph                 1/1     Running     0               4h29m\nusermgmt-6b976464f-6vf76                                          1/1     Running     0               4h\nusermgmt-6b976464f-mrv8z                                          1/1     Running     0               4h\nzen-audit-59ff87c7dc-fwwbj                                        1/1     Running     0               4h8m\nzen-core-7fd5cff5c6-2ppfz                                         1/1     Running     0               4h8m\nzen-core-7fd5cff5c6-f8pww                                         1/1     Running     0               4h8m\nzen-core-api-55594899d7-d2p95                                     1/1     Running     0               4h8m\nzen-core-api-55594899d7-ndd6t                                     1/1     Running     0               4h8m\nzen-metastoredb-0                                                 1/1     Running     0               4h19m\nzen-metastoredb-1                                                 1/1     Running     0               4h19m\nzen-metastoredb-2                                                 1/1     Running     0               4h19m\nzen-metastoredb-certs-xxx6g                                       0/1     Completed   0               4h24m\nzen-metastoredb-init-c4j2p                                        0/1     Completed   0               4h19m\nzen-pre-requisite-job-xm8cf                                       0/1     Completed   0               4h11m\nzen-watcher-9f8b6c975-tlvcc                                       1/1     Running     0               4h8m\n</code></pre> <p>If any pods are in an error state, you can check the logs from the Argo CD UI, or you can run <code>oc logs</code> from the command line.</p>"},{"location":"how-to-deploy-cp4waiops-37/#access-cloud-pak-for-watson-aiops","title":"Access Cloud Pak for Watson AIOps","text":"<p>If all of the pods for Cloud Pak for Watson AIOps are up and running, then you can log in to the Cloud Pak for Watson AIOps UI as follows.</p> <p>Log in to the Red Hat OpenShift console, and then click the drop-down menu on the upper right.</p> <p></p> <p>Click the <code>IBM Cloud Pak for Administration</code> link, and select <code>OpenShift authentication</code>.</p> <p></p> <p>Log in to <code>IBM Cloud Pak for Administration</code>, click the drop-down menu on the upper right, and then select <code>IBM Automation (cp4waiops)</code>.</p> <p></p> <p>Log in to the Cloud Pak for Watson AIOps UI and then select <code>OpenShift authentication</code>.</p> <p></p> <p>The Cloud Pak for Watson AIOps user interface is displayed.</p> <p></p> <p>Congratulations! You are ready to play with Cloud Pak for Watson AIOps!</p>"},{"location":"how-to-deploy-cp4waiops-37/#installing-cloud-pak-for-watson-aiops-from-the-command-line","title":"Installing Cloud Pak for Watson AIOps from the command line","text":""},{"location":"how-to-deploy-cp4waiops-37/#log-in-to-argo-cd-cli","title":"Log in to Argo CD (CLI)","text":"<p>Make sure that the Argo CD CLI (<code>argocd</code> command) is installed. For more information, see the Argo documentation.</p> <p>Then, run the following commands to log in to Argo CD:</p> <pre><code>argo_route=openshift-gitops-server\nargo_secret=openshift-gitops-cluster\nsa_account=openshift-gitops-argocd-application-controller\n\nargo_pwd=$(oc get secret ${argo_secret} \\\n-n openshift-gitops \\\n-o jsonpath='{.data.admin\\.password}' | base64 -d ; echo ) \\\n&amp;&amp; argo_url=$(oc get route ${argo_route} \\\n-n openshift-gitops \\\n-o jsonpath='{.spec.host}') \\\n&amp;&amp; argocd login \"${argo_url}\" \\\n--username admin \\\n--password \"${argo_pwd}\" \\\n--insecure\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-37/#grant-argo-cd-cluster-admin-permission-cli","title":"Grant Argo CD cluster admin permission (CLI)","text":"<p>Apply the following YAML manifest to the cluster where Argo CD runs:</p> <pre><code>kind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\nname: argocd-admin\nsubjects:\n- kind: ServiceAccount\nname: openshift-gitops-argocd-application-controller\nnamespace: openshift-gitops\nroleRef:\napiGroup: rbac.authorization.k8s.io\nkind: ClusterRole\nname: cluster-admin\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-37/#storage-considerations-cli","title":"Storage considerations (CLI)","text":"<p>You must use a supported storage provider. For more information about supported storage, see Storage Considerations. If your Red Hat OpenShift cluster already has a single default supported storage class, then skip this step.</p> <p>Note: Multiple default storage classes cause deployment problems. Run the following command to check your cluster's storage class.</p> <pre><code>oc get sc\n</code></pre> <p>If your cluster has multiple default storage classes, then you must edit your storage classes to leave only one storage class as the default. To remove the default setting from a storage class, run the following command to edit the storage class, and then delete the <code>storageclass.kubernetes.io/is-default-class: \"true\"</code> line under <code>annotations</code>.</p> <pre><code>oc edit sc [STORAGE-CLASS-NAME]\n</code></pre> <p>This tutorial sets up and uses Ceph storage for demonstration purpose. </p> <p>To create an Argo CD App for Ceph storage, run the following command:</p> <pre><code>argocd app create ceph \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/ceph \\\n--revision release-3.7 \\\n--dest-namespace rook-ceph \\\n--dest-server https://kubernetes.default.svc\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-37/#obtain-an-entitlement-key-cli","title":"Obtain an entitlement key (CLI)","text":"<p>Obtain your IBM Entitled Registry key to enable your deployment to pull images from the IBM Entitled Registry.</p> <ol> <li> <p>Obtain the entitlement key that is assigned to your IBMid. Log in to MyIBM Container Software Library with the IBMid and password details that are associated with the entitled software.</p> </li> <li> <p>In the \"Entitlement key\" section, select \"Copy key\" to copy the entitlement key to the clipboard.</p> </li> <li> <p>Copy the entitlement key to a safe place so that you can use it later when you update the global pull secret for the cluster.</p> </li> <li> <p>(Optional) Verify the validity of the key by logging in to the IBM Entitled Registry.</p> </li> </ol> <p>Depending on the container system that you are using, you might need to use <code>docker login</code> instead of <code>podman login</code> for the following command.</p> <pre><code>export IBM_ENTITLEMENT_KEY=the key from the previous steps\npodman login cp.icr.io --username cp --password \"${IBM_ENTITLEMENT_KEY:?}\"\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-37/#update-the-openshift-container-platform-global-pull-secret-cli","title":"Update the OpenShift Container Platform global pull secret (CLI)","text":"<p>Run the following command to create the entitlement key pull secret:</p> <pre><code>oc create secret docker-registry ibm-entitlement-key \\\n    --docker-username=cp \\\n    --docker-password=&lt;entitlement-key&gt; \\\n    --docker-server=cp.icr.io \\\n    --namespace=cp4waiops\n</code></pre> <p>Where <code>&lt;entitlement-key&gt;</code> is the entitlement key that you copied in the previous step.</p>"},{"location":"how-to-deploy-cp4waiops-37/#installing-ai-manager-and-event-manager-separately-cli","title":"Installing AI Manager and Event Manager separately (CLI)","text":""},{"location":"how-to-deploy-cp4waiops-37/#install-shared-components-cli","title":"Install shared components (CLI)","text":"<pre><code>argocd app create cp-shared \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/cp-shared/operators \\\n--revision release-3.7 \\\n--dest-namespace openshift-marketplace \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.imageCatalog=icr.io/cpopen/ibm-operator-catalog:latest \\\n--helm-set spec.catalogName=ibm-operator-catalog \\\n--helm-set spec.catalogNamespace=openshift-marketplace\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-37/#install-ai-manager-cli","title":"Install AI Manager (CLI)","text":"<p>Run the following command to install AI Manager by using GitOps to create an Argo CD App for AI Manager.</p> <pre><code>argocd app create aimanager-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/cp4waiops/install-aimgr \\\n--revision release-3.7 \\\n--dest-namespace cp4waiops \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.storageClass=rook-cephfs \\\n--helm-set spec.storageClassLargeBlock=rook-cephfs \\\n--helm-set spec.aiManager.namespace=cp4waiops \\\n--helm-set spec.aiManager.channel=v3.7 \\\n--helm-set spec.aiManager.size=small \\\n--helm-set spec.aiManager.pakModules.aiopsFoundation.enabled=true \\\n--helm-set spec.aiManager.pakModules.applicationManager.enabled=true \\\n--helm-set spec.aiManager.pakModules.aiManager.enabled=true \\\n--helm-set spec.aiManager.pakModules.connection.enabled=true\n</code></pre> <p>Important: You must update the values of spec.storageClass and storageClassLargeBlock to be the RWX and RWO storage classes that are being used in your environment. You can find this by running the command <code>oc get sc</code>.</p>"},{"location":"how-to-deploy-cp4waiops-37/#install-event-manager-cli","title":"Install Event Manager (CLI)","text":"<p>Run the following command to install Event Manager by using GitOps to create an Argo CD App for Event Manager.</p> <pre><code>argocd app create eventmanager-app \\\n--sync-policy automatic \\\n--project default \\\n--repo https://github.com/IBM/cp4waiops-gitops.git \\\n--path config/cp4waiops/install-emgr \\\n--revision release-3.7 \\\n--dest-namespace noi \\\n--dest-server https://kubernetes.default.svc \\\n--helm-set spec.imageCatalog=icr.io/cpopen/ibm-operator-catalog:latest \\\n--helm-set spec.storageClass=rook-cephfs \\\n--helm-set spec.storageClassLargeBlock=rook-cephfs \\\n--helm-set spec.eventManager.namespace=noi \\\n--helm-set spec.eventManager.channel=v1.12 \\\n--helm-set spec.eventManager.version=1.6.8 \\\n--helm-set spec.eventManager.clusterDomain=&lt;domain_name&gt; \\\n--helm-set spec.eventManager.deploymentType=trial\n</code></pre> <p>Important: - You must update the values of spec.storageClass and storageClassLargeBlock to be the RWX and RWO storage classes that are being used in your environment. You can find this by running the command <code>oc get sc</code>. - <code>&lt;domain_name&gt;</code> must be the domain name of the cluster where Event Manager is installed. Use a fully qualified domain name (FQDN). For example, <code>apps.clustername.abc.xyz.com</code>. You can also retrieve the FDQN by running the following command:</p> <pre><code>INGRESS_OPERATOR_NAMESPACE=openshift-ingress-operator\nappDomain=`oc -n ${INGRESS_OPERATOR_NAMESPACE} get ingresscontrollers default -o yaml | yq .status.domain`\necho ${appDomain}\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-37/#verify-the-cloud-pak-for-watson-aiops-installation-cli","title":"Verify the Cloud Pak for Watson AIOps installation (CLI)","text":"<p>Run the following command to verify that the Cloud Pak for Watson AIOps installation was successful:</p> <pre><code>oc get application -A\n</code></pre> <p>Example output from a successful installation:</p> <pre><code># oc get application -A\nNAMESPACE          NAME                      SYNC STATUS   HEALTH STATUS\nopenshift-gitops   cp4waiops                 Synced        Healthy\nopenshift-gitops   in-cluster-aimanager      Synced        Healthy\nopenshift-gitops   in-cluster-eventmanager   Synced        Healthy\nopenshift-gitops   in-cluster-rook-ceph      Synced        Healthy\n</code></pre> <p>Wait for a while and then run the following commands to verify that all of the pods in the <code>cp4waiops</code> and <code>noi</code> namespaces are running.</p> <pre><code>oc get pod -n cp4waiops\noc get pod -n noi\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-37/#access-cloud-pak-for-watson-aiops-cli","title":"Access Cloud Pak for Watson AIOps (CLI)","text":"<p>If all of the pods for Cloud Pak for Watson AIOps are up and running, then you can log in to the Cloud Pak for Watson AIOps UI as follows.</p> <p>Log in to the Red Hat OpenShift console, and then click the drop-down menu on the upper right.</p> <p></p> <p>Click the <code>IBM Cloud Pak for Administration</code> link, and select <code>OpenShift authentication</code>.</p> <p></p> <p>Log in to <code>IBM Cloud Pak for Administration</code>, click the drop-down menu on the upper right, and then select <code>IBM Automation (cp4waiops)</code>.</p> <p></p> <p>Log in to the Cloud Pak for Watson AIOps UI and then select <code>OpenShift authentication</code>.</p> <p></p> <p>The Cloud Pak for Watson AIOps user interface is displayed.</p> <p></p> <p>Congratulations! You are ready to play with Cloud Pak for Watson AIOps!</p>"},{"location":"how-to-deploy-cp4waiops-37/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to-deploy-cp4waiops-37/#storage","title":"Storage","text":""},{"location":"how-to-deploy-cp4waiops-37/#problem","title":"Problem","text":"<p>Ceph pod reports the following error:</p> <p><code>cephosd: failed to lookup binary path \"/rootfs/usr/sbin/lvm\" on the host rootfs</code>.</p>"},{"location":"how-to-deploy-cp4waiops-37/#cause","title":"Cause","text":"<p>This problem is caused by missing lvm2 support. For more information, see issue 6705.</p>"},{"location":"how-to-deploy-cp4waiops-37/#solution","title":"Solution","text":"<p>Install lvm2 on all Red Hat OpenShift nodes.</p>"},{"location":"how-to-deploy-cp4waiops-daily-build/","title":"How to deploy cp4waiops daily build","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Deploy CP4WAIOps daily build using GitOps</li> <li></li> </ul>"},{"location":"how-to-deploy-cp4waiops-daily-build/#deploy-cp4waiops-daily-build-using-gitops","title":"Deploy CP4WAIOps daily build using GitOps","text":""},{"location":"how-to-deploy-cp4waiops-daily-build/#_1","title":"How to deploy cp4waiops daily build","text":"<p>The procedure for deploying CP4WAIOps with daily build is very similar compare to deploying with GAed build, you can follow the Deploy Cloud Pak for Watson AIOps using GitOps guide to deploy CP4WAIOps with daily build, the only differences are in 3 places. - First, in the update the OCP global pull secret instruction here, need to add build repository credential. you can find the build repository and catalog image info here    - \"Registry Server Address\": [build repository]     - \"Username\": [Your Email address]    - \"Password\": paste the api token of the account above    - \"Email\": any email, valid or not, will work. This fields is mostly a hint to other people who may see the entry in the configuration  </p> <p>You can test the build repository credential using docker command below. <pre><code>docker login [build repository] -u [Your Email address] -p [API Token]\ndocker pull [catalog image]\n</code></pre> - Second, under Install shared components, need to use build catalog image instead of GA catalog for <code>spec.imageCatalog</code>. please check daily build instruction here to obtain build catalog image link. For Cli deployment, need to replace <code>spec.imageCatalog</code> in the Cli command under Install shared components (Cli)</p> <ul> <li>Third, under Install AI Manager, need to use daily build dev channel instead, for <code>spec.aiManager.channel</code> . please check daily build instruction here to obtain daily build dev channel name. for Cli deployment, need to replace <code>spec.aiManager.channel</code> in the Cli command under Install AI Manager (Cli)</li> </ul>"},{"location":"how-to-deploy-cp4waiops-upgrade-from-previous/","title":"How to deploy cp4waiops upgrade from previous","text":"<p>Table of Contents generated with DocToc</p> <ul> <li>Upgrade CP4WAIOps From Previous Version using GitOps</li> <li>Prerequisite</li> <li>Upgrade CP4WAIOps from UI<ul> <li>Login to Argo CD</li> <li>Upgrade AI Manager from Application Dashboard</li> </ul> </li> <li>Upgrade CP4WAIOps from Command Line<ul> <li>Login to Argo CD (Cli)</li> <li>Verify Argo CD (Cli)</li> <li>Upgrade AI Manager (Cli)</li> </ul> </li> <li>Verify Upgrade Result</li> </ul>"},{"location":"how-to-deploy-cp4waiops-upgrade-from-previous/#upgrade-cp4waiops-from-previous-version-using-gitops","title":"Upgrade CP4WAIOps From Previous Version using GitOps","text":""},{"location":"how-to-deploy-cp4waiops-upgrade-from-previous/#prerequisite","title":"Prerequisite","text":"<ul> <li>To learn CP4WAIOps system requirement, please refer to System requirements for Cloud Pak for Watson AIOps.</li> <li>The upgrade method here is suitable for CP4WAIOps previous installed using gitops.</li> </ul>"},{"location":"how-to-deploy-cp4waiops-upgrade-from-previous/#upgrade-cp4waiops-from-ui","title":"Upgrade CP4WAIOps from UI","text":""},{"location":"how-to-deploy-cp4waiops-upgrade-from-previous/#login-to-argo-cd","title":"Login to Argo CD","text":"<p>You can now login to Argo CD UI as follows by clicking the drop down menu on top right. </p> <p>Argo CD UI will be popped up and you can login using <code>LOG IN VIA OPENSHIFT</code>.  </p> <p></p>"},{"location":"how-to-deploy-cp4waiops-upgrade-from-previous/#upgrade-ai-manager-from-application-dashboard","title":"Upgrade AI Manager from Application Dashboard","text":"<ul> <li>Click on the AI Manager application <code>aimanager-app</code></li> <li>Click on the <code>APP DETAILS</code> button on the top of the screen: </li> <li>Select <code>PARAMETERS</code> tab</li> <li>Click on <code>EDIT</code></li> <li>Update the \"spec.aiManager.channel\" value to <code>v3.4</code></li> <li>Click on <code>SAVE</code> </li> </ul>"},{"location":"how-to-deploy-cp4waiops-upgrade-from-previous/#upgrade-cp4waiops-from-command-line","title":"Upgrade CP4WAIOps from Command Line","text":""},{"location":"how-to-deploy-cp4waiops-upgrade-from-previous/#login-to-argo-cd-cli","title":"Login to Argo CD (Cli)","text":"<p>Make sure you have installed Argo CD CLI, i.e.: the <code>argocd</code> command, then run following commands to login to Argo CD:</p> <pre><code>argo_route=openshift-gitops-server\nargo_secret=openshift-gitops-cluster\nsa_account=openshift-gitops-argocd-application-controller\n\nargo_pwd=$(kubectl get secret ${argo_secret} \\\n-n openshift-gitops \\\n-o jsonpath='{.data.admin\\.password}' | base64 -d ; echo ) \\\n&amp;&amp; argo_url=$(kubectl get route ${argo_route} \\\n-n openshift-gitops \\\n-o jsonpath='{.spec.host}') \\\n&amp;&amp; argocd login \"${argo_url}\" \\\n--username admin \\\n--password \"${argo_pwd}\" \\\n--insecure\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-upgrade-from-previous/#verify-argo-cd-cli","title":"Verify Argo CD (Cli)","text":"<pre><code>argocd app list\n</code></pre> <p>The output should shows the previous installed CP4WAIOps version. <pre><code>NAME           CLUSTER                         NAMESPACE              PROJECT  STATUS  HEALTH   SYNCPOLICY  CONDITIONS  REPO                                     PATH                            TARGET\naimanager-app  https://kubernetes.default.svc  cp4waiops              default  Synced  Healthy  Auto        &lt;none&gt;      https://github.com/IBM/cp4waiops-gitops  config/cp4waiops/install-aimgr  release-3.3\nceph           https://kubernetes.default.svc  rook-ceph              default  Synced  Healthy  Auto        &lt;none&gt;      https://github.com/IBM/cp4waiops-gitops  config/ceph                     release-3.3\ncp-shared      https://kubernetes.default.svc  openshift-marketplace  default  Synced  Healthy  Auto        &lt;none&gt;      https://github.com/IBM/cp4waiops-gitops  config/cp-shared/operators      release-3.3\n</code></pre> NOTE:</p> <p>The results may not contains application <code>cp-shared</code>, no need to worry about it.  </p>"},{"location":"how-to-deploy-cp4waiops-upgrade-from-previous/#upgrade-ai-manager-cli","title":"Upgrade AI Manager (Cli)","text":"<pre><code>argocd app set aimanager-app -p spec.aiManager.channel=v3.4\nargocd app sync aimanager-app\n</code></pre>"},{"location":"how-to-deploy-cp4waiops-upgrade-from-previous/#verify-upgrade-result","title":"Verify Upgrade Result","text":"<p>The upgrade process will take a while, it will largely depends on the network performance. After upgrade completed, all pod should be in running status and ready.  </p> <p>Use command line to check CSV details. <pre><code>oc get csv -n cp4waiops\n</code></pre></p> <p>The output should be looking like below: <pre><code>NAME                                               DISPLAY                                            VERSION              REPLACES                                PHASE\naimanager-operator.v3.4.0                          IBM Watson AIOps AI Manager                        3.4.0                aimanager-operator.v3.3.2               Succeeded\naiopsedge-operator.v3.4.0                          IBM Watson AIOps Edge                              3.4.0                aiopsedge-operator.v3.3.2               Succeeded\nasm-operator.v3.4.0                                IBM Netcool Agile Service Manager                  3.4.0                asm-operator.v3.3.2                     Succeeded\ncouchdb-operator.v2.2.1                            Operator for Apache CouchDB                        2.2.1                couchdb-operator.v2.2.0                 Succeeded\nibm-aiops-ir-ai.v3.4.0                             IBM Watson AIOps Issue Resolution AI &amp; Analytics   3.4.0                ibm-aiops-ir-ai.v3.3.2                  Succeeded\nibm-aiops-ir-core.v3.4.0                           IBM Watson AIOps Issue Resolution Core             3.4.0                ibm-aiops-ir-core.v3.3.2                Succeeded\nibm-aiops-ir-lifecycle.v3.4.0                      IBM Cloud Pak for Watson AIOps Lifecycle           3.4.0                ibm-aiops-ir-lifecycle.v3.3.2           Succeeded\nibm-aiops-orchestrator.v3.4.0                      IBM Cloud Pak for Watson AIOps AI Manager          3.4.0                ibm-aiops-orchestrator.v3.3.2           Succeeded\nibm-automation-core.v1.3.7                         IBM Automation Foundation Core                     1.3.7                ibm-automation-core.v1.3.6              Succeeded\nibm-automation-elastic.v1.3.6                      IBM Elastic                                        1.3.6                ibm-automation-elastic.v1.3.5           Succeeded\nibm-automation-eventprocessing.v1.3.7              IBM Automation Foundation Event Processing         1.3.7                ibm-automation-eventprocessing.v1.3.6   Succeeded\nibm-automation-flink.v1.3.6                        IBM Automation Foundation Flink                    1.3.6                ibm-automation-flink.v1.3.5             Succeeded\nibm-automation.v1.3.7                              IBM Automation Foundation                          1.3.7                ibm-automation.v1.3.6                   Succeeded\nibm-cloud-databases-redis.v1.4.3                   IBM Operator for Redis                             1.4.3                ibm-cloud-databases-redis.v1.4.2        Succeeded\nibm-common-service-operator.v3.18.0                IBM Cloud Pak foundational services                3.18.0               ibm-common-service-operator.v3.17.0     Succeeded\nibm-management-kong.v3.4.0                         IBM Internal - IBM Watson AIOps Kong               3.4.0                ibm-management-kong.v3.3.2              Succeeded\nibm-postgreservice-operator.v3.4.0                 IBM Postgreservice                                 3.4.0                ibm-postgreservice-operator.v3.3.2      Succeeded\nibm-secure-tunnel-operator.v3.4.0                  IBM Secure Tunnel                                  3.4.0                ibm-secure-tunnel-operator.v3.3.2       Succeeded\nibm-vault-operator.v3.4.0                          IBM Vault Operator                                 3.4.0                ibm-vault-operator.v3.3.2               Succeeded\nibm-watson-aiops-ui-operator.v3.4.0                IBM Watson AIOps UI                                3.4.0                ibm-watson-aiops-ui-operator.v3.3.2     Succeeded\nopenshift-gitops-operator.v1.5.2                   Red Hat OpenShift GitOps                           1.5.2                                                        Succeeded\n</code></pre></p> <p>The output should be showing the new version 3.4.x for components below: - IBM Watson AIOps AI Manager - IBM Watson AIOps Edge - IBM Netcool Agile Service Manager - IBM Watson AIOps Issue Resolution AI &amp; Analytics - IBM Watson AIOps Issue Resolution Core - IBM Cloud Pak for Watson AIOps Lifecycle - IBM Cloud Pak for Watson AIOps AI Manager - IBM Internal - IBM Watson AIOps Kong - IBM Postgreservice - IBM Secure Tunnel - IBM Vault Operator - IBM Watson AIOps UI</p>"}]}