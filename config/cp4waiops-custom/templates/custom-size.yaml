{{- if hasSuffix "-custom" .Values.profile }}
apiVersion: v1
kind: ConfigMap
metadata:
  annotations:
    argocd.argoproj.io/sync-wave: "-1"
  name: aiops-custom-size-profile
  namespace: {{ .Values.aiManager.namespace }} 
data:
  profiles: |
    generatedFor: "NonHA"
    automationbase:
      kafka:
        replicas: {{.Values.res.kafka.kafka.replicas}}
        config:
          default.replication.factor: 1
          min.insync.replicas: 1
        resources:
          limits:
            cpu: "{{.Values.res.kafka.kafka.limits.cpu}}"
            memory: "{{.Values.res.kafka.kafka.limits.memory}}"
          requests:
            cpu: "{{.Values.res.kafka.kafka.requests.cpu}}"
            memory: "{{.Values.res.kafka.kafka.requests.memory}}"
      zookeeper:
        replicas: {{.Values.res.kafka.zookeeper.replicas}}
        resources:
          limits:
            cpu: "{{.Values.res.kafka.zookeeper.limits.cpu}}"
            memory: "{{.Values.res.kafka.zookeeper.limits.memory}}"
          requests:
            cpu: "{{.Values.res.kafka.zookeeper.requests.cpu}}"
            memory: "{{.Values.res.kafka.zookeeper.requests.memory}}"
      elasticsearch:
        env:
          - name: ES_JAVA_OPTS
            value: "{{.Values.res.elasticsearch.javaOps}}"
        replicas: {{.Values.res.elasticsearch.replicas}}
        resources:
          limits:
            cpu: "{{.Values.res.elasticsearch.elasticsearch.limits.cpu}}"
            memory: "{{.Values.res.elasticsearch.elasticsearch.limits.memory}}"
          requests:
            cpu: "{{.Values.res.elasticsearch.elasticsearch.requests.cpu}}"
            memory: "{{.Values.res.elasticsearch.elasticsearch.requests.memory}}"
        tls-proxy:
          resources:
            limits:
              cpu: "{{.Values.res.elasticsearch.tlsproxy.limits.cpu}}"
              memory: "{{.Values.res.elasticsearch.tlsproxy.limits.memory}}"
            requests:
              cpu: "{{.Values.res.elasticsearch.tlsproxy.requests.cpu}}"
              memory: "{{.Values.res.elasticsearch.tlsproxy.requests.memory}}"
    cp4waiops-eventprocessor:
      flink:
        # Settings for the jobmanager statefulSet
        jobmanager:
          replicas: {{.Values.res.flink.jobmanager.replicas}}
          resources:
            limits:
              cpu: "{{.Values.res.flink.jobmanager.jobmanager.limits.cpu}}"
              memory: "{{.Values.res.flink.jobmanager.jobmanager.limits.memory}}"
            requests:
              cpu: "{{.Values.res.flink.jobmanager.jobmanager.requests.cpu}}"
              memory: "{{.Values.res.flink.jobmanager.jobmanager.requests.memory}}"
        # Settings for the taskmanager statefulSet
        taskmanager:
          replicas: {{.Values.res.flink.taskmanager.replicas}}
          resources:
            limits:
              cpu: {{.Values.res.flink.taskmanager.taskmanager.limits.cpu}}
              memory: {{.Values.res.flink.taskmanager.taskmanager.limits.memory}}
            requests:
              cpu: {{.Values.res.flink.taskmanager.taskmanager.requests.cpu}}
              memory: {{.Values.res.flink.taskmanager.taskmanager.requests.memory}}
        properties:
          jobmanager.memory.heap.size: "{{.Values.res.flink.jobmanager.heapSize}}"
          jobmanager.memory.jvm-metaspace.size: "{{.Values.res.flink.jobmanager.jvmMetaSpaceSize}}"
          taskmanager.memory.heap.size: "{{.Values.res.flink.taskmanager.heapSize}}"
          taskmanager.memory.managed.size: "{{.Values.res.flink.taskmanager.managedSize}}"
          taskmanager.numberOfTaskSlots: {{.Values.res.flink.taskmanager.numberOfTaskSlots}}
    configmaps:
    - name: aiops-topology-sizing
      data: 
        asm: |
          cassandra:
            specs:
              replicas: {{.Values.res.cassandra.replicas}}
            containers:
              cassandra:
                resources:
                  limits:
                    cpu: {{.Values.res.cassandra.limits.cpu}}
                    memory: {{.Values.res.cassandra.limits.memory}}
                  requests:
                    cpu: {{.Values.res.cassandra.requests.cpu}}
                    memory: {{.Values.res.cassandra.requests.memory}}
                env:
                  - name: CASSANDRA_HEAP_SIZE
                    value: {{.Values.res.cassandra.heap.size}}
                  - name: CASSANDRA_HEAP_NEWSIZE
                    value: {{.Values.res.cassandra.heap.newSize}}
    operandconfigs:
    - name: aimanager-operator
      spec:
        aimanager:
          modelTrain:
            maxLearners: {{.Values.res.aimanager.maxLearners}}
    - name: ibm-management-kong
      spec:
        kong:
          replicaCount: {{.Values.res.kong.replicas}}
    - name: couchdb
      spec:
        couchdbcluster:
          size: 1
          resources:
            db:
              limits:
                cpu: "{{.Values.res.couchdbcluster.db.limits.cpu}}"
                memory: "{{.Values.res.couchdbcluster.db.limits.memory}}"
              requests:
                cpu: "{{.Values.res.couchdbcluster.db.requests.cpu}}"
                memory: "{{.Values.res.couchdbcluster.db.requests.memory}}"
            search:
              limits:
                cpu: "{{.Values.res.couchdbcluster.search.limits.cpu}}"
                memory: "{{.Values.res.couchdbcluster.search.limits.memory}}"
              requests:
                cpu: "{{.Values.res.couchdbcluster.search.requests.cpu}}"
                memory: "{{.Values.res.couchdbcluster.search.requests.memory}}"
            mgmt:
              limits:
                cpu: "{{.Values.res.couchdbcluster.mgmt.limits.cpu}}"
                memory: "{{.Values.res.couchdbcluster.mgmt.limits.memory}}"
              requests:
                cpu: "{{.Values.res.couchdbcluster.mgmt.requests.cpu}}"
                memory: "{{.Values.res.couchdbcluster.mgmt.requests.memory}}"
    - name: redis
      spec:
        redissentinel:
          resources:
            member:
              db:
                limits:
                  cpu: "{{.Values.res.redis.member.db.limits.cpu}}"
                  memory: "{{.Values.res.redis.member.db.limits.memory}}"
                requests:
                  cpu: "{{.Values.res.redis.member.db.requests.cpu}}"
                  memory: "{{.Values.res.redis.member.db.requests.memory}}"
              mgmt:
                limits:
                  cpu: "{{.Values.res.redis.member.mgmt.limits.cpu}}"
                  memory: "{{.Values.res.redis.member.mgmt.limits.memory}}"
                requests:
                  cpu: "{{.Values.res.redis.member.mgmt.requests.cpu}}"
                  memory: "{{.Values.res.redis.member.mgmt.requests.memory}}"
              proxy:
                limits:
                  cpu: "{{.Values.res.redis.member.proxy.limits.cpu}}"
                  memory: "{{.Values.res.redis.member.proxy.limits.memory}}"
                requests:
                  cpu: "{{.Values.res.redis.member.proxy.requests.cpu}}"
                  memory: "{{.Values.res.redis.member.proxy.requests.memory}}"
              proxylog:
                limits:
                  cpu: "{{.Values.res.redis.member.proxylog.limits.cpu}}"
                  memory: "{{.Values.res.redis.member.proxylog.limits.memory}}"
                requests:
                  cpu: "{{.Values.res.redis.member.proxylog.requests.cpu}}"
                  memory: "{{.Values.res.redis.member.proxylog.requests.memory}}"
            sentinel:
              db:
                limits:
                  cpu: "{{.Values.res.redis.sentinel.db.limits.cpu}}"
                  memory: "{{.Values.res.redis.sentinel.db.limits.memory}}"
                requests:
                  cpu: "{{.Values.res.redis.sentinel.db.requests.cpu}}"
                  memory: "{{.Values.res.redis.sentinel.db.requests.memory}}"
              mgmt:
                limits:
                  cpu: "{{.Values.res.redis.sentinel.mgmt.limits.cpu}}"
                  memory: "{{.Values.res.redis.sentinel.mgmt.limits.memory}}"
                requests:
                  cpu: "{{.Values.res.redis.sentinel.mgmt.requests.cpu}}"
                  memory: "{{.Values.res.redis.sentinel.mgmt.requests.memory}}"
              proxy:
                limits:
                  cpu: "{{.Values.res.redis.sentinel.proxy.limits.cpu}}"
                  memory: "{{.Values.res.redis.sentinel.proxy.limits.memory}}"
                requests:
                  cpu: "{{.Values.res.redis.sentinel.proxy.requests.cpu}}"
                  memory: "{{.Values.res.redis.sentinel.proxy.requests.memory}}"
              proxylog:
                limits:
                  cpu: "{{.Values.res.redis.sentinel.proxylog.limits.cpu}}"
                  memory: "{{.Values.res.redis.sentinel.proxylog.limits.memory}}"
                requests:
                  cpu: "{{.Values.res.redis.sentinel.proxylog.requests.cpu}}"
                  memory: "{{.Values.res.redis.sentinel.proxylog.requests.memory}}"
    - name: ir-lifecycle-operator
      spec:
        lifecycleservice:
          customSizing:
            logstash:
              resourceLimitsCPU: "{{.Values.res.lifecycleservice.logstash.limits.cpu}}"
              resourceLimitsMemory: "{{.Values.res.lifecycleservice.logstash.limits.memory}}"
              resourceRequestsCPU: "{{.Values.res.lifecycleservice.logstash.requests.cpu}}"
              resourceRequestsMemory: "{{.Values.res.lifecycleservice.logstash.requests.memory}}"
            taskManager:
              resourceLimitsCPU: "{{.Values.res.lifecycleservice.taskManager.limits.cpu}}"
              resourceLimitsMemory: "{{.Values.res.lifecycleservice.taskManager.limits.memory}}"
              resourceRequestsCPU: "{{.Values.res.lifecycleservice.taskManager.requests.cpu}}"
              resourceRequestsMemory: "{{.Values.res.lifecycleservice.taskManager.requests.memory}}"
            jobManager:
              resourceLimitsCPU: "{{.Values.res.lifecycleservice.jobManager.limits.cpu}}"
              resourceLimitsMemory: "{{.Values.res.lifecycleservice.jobManager.limits.memory}}"
              resourceRequestsCPU: "{{.Values.res.lifecycleservice.jobManager.requests.cpu}}"
              resourceRequestsMemory: "{{.Values.res.lifecycleservice.jobManager.requests.memory}}"
    - name: ir-ai-operator
      spec:
        aiopsanalyticsorchestrator:
          customSizing:
            deployments:
              - name: probablecause
                replicas: {{.Values.res.probablecause.replicas}}
                containers:
                - name: probablecause
                  limits:
                    cpu: "{{.Values.res.probablecause.limits.cpu}}"
                    memory: "{{.Values.res.probablecause.limits.memory}}"
                  requests:
                    cpu: "{{.Values.res.probablecause.requests.cpu}}"
                    memory: "{{.Values.res.probablecause.requests.memory}}"
              - name: classifier
                replicas: {{.Values.res.classifier.replicas}}
                containers:
                - name: classifier
                  limits:
                    cpu: "{{.Values.res.classifier.limits.cpu}}"
                    memory: "{{.Values.res.classifier.limits.memory}}"
                  requests:
                    cpu: "{{.Values.res.classifier.requests.cpu}}"
                    memory: "{{.Values.res.classifier.requests.memory}}"
              - name: spark-worker
                replicas: {{.Values.res.sparkworker.replicas}}
                containers:
                - name: spark-worker
                  limits:
                    cpu: "{{.Values.res.sparkworker.limits.cpu}}"
                    memory: "{{.Values.res.sparkworker.limits.memory}}"
                  requests:
                    cpu: "{{.Values.res.sparkworker.requests.cpu}}"
                    memory: "{{.Values.res.sparkworker.requests.memory}}"
              - name: spark-pipeline-composer
                replicas: {{.Values.res.sparkpipelinecomposer.replicas}}
                containers:
                - name: spark-pipeline-composer
                  limits:
                    cpu: "{{.Values.res.sparkpipelinecomposer.limits.cpu}}"
                    memory: "{{.Values.res.sparkpipelinecomposer.limits.memory}}"
                  requests:
                    cpu: "{{.Values.res.sparkpipelinecomposer.requests.cpu}}"
                    memory: "{{.Values.res.sparkpipelinecomposer.requests.memory}}"
    - name: ir-core-operator
      spec:
        issueresolutioncore:
          customSizing:
            deployments:
              - name: ncodl-api
                replicas: {{.Values.res.ncodlapi.replicas}}
                containers:
                - name: api
                  limits:
                    cpu: "{{.Values.res.ncodlapi.limits.cpu}}"
                    memory: "{{.Values.res.ncodlapi.limits.memory}}"
                  requests:
                    cpu: "{{.Values.res.ncodlapi.requests.cpu}}"
                    memory: "{{.Values.res.ncodlapi.requests.memory}}"
              - name: ncodl-if
                replicas: {{.Values.res.ncodlif.replicas}}
                containers:
                - name: iducforward
                  limits:
                    cpu: "{{.Values.res.ncodlif.limits.cpu}}"
                    memory: "{{.Values.res.ncodlif.limits.memory}}"
                  requests:
                    cpu: "{{.Values.res.ncodlif.requests.cpu}}"
                    memory: "{{.Values.res.ncodlif.requests.memory}}"
              - name: ncodl-ir
                replicas: {{.Values.res.ncodlir.replicas}}
                containers:
                - name: iducrelay
                  limits:
                    cpu: "{{.Values.res.ncodlir.limits.cpu}}"
                    memory: "{{.Values.res.ncodlir.limits.memory}}"
                  requests:
                    cpu: "{{.Values.res.ncodlir.requests.cpu}}"
                    memory: "{{.Values.res.ncodlir.requests.memory}}"
              - name: ncodl-jobmgr
                replicas: {{.Values.res.ncodljobmgr.replicas}}
                containers:
                - name: jobmgr
                  limits:
                    cpu: "{{.Values.res.ncodljobmgr.limits.cpu}}"
                    memory: "{{.Values.res.ncodljobmgr.limits.memory}}"
                  requests:
                    cpu: "{{.Values.res.ncodljobmgr.requests.cpu}}"
                    memory: "{{.Values.res.ncodljobmgr.requests.memory}}"
              - name: ncodl-std
                replicas: {{.Values.res.ncodlstd.replicas}}
                containers:
                - name: standard
                  limits:
                    cpu: "{{.Values.res.ncodlstd.limits.cpu}}"
                    memory: "{{.Values.res.ncodlstd.limits.memory}}"
                  requests:
                    cpu: "{{.Values.res.ncodlstd.requests.cpu}}"
                    memory: "{{.Values.res.ncodlstd.requests.memory}}"
              - name: logstash
                replicas: {{.Values.res.logstash.replicas}}
                containers:
                - name: logstash
                  limits:
                    cpu: "{{.Values.res.logstash.limits.cpu}}"
                    memory: "{{.Values.res.logstash.limits.memory}}"
                  requests:
                    cpu: "{{.Values.res.logstash.requests.cpu}}"
                    memory: "{{.Values.res.logstash.requests.memory}}"
            statefulSets:
              - name: ncobackup
                replicas: {{.Values.res.ncobackup.replicas}}
                containers:
                - name: agg-gate
                  limits:
                    cpu: "{{.Values.res.ncobackup.agggate.limits.cpu}}"
                    memory: "{{.Values.res.ncobackup.agggate.limits.memory}}"
                  requests:
                    cpu: "{{.Values.res.ncobackup.agggate.requests.cpu}}"
                    memory: "{{.Values.res.ncobackup.agggate.requests.memory}}"
                - name: objserv
                  limits:
                    cpu: "{{.Values.res.ncobackup.objserv.limits.cpu}}"
                    memory: "{{.Values.res.ncobackup.objserv.limits.memory}}"
                  requests:
                    cpu: "{{.Values.res.ncobackup.objserv.requests.cpu}}"
                    memory: "{{.Values.res.ncobackup.objserv.requests.memory}}"
              - name: ncoprimary
                replicas: {{.Values.res.ncoprimary.replicas}}
                containers:
                - name: objserv
                  limits:
                    cpu: "{{.Values.res.ncoprimary.limits.cpu}}"
                    memory: "{{.Values.res.ncoprimary.limits.memory}}"  
                  requests:
                    cpu: "{{.Values.res.ncoprimary.requests.cpu}}"
                    memory: "{{.Values.res.ncoprimary.requests.memory}}"
---
apiVersion: redhatcop.redhat.io/v1alpha1
kind: ResourceLocker
metadata:
  name: aimanager-resource-locker
  namespace: resource-locker-operator
spec:
  patches:
  - id: aimanagermainprod-locker
    patchTemplate: |
      spec:
        helmValues:
          changeRisk:
            resources:
              limits:
                cpu: "{{.Values.res.changeRisk.limits.cpu}}"
                memory: "{{.Values.res.changeRisk.limits.memory}}"
              requests:
                cpu: "{{.Values.res.changeRisk.requests.cpu}}"
                memory: "{{.Values.res.changeRisk.requests.memory}}"
          logAnomaly:
            resources:
              limits:
                cpu: "{{.Values.res.logAnomaly.limits.cpu}}"
                memory: "{{.Values.res.logAnomaly.limits.memory}}"
              requests:
                cpu: "{{.Values.res.logAnomaly.requests.cpu}}"
                memory: "{{.Values.res.logAnomaly.requests.memory}}"
          aiPlatformApiServer:
            resources:
              limits:
                cpu: "{{.Values.res.aiPlatformApiServer.limits.cpu}}"
                memory: "{{.Values.res.aiPlatformApiServer.limits.memory}}"
              requests:
                cpu: "{{.Values.res.aiPlatformApiServer.requests.cpu}}"
                memory: "{{.Values.res.aiPlatformApiServer.requests.memory}}"
          global:
            logAnomaly:
              replicas: 1
    patchType: application/merge-patch+json
    targetObjectRef:
      apiVersion: ai-manager.watson-aiops.ibm.com/v1beta1
      kind: AIManagerMainProd
      name: aimanager
      namespace: {{.Values.aiManager.namespace}}
  serviceAccountRef:
    name: resource-locker-operator-controller-manager
---
apiVersion: redhatcop.redhat.io/v1alpha1
kind: ResourceLocker
metadata:
  name: iaf-resource-locker
  namespace: resource-locker-operator
spec:
  patches:
  - id: nginx-locker
    patchTemplate: |
      spec:
        replicas: {{.Values.res.nginx.replicas}}
    patchType: application/strategic-merge-patch+json
    targetObjectRef:
      apiVersion: apps/v1
      kind: Deployment
      name: ibm-nginx
      namespace: {{.Values.aiManager.namespace}}
  - id: usermgmt-locker
    patchTemplate: |
      spec:
        replicas: {{.Values.res.usermgmt.replicas}}
    patchType: application/strategic-merge-patch+json
    targetObjectRef:
      apiVersion: apps/v1
      kind: Deployment
      name: usermgmt
      namespace: {{.Values.aiManager.namespace}}
  - id: zen-core-locker
    patchTemplate: |
      spec:
        replicas: {{.Values.res.zencore.replicas}}
    patchType: application/strategic-merge-patch+json
    targetObjectRef:
      apiVersion: apps/v1
      kind: Deployment
      name: zen-core
      namespace: {{.Values.aiManager.namespace}}
  - id: zen-core-api-locker
    patchTemplate: |
      spec:
        replicas: {{.Values.res.zencoreapi.replicas}}
    patchType: application/strategic-merge-patch+json
    targetObjectRef:
      apiVersion: apps/v1
      kind: Deployment
      name: zen-core-api
      namespace: {{.Values.aiManager.namespace}}    
  - id: automationbase-locker
    patchTemplate: |
      spec:
        kafka:
          entityOperator:
            tlsSidecar:
              resources:
                limits:
                  cpu: "{{.Values.res.kafka.entityOperator.tlsSidecar.limits.cpu}}"
                  memory: "{{.Values.res.kafka.entityOperator.tlsSidecar.limits.memory}}"
                requests:
                  cpu: "{{.Values.res.kafka.entityOperator.tlsSidecar.requests.cpu}}"
                  memory: "{{.Values.res.kafka.entityOperator.tlsSidecar.requests.memory}}"
            topicOperator:
              resources:
                limits:
                  cpu: "{{.Values.res.kafka.entityOperator.topicOperator.limits.cpu}}"
                  memory: "{{.Values.res.kafka.entityOperator.topicOperator.limits.memory}}"
                requests:
                  cpu: "{{.Values.res.kafka.entityOperator.topicOperator.requests.cpu}}"
                  memory: "{{.Values.res.kafka.entityOperator.topicOperator.requests.memory}}"
            userOperator:
              resources:
                limits:
                  cpu: "{{.Values.res.kafka.entityOperator.userOperator.limits.cpu}}"
                  memory: "{{.Values.res.kafka.entityOperator.userOperator.limits.memory}}"
                requests:
                  cpu: "{{.Values.res.kafka.entityOperator.userOperator.requests.cpu}}"
                  memory: "{{.Values.res.kafka.entityOperator.userOperator.requests.memory}}"
    patchType: application/merge-patch+json
    targetObjectRef:
      apiVersion: base.automation.ibm.com/v1beta1
      kind: AutomationBase
      name: automationbase-sample
      namespace: {{.Values.aiManager.namespace}}
  serviceAccountRef:
    name: resource-locker-operator-controller-manager
---
apiVersion: redhatcop.redhat.io/v1alpha1
kind: ResourceLocker
metadata:
  name: appmanager-resource-locker
  namespace: resource-locker-operator
spec:
  patches:
  - id: aiopsedge-operator-controller-manager-locker
    patchTemplate: |
      spec:
        replicas: {{.Values.res.aiopsedgeOperator.replicas}}
    patchType: application/strategic-merge-patch+json
    targetObjectRef:
      apiVersion: apps/v1
      kind: Deployment
      name: aiopsedge-operator-controller-manager
      namespace: {{.Values.aiManager.namespace}}
  serviceAccountRef:
    name: resource-locker-operator-controller-manager
{{- end }}
